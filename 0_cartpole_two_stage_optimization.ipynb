{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n",
      "cfg_env cartpole\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)\n",
    "print(\"cfg_env\",cfg_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-7875.4570)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 29612.53251  validloss 28798.53076±0.00000  bestvalidloss 28798.53076  last_update 0\n",
      "train: iter 1  trainloss 2909.69971  validloss 1664.17123±0.00000  bestvalidloss 1664.17123  last_update 0\n",
      "train: iter 2  trainloss 2927.73078  validloss 1332.37642±0.00000  bestvalidloss 1332.37642  last_update 0\n",
      "train: iter 3  trainloss 1910.93044  validloss 1176.35914±0.00000  bestvalidloss 1176.35914  last_update 0\n",
      "train: iter 4  trainloss 1378.65405  validloss 1112.51168±0.00000  bestvalidloss 1112.51168  last_update 0\n",
      "train: iter 5  trainloss 1193.93200  validloss 1044.42471±0.00000  bestvalidloss 1044.42471  last_update 0\n",
      "train: iter 6  trainloss 1190.70031  validloss 1030.92500±0.00000  bestvalidloss 1030.92500  last_update 0\n",
      "train: iter 7  trainloss 1087.34951  validloss 1447.92330±0.00000  bestvalidloss 1030.92500  last_update 1\n",
      "train: iter 8  trainloss 1034.80688  validloss 1001.82381±0.00000  bestvalidloss 1001.82381  last_update 0\n",
      "train: iter 9  trainloss 1001.03661  validloss 960.32826±0.00000  bestvalidloss 960.32826  last_update 0\n",
      "train: iter 10  trainloss 914.34918  validloss 965.64074±0.00000  bestvalidloss 960.32826  last_update 1\n",
      "train: iter 11  trainloss 864.93075  validloss 925.74653±0.00000  bestvalidloss 925.74653  last_update 0\n",
      "train: iter 12  trainloss 835.15681  validloss 853.77695±0.00000  bestvalidloss 853.77695  last_update 0\n",
      "train: iter 13  trainloss 827.30906  validloss 1014.79173±0.00000  bestvalidloss 853.77695  last_update 1\n",
      "train: iter 14  trainloss 758.24659  validloss 822.87076±0.00000  bestvalidloss 822.87076  last_update 0\n",
      "train: iter 15  trainloss 723.63874  validloss 760.10264±0.00000  bestvalidloss 760.10264  last_update 0\n",
      "train: iter 16  trainloss 697.60278  validloss 765.21249±0.00000  bestvalidloss 760.10264  last_update 1\n",
      "train: iter 17  trainloss 668.17658  validloss 722.61849±0.00000  bestvalidloss 722.61849  last_update 0\n",
      "train: iter 18  trainloss 635.78227  validloss 647.19960±0.00000  bestvalidloss 647.19960  last_update 0\n",
      "train: iter 19  trainloss 589.07718  validloss 606.53307±0.00000  bestvalidloss 606.53307  last_update 0\n",
      "train: iter 20  trainloss 581.01635  validloss 584.79521±0.00000  bestvalidloss 584.79521  last_update 0\n",
      "train: iter 21  trainloss 525.38920  validloss 557.04293±0.00000  bestvalidloss 557.04293  last_update 0\n",
      "train: iter 22  trainloss 491.27969  validloss 520.18845±0.00000  bestvalidloss 520.18845  last_update 0\n",
      "train: iter 23  trainloss 465.48107  validloss 562.09842±0.00000  bestvalidloss 520.18845  last_update 1\n",
      "train: iter 24  trainloss 446.25121  validloss 486.38190±0.00000  bestvalidloss 486.38190  last_update 0\n",
      "train: iter 25  trainloss 396.33258  validloss 419.02049±0.00000  bestvalidloss 419.02049  last_update 0\n",
      "train: iter 26  trainloss 380.59649  validloss 410.71195±0.00000  bestvalidloss 410.71195  last_update 0\n",
      "train: iter 27  trainloss 337.04773  validloss 372.96523±0.00000  bestvalidloss 372.96523  last_update 0\n",
      "train: iter 28  trainloss 311.58577  validloss 307.59573±0.00000  bestvalidloss 307.59573  last_update 0\n",
      "train: iter 29  trainloss 292.63809  validloss 296.85385±0.00000  bestvalidloss 296.85385  last_update 0\n",
      "train: iter 30  trainloss 249.62946  validloss 256.97739±0.00000  bestvalidloss 256.97739  last_update 0\n",
      "train: iter 31  trainloss 228.74332  validloss 229.70542±0.00000  bestvalidloss 229.70542  last_update 0\n",
      "train: iter 32  trainloss 202.63044  validloss 266.84666±0.00000  bestvalidloss 229.70542  last_update 1\n",
      "train: iter 33  trainloss 163.57625  validloss 188.26544±0.00000  bestvalidloss 188.26544  last_update 0\n",
      "train: iter 34  trainloss 129.39791  validloss 210.37057±0.00000  bestvalidloss 188.26544  last_update 1\n",
      "train: iter 35  trainloss 115.68789  validloss 147.41536±0.00000  bestvalidloss 147.41536  last_update 0\n",
      "train: iter 36  trainloss 90.53751  validloss 158.37995±0.00000  bestvalidloss 147.41536  last_update 1\n",
      "train: iter 37  trainloss 69.68802  validloss 59.20685±0.00000  bestvalidloss 59.20685  last_update 0\n",
      "train: iter 38  trainloss 25.23696  validloss 58.22997±0.00000  bestvalidloss 58.22997  last_update 0\n",
      "train: iter 39  trainloss 22.63837  validloss 25.44716±0.00000  bestvalidloss 25.44716  last_update 0\n",
      "train: iter 40  trainloss -8.48245  validloss -7.22148±0.00000  bestvalidloss -7.22148  last_update 0\n",
      "train: iter 41  trainloss -38.79063  validloss -30.43123±0.00000  bestvalidloss -30.43123  last_update 0\n",
      "train: iter 42  trainloss -50.42764  validloss -23.11520±0.00000  bestvalidloss -30.43123  last_update 1\n",
      "train: iter 43  trainloss -70.78026  validloss -68.81867±0.00000  bestvalidloss -68.81867  last_update 0\n",
      "train: iter 44  trainloss -78.99832  validloss -104.33438±0.00000  bestvalidloss -104.33438  last_update 0\n",
      "train: iter 45  trainloss -107.07231  validloss -110.58127±0.00000  bestvalidloss -110.58127  last_update 0\n",
      "train: iter 46  trainloss -87.20160  validloss -72.90707±0.00000  bestvalidloss -110.58127  last_update 1\n",
      "train: iter 47  trainloss -148.69137  validloss -143.11098±0.00000  bestvalidloss -143.11098  last_update 0\n",
      "train: iter 48  trainloss -158.90349  validloss -102.76911±0.00000  bestvalidloss -143.11098  last_update 1\n",
      "train: iter 49  trainloss -177.43653  validloss -167.25797±0.00000  bestvalidloss -167.25797  last_update 0\n",
      "train: iter 50  trainloss -176.55536  validloss -188.69472±0.00000  bestvalidloss -188.69472  last_update 0\n",
      "train: iter 51  trainloss -186.53683  validloss -127.37570±0.00000  bestvalidloss -188.69472  last_update 1\n",
      "train: iter 52  trainloss -193.45639  validloss -208.05750±0.00000  bestvalidloss -208.05750  last_update 0\n",
      "train: iter 53  trainloss -231.17981  validloss -195.39886±0.00000  bestvalidloss -208.05750  last_update 1\n",
      "train: iter 54  trainloss -230.66934  validloss -231.70216±0.00000  bestvalidloss -231.70216  last_update 0\n",
      "train: iter 55  trainloss -250.18996  validloss -228.68294±0.00000  bestvalidloss -231.70216  last_update 1\n",
      "train: iter 56  trainloss -270.57369  validloss -220.94453±0.00000  bestvalidloss -231.70216  last_update 2\n",
      "train: iter 57  trainloss -279.40172  validloss -228.96285±0.00000  bestvalidloss -231.70216  last_update 3\n",
      "train: iter 58  trainloss -275.64768  validloss -230.25394±0.00000  bestvalidloss -231.70216  last_update 4\n",
      "train: iter 59  trainloss -282.75152  validloss -254.66085±0.00000  bestvalidloss -254.66085  last_update 0\n",
      "train: iter 60  trainloss -257.83542  validloss -270.92763±0.00000  bestvalidloss -270.92763  last_update 0\n",
      "train: iter 61  trainloss -330.18300  validloss -263.18630±0.00000  bestvalidloss -270.92763  last_update 1\n",
      "train: iter 62  trainloss -278.59570  validloss -329.43958±0.00000  bestvalidloss -329.43958  last_update 0\n",
      "train: iter 63  trainloss -320.01967  validloss -275.52834±0.00000  bestvalidloss -329.43958  last_update 1\n",
      "train: iter 64  trainloss -355.57633  validloss -322.90313±0.00000  bestvalidloss -329.43958  last_update 2\n",
      "train: iter 65  trainloss -367.62336  validloss -279.74350±0.00000  bestvalidloss -329.43958  last_update 3\n",
      "train: iter 66  trainloss -370.79041  validloss -378.08488±0.00000  bestvalidloss -378.08488  last_update 0\n",
      "train: iter 67  trainloss -382.65999  validloss -363.88226±0.00000  bestvalidloss -378.08488  last_update 1\n",
      "train: iter 68  trainloss -398.21530  validloss -388.30331±0.00000  bestvalidloss -388.30331  last_update 0\n",
      "train: iter 69  trainloss -417.91953  validloss -387.60812±0.00000  bestvalidloss -388.30331  last_update 1\n",
      "train: iter 70  trainloss -411.17488  validloss -430.28800±0.00000  bestvalidloss -430.28800  last_update 0\n",
      "train: iter 71  trainloss -368.24832  validloss -380.29286±0.00000  bestvalidloss -430.28800  last_update 1\n",
      "train: iter 72  trainloss -347.72351  validloss -335.48899±0.00000  bestvalidloss -430.28800  last_update 2\n",
      "train: iter 73  trainloss -361.12955  validloss -407.24265±0.00000  bestvalidloss -430.28800  last_update 3\n",
      "train: iter 74  trainloss -429.15294  validloss -410.71480±0.00000  bestvalidloss -430.28800  last_update 4\n",
      "train: iter 75  trainloss -320.66615  validloss -326.64198±0.00000  bestvalidloss -430.28800  last_update 5\n",
      "train: iter 76  trainloss -421.55106  validloss -418.12525±0.00000  bestvalidloss -430.28800  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -472.36623  validloss -457.78166±0.00000  bestvalidloss -457.78166  last_update 0\n",
      "train: iter 78  trainloss -482.06876  validloss -438.77308±0.00000  bestvalidloss -457.78166  last_update 1\n",
      "train: iter 79  trainloss -453.05872  validloss -467.47838±0.00000  bestvalidloss -467.47838  last_update 0\n",
      "train: iter 80  trainloss -476.10761  validloss -494.51518±0.00000  bestvalidloss -494.51518  last_update 0\n",
      "train: iter 81  trainloss -379.47435  validloss -452.64368±0.00000  bestvalidloss -494.51518  last_update 1\n",
      "train: iter 82  trainloss -486.23303  validloss -469.56813±0.00000  bestvalidloss -494.51518  last_update 2\n",
      "train: iter 83  trainloss -486.44701  validloss -445.30703±0.00000  bestvalidloss -494.51518  last_update 3\n",
      "train: iter 84  trainloss -363.22563  validloss -458.79488±0.00000  bestvalidloss -494.51518  last_update 4\n",
      "train: iter 85  trainloss -463.59056  validloss -421.98044±0.00000  bestvalidloss -494.51518  last_update 5\n",
      "train: iter 86  trainloss -514.38512  validloss -527.40864±0.00000  bestvalidloss -527.40864  last_update 0\n",
      "train: iter 87  trainloss -423.77257  validloss -525.77932±0.00000  bestvalidloss -527.40864  last_update 1\n",
      "train: iter 88  trainloss -479.89261  validloss -425.63689±0.00000  bestvalidloss -527.40864  last_update 2\n",
      "train: iter 89  trainloss -526.98069  validloss -521.02578±0.00000  bestvalidloss -527.40864  last_update 3\n",
      "train: iter 90  trainloss -501.11231  validloss -546.10730±0.00000  bestvalidloss -546.10730  last_update 0\n",
      "train: iter 91  trainloss -346.13588  validloss -294.41704±0.00000  bestvalidloss -546.10730  last_update 1\n",
      "train: iter 92  trainloss -381.55487  validloss -264.30902±0.00000  bestvalidloss -546.10730  last_update 2\n",
      "train: iter 93  trainloss -491.30549  validloss -271.84203±0.00000  bestvalidloss -546.10730  last_update 3\n",
      "train: iter 94  trainloss -573.79731  validloss -514.21877±0.00000  bestvalidloss -546.10730  last_update 4\n",
      "train: iter 95  trainloss -580.29593  validloss -561.14408±0.00000  bestvalidloss -561.14408  last_update 0\n",
      "train: iter 96  trainloss -546.41537  validloss -546.64334±0.00000  bestvalidloss -561.14408  last_update 1\n",
      "train: iter 97  trainloss -392.04976  validloss -321.31384±0.00000  bestvalidloss -561.14408  last_update 2\n",
      "train: iter 98  trainloss -567.01280  validloss -570.57368±0.00000  bestvalidloss -570.57368  last_update 0\n",
      "train: iter 99  trainloss -589.94925  validloss -561.12272±0.00000  bestvalidloss -570.57368  last_update 1\n",
      "train: iter 100  trainloss -562.50166  validloss -585.31077±0.00000  bestvalidloss -585.31077  last_update 0\n",
      "train: iter 101  trainloss -592.11865  validloss -600.87685±0.00000  bestvalidloss -600.87685  last_update 0\n",
      "train: iter 102  trainloss -590.10224  validloss -519.92284±0.00000  bestvalidloss -600.87685  last_update 1\n",
      "train: iter 103  trainloss -588.65688  validloss -533.52573±0.00000  bestvalidloss -600.87685  last_update 2\n",
      "train: iter 104  trainloss -505.82141  validloss -485.03368±0.00000  bestvalidloss -600.87685  last_update 3\n",
      "train: iter 105  trainloss -595.04898  validloss -610.17519±0.00000  bestvalidloss -610.17519  last_update 0\n",
      "train: iter 106  trainloss -615.21248  validloss -576.45234±0.00000  bestvalidloss -610.17519  last_update 1\n",
      "train: iter 107  trainloss -638.37568  validloss -626.75313±0.00000  bestvalidloss -626.75313  last_update 0\n",
      "train: iter 108  trainloss -567.97134  validloss -540.61229±0.00000  bestvalidloss -626.75313  last_update 1\n",
      "train: iter 109  trainloss -454.50621  validloss -436.30082±0.00000  bestvalidloss -626.75313  last_update 2\n",
      "train: iter 110  trainloss -474.29897  validloss -401.26269±0.00000  bestvalidloss -626.75313  last_update 3\n",
      "train: iter 111  trainloss -556.59542  validloss -490.31607±0.00000  bestvalidloss -626.75313  last_update 4\n",
      "train: iter 112  trainloss -542.04813  validloss -525.36861±0.00000  bestvalidloss -626.75313  last_update 5\n",
      "train: iter 113  trainloss -423.17890  validloss -445.69611±0.00000  bestvalidloss -626.75313  last_update 6\n",
      "train: iter 114  trainloss -545.52878  validloss -485.07164±0.00000  bestvalidloss -626.75313  last_update 7\n",
      "train: iter 115  trainloss -530.01826  validloss -615.54030±0.00000  bestvalidloss -626.75313  last_update 8\n",
      "train: iter 116  trainloss -593.18655  validloss -642.11718±0.00000  bestvalidloss -642.11718  last_update 0\n",
      "train: iter 117  trainloss -630.10340  validloss -642.51972±0.00000  bestvalidloss -642.51972  last_update 0\n",
      "train: iter 118  trainloss -635.88106  validloss -632.15616±0.00000  bestvalidloss -642.51972  last_update 1\n",
      "train: iter 119  trainloss -535.42550  validloss -432.47436±0.00000  bestvalidloss -642.51972  last_update 2\n",
      "train: iter 120  trainloss -603.05783  validloss -591.85501±0.00000  bestvalidloss -642.51972  last_update 3\n",
      "train: iter 121  trainloss -644.04008  validloss -621.71510±0.00000  bestvalidloss -642.51972  last_update 4\n",
      "train: iter 122  trainloss -289.18761  validloss -461.45296±0.00000  bestvalidloss -642.51972  last_update 5\n",
      "train: iter 123  trainloss -486.72623  validloss -220.89005±0.00000  bestvalidloss -642.51972  last_update 6\n",
      "train: iter 124  trainloss -579.22257  validloss -452.24378±0.00000  bestvalidloss -642.51972  last_update 7\n",
      "train: iter 125  trainloss -626.97245  validloss -598.04637±0.00000  bestvalidloss -642.51972  last_update 8\n",
      "train: iter 126  trainloss -673.25128  validloss -606.48415±0.00000  bestvalidloss -642.51972  last_update 9\n",
      "train: iter 127  trainloss -658.20412  validloss -684.50126±0.00000  bestvalidloss -684.50126  last_update 0\n",
      "train: iter 128  trainloss -675.29093  validloss -663.76890±0.00000  bestvalidloss -684.50126  last_update 1\n",
      "train: iter 129  trainloss -636.21717  validloss -634.52557±0.00000  bestvalidloss -684.50126  last_update 2\n",
      "train: iter 130  trainloss -663.55884  validloss -637.17728±0.00000  bestvalidloss -684.50126  last_update 3\n",
      "train: iter 131  trainloss -721.23918  validloss -730.01969±0.00000  bestvalidloss -730.01969  last_update 0\n",
      "train: iter 132  trainloss -583.57368  validloss -654.54857±0.00000  bestvalidloss -730.01969  last_update 1\n",
      "train: iter 133  trainloss -585.94010  validloss -700.26728±0.00000  bestvalidloss -730.01969  last_update 2\n",
      "train: iter 134  trainloss -603.85090  validloss -636.41158±0.00000  bestvalidloss -730.01969  last_update 3\n",
      "train: iter 135  trainloss -652.98119  validloss -652.80237±0.00000  bestvalidloss -730.01969  last_update 4\n",
      "train: iter 136  trainloss -687.03540  validloss -655.25684±0.00000  bestvalidloss -730.01969  last_update 5\n",
      "train: iter 137  trainloss -562.94102  validloss -676.57204±0.00000  bestvalidloss -730.01969  last_update 6\n",
      "train: iter 138  trainloss -636.49091  validloss -515.07130±0.00000  bestvalidloss -730.01969  last_update 7\n",
      "train: iter 139  trainloss -726.92808  validloss -739.83998±0.00000  bestvalidloss -739.83998  last_update 0\n",
      "train: iter 140  trainloss -627.76459  validloss -514.26933±0.00000  bestvalidloss -739.83998  last_update 1\n",
      "train: iter 141  trainloss -702.20165  validloss -435.20192±0.00000  bestvalidloss -739.83998  last_update 2\n",
      "train: iter 142  trainloss -761.12704  validloss -736.61192±0.00000  bestvalidloss -739.83998  last_update 3\n",
      "train: iter 143  trainloss -674.56516  validloss -508.31842±0.00000  bestvalidloss -739.83998  last_update 4\n",
      "train: iter 144  trainloss -682.94831  validloss -616.82275±0.00000  bestvalidloss -739.83998  last_update 5\n",
      "train: iter 145  trainloss -526.57364  validloss -768.19763±0.00000  bestvalidloss -768.19763  last_update 0\n",
      "train: iter 146  trainloss -640.54997  validloss -416.55844±0.00000  bestvalidloss -768.19763  last_update 1\n",
      "train: iter 147  trainloss -640.53820  validloss -571.15035±0.00000  bestvalidloss -768.19763  last_update 2\n",
      "train: iter 148  trainloss -629.45807  validloss -594.36121±0.00000  bestvalidloss -768.19763  last_update 3\n",
      "train: iter 149  trainloss -651.31832  validloss -675.09363±0.00000  bestvalidloss -768.19763  last_update 4\n",
      "train: iter 150  trainloss -716.97305  validloss -697.35130±0.00000  bestvalidloss -768.19763  last_update 5\n",
      "train: iter 151  trainloss -571.83855  validloss -586.14473±0.00000  bestvalidloss -768.19763  last_update 6\n",
      "train: iter 152  trainloss -608.83849  validloss -635.57534±0.00000  bestvalidloss -768.19763  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -750.41219  validloss -730.12974±0.00000  bestvalidloss -768.19763  last_update 8\n",
      "train: iter 154  trainloss -757.72260  validloss -720.44904±0.00000  bestvalidloss -768.19763  last_update 9\n",
      "train: iter 155  trainloss -777.19634  validloss -705.10197±0.00000  bestvalidloss -768.19763  last_update 10\n",
      "train: iter 156  trainloss -658.88071  validloss -771.04091±0.00000  bestvalidloss -771.04091  last_update 0\n",
      "train: iter 157  trainloss -382.49500  validloss -665.68423±0.00000  bestvalidloss -771.04091  last_update 1\n",
      "train: iter 158  trainloss -700.75221  validloss -618.72111±0.00000  bestvalidloss -771.04091  last_update 2\n",
      "train: iter 159  trainloss -770.32962  validloss -718.83034±0.00000  bestvalidloss -771.04091  last_update 3\n",
      "train: iter 160  trainloss -814.30756  validloss -767.54101±0.00000  bestvalidloss -771.04091  last_update 4\n",
      "train: iter 161  trainloss -773.94768  validloss -791.96920±0.00000  bestvalidloss -791.96920  last_update 0\n",
      "train: iter 162  trainloss -786.69795  validloss -570.97128±0.00000  bestvalidloss -791.96920  last_update 1\n",
      "train: iter 163  trainloss -518.92230  validloss -167.52602±0.00000  bestvalidloss -791.96920  last_update 2\n",
      "train: iter 164  trainloss -781.57588  validloss -748.14911±0.00000  bestvalidloss -791.96920  last_update 3\n",
      "train: iter 165  trainloss -744.84916  validloss -733.01754±0.00000  bestvalidloss -791.96920  last_update 4\n",
      "train: iter 166  trainloss -765.48430  validloss -750.11623±0.00000  bestvalidloss -791.96920  last_update 5\n",
      "train: iter 167  trainloss -737.64336  validloss -707.99084±0.00000  bestvalidloss -791.96920  last_update 6\n",
      "train: iter 168  trainloss -634.88973  validloss -735.43143±0.00000  bestvalidloss -791.96920  last_update 7\n",
      "train: iter 169  trainloss -677.44587  validloss -735.29121±0.00000  bestvalidloss -791.96920  last_update 8\n",
      "train: iter 170  trainloss -690.80095  validloss -536.98192±0.00000  bestvalidloss -791.96920  last_update 9\n",
      "train: iter 171  trainloss -744.83782  validloss -762.77918±0.00000  bestvalidloss -791.96920  last_update 10\n",
      "train: iter 172  trainloss -638.09889  validloss -795.00833±0.00000  bestvalidloss -795.00833  last_update 0\n",
      "train: iter 173  trainloss -558.15733  validloss -333.50172±0.00000  bestvalidloss -795.00833  last_update 1\n",
      "train: iter 174  trainloss -600.43212  validloss -635.64232±0.00000  bestvalidloss -795.00833  last_update 2\n",
      "train: iter 175  trainloss -494.22554  validloss -251.04795±0.00000  bestvalidloss -795.00833  last_update 3\n",
      "train: iter 176  trainloss -714.98779  validloss -669.21252±0.00000  bestvalidloss -795.00833  last_update 4\n",
      "train: iter 177  trainloss -838.02050  validloss -770.85798±0.00000  bestvalidloss -795.00833  last_update 5\n",
      "train: iter 178  trainloss -743.52040  validloss -784.23425±0.00000  bestvalidloss -795.00833  last_update 6\n",
      "train: iter 179  trainloss -834.07828  validloss -777.52969±0.00000  bestvalidloss -795.00833  last_update 7\n",
      "train: iter 180  trainloss -727.82831  validloss -830.62407±0.00000  bestvalidloss -830.62407  last_update 0\n",
      "train: iter 181  trainloss -705.46461  validloss -728.65225±0.00000  bestvalidloss -830.62407  last_update 1\n",
      "train: iter 182  trainloss -631.19720  validloss -679.04679±0.00000  bestvalidloss -830.62407  last_update 2\n",
      "train: iter 183  trainloss -778.50647  validloss -563.00745±0.00000  bestvalidloss -830.62407  last_update 3\n",
      "train: iter 184  trainloss -859.00773  validloss -723.40314±0.00000  bestvalidloss -830.62407  last_update 4\n",
      "train: iter 185  trainloss -712.12495  validloss -823.40864±0.00000  bestvalidloss -830.62407  last_update 5\n",
      "train: iter 186  trainloss -814.46816  validloss -701.37845±0.00000  bestvalidloss -830.62407  last_update 6\n",
      "train: iter 187  trainloss -669.67249  validloss -777.37493±0.00000  bestvalidloss -830.62407  last_update 7\n",
      "train: iter 188  trainloss -777.89087  validloss -691.44339±0.00000  bestvalidloss -830.62407  last_update 8\n",
      "train: iter 189  trainloss -670.85091  validloss -514.65007±0.00000  bestvalidloss -830.62407  last_update 9\n",
      "train: iter 190  trainloss -785.07951  validloss -713.67671±0.00000  bestvalidloss -830.62407  last_update 10\n",
      "train: iter 191  trainloss -831.98222  validloss -846.55319±0.00000  bestvalidloss -846.55319  last_update 0\n",
      "train: iter 192  trainloss -785.40350  validloss -530.38345±0.00000  bestvalidloss -846.55319  last_update 1\n",
      "train: iter 193  trainloss -823.40286  validloss -873.14912±0.00000  bestvalidloss -873.14912  last_update 0\n",
      "train: iter 194  trainloss -842.08784  validloss -815.02259±0.00000  bestvalidloss -873.14912  last_update 1\n",
      "train: iter 195  trainloss -834.78288  validloss -721.43680±0.00000  bestvalidloss -873.14912  last_update 2\n",
      "train: iter 196  trainloss -484.52441  validloss 122.21431±0.00000  bestvalidloss -873.14912  last_update 3\n",
      "train: iter 197  trainloss -800.30815  validloss -807.36913±0.00000  bestvalidloss -873.14912  last_update 4\n",
      "train: iter 198  trainloss -660.64389  validloss -630.32817±0.00000  bestvalidloss -873.14912  last_update 5\n",
      "train: iter 199  trainloss -690.75254  validloss -349.14639±0.00000  bestvalidloss -873.14912  last_update 6\n",
      "train: iter 200  trainloss -758.62744  validloss -827.34549±0.00000  bestvalidloss -873.14912  last_update 7\n",
      "train: iter 201  trainloss -849.78174  validloss -850.25278±0.00000  bestvalidloss -873.14912  last_update 8\n",
      "train: iter 202  trainloss -875.00123  validloss -873.12629±0.00000  bestvalidloss -873.14912  last_update 9\n",
      "train: iter 203  trainloss -642.09090  validloss -906.82757±0.00000  bestvalidloss -906.82757  last_update 0\n",
      "train: iter 204  trainloss -782.59878  validloss -728.27788±0.00000  bestvalidloss -906.82757  last_update 1\n",
      "train: iter 205  trainloss -667.96418  validloss -866.88723±0.00000  bestvalidloss -906.82757  last_update 2\n",
      "train: iter 206  trainloss -796.90942  validloss -469.96520±0.00000  bestvalidloss -906.82757  last_update 3\n",
      "train: iter 207  trainloss -905.92298  validloss -890.36535±0.00000  bestvalidloss -906.82757  last_update 4\n",
      "train: iter 208  trainloss -823.38203  validloss -832.82105±0.00000  bestvalidloss -906.82757  last_update 5\n",
      "train: iter 209  trainloss -830.12398  validloss -777.24558±0.00000  bestvalidloss -906.82757  last_update 6\n",
      "train: iter 210  trainloss -879.49442  validloss -886.20947±0.00000  bestvalidloss -906.82757  last_update 7\n",
      "train: iter 211  trainloss -901.22770  validloss -907.13370±0.00000  bestvalidloss -907.13370  last_update 0\n",
      "train: iter 212  trainloss -786.43425  validloss -758.01780±0.00000  bestvalidloss -907.13370  last_update 1\n",
      "train: iter 213  trainloss -671.20730  validloss -760.81840±0.00000  bestvalidloss -907.13370  last_update 2\n",
      "train: iter 214  trainloss -713.78830  validloss -411.05348±0.00000  bestvalidloss -907.13370  last_update 3\n",
      "train: iter 215  trainloss -566.03790  validloss -787.72163±0.00000  bestvalidloss -907.13370  last_update 4\n",
      "train: iter 216  trainloss -735.97991  validloss -555.05866±0.00000  bestvalidloss -907.13370  last_update 5\n",
      "train: iter 217  trainloss -844.13902  validloss -804.66044±0.00000  bestvalidloss -907.13370  last_update 6\n",
      "train: iter 218  trainloss -864.71328  validloss -849.70477±0.00000  bestvalidloss -907.13370  last_update 7\n",
      "train: iter 219  trainloss -842.15960  validloss -865.45352±0.00000  bestvalidloss -907.13370  last_update 8\n",
      "train: iter 220  trainloss -889.24069  validloss -877.25541±0.00000  bestvalidloss -907.13370  last_update 9\n",
      "train: iter 221  trainloss -823.86730  validloss -801.59820±0.00000  bestvalidloss -907.13370  last_update 10\n",
      "train: iter 222  trainloss -906.91117  validloss -884.41797±0.00000  bestvalidloss -907.13370  last_update 11\n",
      "train: iter 223  trainloss -829.88658  validloss -922.68981±0.00000  bestvalidloss -922.68981  last_update 0\n",
      "train: iter 224  trainloss -928.12549  validloss -904.70578±0.00000  bestvalidloss -922.68981  last_update 1\n",
      "train: iter 225  trainloss -857.90757  validloss -961.03818±0.00000  bestvalidloss -961.03818  last_update 0\n",
      "train: iter 226  trainloss -887.24660  validloss -777.34261±0.00000  bestvalidloss -961.03818  last_update 1\n",
      "train: iter 227  trainloss -845.44161  validloss -909.12631±0.00000  bestvalidloss -961.03818  last_update 2\n",
      "train: iter 228  trainloss -915.89149  validloss -792.17183±0.00000  bestvalidloss -961.03818  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 229  trainloss -918.95156  validloss -956.40245±0.00000  bestvalidloss -961.03818  last_update 4\n",
      "train: iter 230  trainloss -943.89020  validloss -856.20793±0.00000  bestvalidloss -961.03818  last_update 5\n",
      "train: iter 231  trainloss -714.89225  validloss -871.42762±0.00000  bestvalidloss -961.03818  last_update 6\n",
      "train: iter 232  trainloss -924.01205  validloss -790.82453±0.00000  bestvalidloss -961.03818  last_update 7\n",
      "train: iter 233  trainloss -676.80693  validloss -875.36682±0.00000  bestvalidloss -961.03818  last_update 8\n",
      "train: iter 234  trainloss -944.16061  validloss -931.23321±0.00000  bestvalidloss -961.03818  last_update 9\n",
      "train: iter 235  trainloss -733.99331  validloss -975.51769±0.00000  bestvalidloss -975.51769  last_update 0\n",
      "train: iter 236  trainloss -787.26576  validloss -820.55262±0.00000  bestvalidloss -975.51769  last_update 1\n",
      "train: iter 237  trainloss -914.41405  validloss -835.93501±0.00000  bestvalidloss -975.51769  last_update 2\n",
      "train: iter 238  trainloss -905.59431  validloss -897.62232±0.00000  bestvalidloss -975.51769  last_update 3\n",
      "train: iter 239  trainloss -826.07789  validloss -956.79408±0.00000  bestvalidloss -975.51769  last_update 4\n",
      "train: iter 240  trainloss -931.76272  validloss -957.45957±0.00000  bestvalidloss -975.51769  last_update 5\n",
      "train: iter 241  trainloss -902.15094  validloss -915.88079±0.00000  bestvalidloss -975.51769  last_update 6\n",
      "train: iter 242  trainloss -817.44716  validloss -818.76998±0.00000  bestvalidloss -975.51769  last_update 7\n",
      "train: iter 243  trainloss -873.58918  validloss -943.26950±0.00000  bestvalidloss -975.51769  last_update 8\n",
      "train: iter 244  trainloss -971.92711  validloss -886.15094±0.00000  bestvalidloss -975.51769  last_update 9\n",
      "train: iter 245  trainloss -859.45614  validloss -1017.45087±0.00000  bestvalidloss -1017.45087  last_update 0\n",
      "train: iter 246  trainloss -933.37329  validloss -925.43945±0.00000  bestvalidloss -1017.45087  last_update 1\n",
      "train: iter 247  trainloss -825.33671  validloss -924.81230±0.00000  bestvalidloss -1017.45087  last_update 2\n",
      "train: iter 248  trainloss -845.72040  validloss -903.58157±0.00000  bestvalidloss -1017.45087  last_update 3\n",
      "train: iter 249  trainloss -241.85588  validloss -835.35367±0.00000  bestvalidloss -1017.45087  last_update 4\n",
      "train: iter 250  trainloss -419.52388  validloss -474.54950±0.00000  bestvalidloss -1017.45087  last_update 5\n",
      "train: iter 251  trainloss -712.88558  validloss -648.54148±0.00000  bestvalidloss -1017.45087  last_update 6\n",
      "train: iter 252  trainloss -768.80887  validloss -790.40243±0.00000  bestvalidloss -1017.45087  last_update 7\n",
      "train: iter 253  trainloss -900.45391  validloss -841.17243±0.00000  bestvalidloss -1017.45087  last_update 8\n",
      "train: iter 254  trainloss -931.79055  validloss -929.21214±0.00000  bestvalidloss -1017.45087  last_update 9\n",
      "train: iter 255  trainloss -916.68330  validloss -858.27815±0.00000  bestvalidloss -1017.45087  last_update 10\n",
      "train: iter 256  trainloss -846.36477  validloss -941.66314±0.00000  bestvalidloss -1017.45087  last_update 11\n",
      "train: iter 257  trainloss -939.72197  validloss -925.66046±0.00000  bestvalidloss -1017.45087  last_update 12\n",
      "train: iter 258  trainloss -912.74799  validloss -743.26898±0.00000  bestvalidloss -1017.45087  last_update 13\n",
      "train: iter 259  trainloss -947.68884  validloss -916.81453±0.00000  bestvalidloss -1017.45087  last_update 14\n",
      "train: iter 260  trainloss -820.42948  validloss -929.77854±0.00000  bestvalidloss -1017.45087  last_update 15\n",
      "train: iter 261  trainloss -875.96260  validloss -645.91194±0.00000  bestvalidloss -1017.45087  last_update 16\n",
      "train: iter 262  trainloss -997.55675  validloss -890.02518±0.00000  bestvalidloss -1017.45087  last_update 17\n",
      "train: iter 263  trainloss -715.24835  validloss -960.29899±0.00000  bestvalidloss -1017.45087  last_update 18\n",
      "train: iter 264  trainloss -882.37254  validloss -658.94491±0.00000  bestvalidloss -1017.45087  last_update 19\n",
      "train: iter 265  trainloss -961.20770  validloss -794.69267±0.00000  bestvalidloss -1017.45087  last_update 20\n",
      "train: iter 266  trainloss -922.93000  validloss -840.41528±0.00000  bestvalidloss -1017.45087  last_update 21\n",
      "train: iter 267  trainloss -769.40779  validloss -1028.92767±0.00000  bestvalidloss -1028.92767  last_update 0\n",
      "train: iter 268  trainloss -964.16389  validloss -963.61758±0.00000  bestvalidloss -1028.92767  last_update 1\n",
      "train: iter 269  trainloss -896.38093  validloss -1012.66203±0.00000  bestvalidloss -1028.92767  last_update 2\n",
      "train: iter 270  trainloss -872.10352  validloss -639.34605±0.00000  bestvalidloss -1028.92767  last_update 3\n",
      "train: iter 271  trainloss -979.44728  validloss -913.11847±0.00000  bestvalidloss -1028.92767  last_update 4\n",
      "train: iter 272  trainloss -1007.76397  validloss -1023.58425±0.00000  bestvalidloss -1028.92767  last_update 5\n",
      "train: iter 273  trainloss -1022.03236  validloss -1034.20234±0.00000  bestvalidloss -1034.20234  last_update 0\n",
      "train: iter 274  trainloss -891.05657  validloss -1025.64080±0.00000  bestvalidloss -1034.20234  last_update 1\n",
      "train: iter 275  trainloss -959.14507  validloss -954.93129±0.00000  bestvalidloss -1034.20234  last_update 2\n",
      "train: iter 276  trainloss -823.66741  validloss -1029.05229±0.00000  bestvalidloss -1034.20234  last_update 3\n",
      "train: iter 277  trainloss -933.54695  validloss -946.51937±0.00000  bestvalidloss -1034.20234  last_update 4\n",
      "train: iter 278  trainloss -1026.47307  validloss -992.11983±0.00000  bestvalidloss -1034.20234  last_update 5\n",
      "train: iter 279  trainloss -923.41351  validloss -876.11336±0.00000  bestvalidloss -1034.20234  last_update 6\n",
      "train: iter 280  trainloss -836.44475  validloss -850.96688±0.00000  bestvalidloss -1034.20234  last_update 7\n",
      "train: iter 281  trainloss -1029.71188  validloss -913.53994±0.00000  bestvalidloss -1034.20234  last_update 8\n",
      "train: iter 282  trainloss -937.47856  validloss -1007.38405±0.00000  bestvalidloss -1034.20234  last_update 9\n",
      "train: iter 283  trainloss -993.01708  validloss -832.32389±0.00000  bestvalidloss -1034.20234  last_update 10\n",
      "train: iter 284  trainloss -965.10620  validloss -1019.22112±0.00000  bestvalidloss -1034.20234  last_update 11\n",
      "train: iter 285  trainloss -972.42134  validloss -974.84068±0.00000  bestvalidloss -1034.20234  last_update 12\n",
      "train: iter 286  trainloss -1011.45246  validloss -993.05986±0.00000  bestvalidloss -1034.20234  last_update 13\n",
      "train: iter 287  trainloss -887.59851  validloss -965.00583±0.00000  bestvalidloss -1034.20234  last_update 14\n",
      "train: iter 288  trainloss -941.16222  validloss -948.27851±0.00000  bestvalidloss -1034.20234  last_update 15\n",
      "train: iter 289  trainloss -885.13728  validloss -1006.33455±0.00000  bestvalidloss -1034.20234  last_update 16\n",
      "train: iter 290  trainloss -977.16236  validloss -938.27094±0.00000  bestvalidloss -1034.20234  last_update 17\n",
      "train: iter 291  trainloss -504.55696  validloss -1022.07349±0.00000  bestvalidloss -1034.20234  last_update 18\n",
      "train: iter 292  trainloss -898.03775  validloss -821.83750±0.00000  bestvalidloss -1034.20234  last_update 19\n",
      "train: iter 293  trainloss -977.42126  validloss -937.63334±0.00000  bestvalidloss -1034.20234  last_update 20\n",
      "train: iter 294  trainloss -937.27249  validloss -984.61791±0.00000  bestvalidloss -1034.20234  last_update 21\n",
      "train: iter 295  trainloss -997.51399  validloss -996.17645±0.00000  bestvalidloss -1034.20234  last_update 22\n",
      "train: iter 296  trainloss -1030.47863  validloss -961.75061±0.00000  bestvalidloss -1034.20234  last_update 23\n",
      "train: iter 297  trainloss -935.43329  validloss -986.57481±0.00000  bestvalidloss -1034.20234  last_update 24\n",
      "train: iter 298  trainloss -983.04727  validloss -951.25087±0.00000  bestvalidloss -1034.20234  last_update 25\n",
      "train: iter 299  trainloss -910.57019  validloss -892.96643±0.00000  bestvalidloss -1034.20234  last_update 26\n",
      "train: iter 300  trainloss -1050.14038  validloss -1047.16812±0.00000  bestvalidloss -1047.16812  last_update 0\n",
      "train: iter 301  trainloss -1008.98375  validloss -1078.44843±0.00000  bestvalidloss -1078.44843  last_update 0\n",
      "train: iter 302  trainloss -785.40833  validloss -971.15418±0.00000  bestvalidloss -1078.44843  last_update 1\n",
      "train: iter 303  trainloss -854.27300  validloss -925.42859±0.00000  bestvalidloss -1078.44843  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 304  trainloss -1013.48892  validloss -1040.29074±0.00000  bestvalidloss -1078.44843  last_update 3\n",
      "train: iter 305  trainloss -971.43967  validloss -955.22302±0.00000  bestvalidloss -1078.44843  last_update 4\n",
      "train: iter 306  trainloss -1032.06755  validloss -900.51608±0.00000  bestvalidloss -1078.44843  last_update 5\n",
      "train: iter 307  trainloss -995.22978  validloss -989.16158±0.00000  bestvalidloss -1078.44843  last_update 6\n",
      "train: iter 308  trainloss -800.02687  validloss -959.86877±0.00000  bestvalidloss -1078.44843  last_update 7\n",
      "train: iter 309  trainloss -1016.81086  validloss -1013.89419±0.00000  bestvalidloss -1078.44843  last_update 8\n",
      "train: iter 310  trainloss -948.19165  validloss -1047.07850±0.00000  bestvalidloss -1078.44843  last_update 9\n",
      "train: iter 311  trainloss -1025.79596  validloss -962.24689±0.00000  bestvalidloss -1078.44843  last_update 10\n",
      "train: iter 312  trainloss -867.46750  validloss -1028.68038±0.00000  bestvalidloss -1078.44843  last_update 11\n",
      "train: iter 313  trainloss -945.04136  validloss -898.38908±0.00000  bestvalidloss -1078.44843  last_update 12\n",
      "train: iter 314  trainloss -960.75623  validloss -1038.39836±0.00000  bestvalidloss -1078.44843  last_update 13\n",
      "train: iter 315  trainloss -950.90885  validloss -774.37039±0.00000  bestvalidloss -1078.44843  last_update 14\n",
      "train: iter 316  trainloss -1002.16096  validloss -839.32034±0.00000  bestvalidloss -1078.44843  last_update 15\n",
      "train: iter 317  trainloss -1057.35740  validloss -975.72722±0.00000  bestvalidloss -1078.44843  last_update 16\n",
      "train: iter 318  trainloss -980.57433  validloss -875.40073±0.00000  bestvalidloss -1078.44843  last_update 17\n",
      "train: iter 319  trainloss -953.75554  validloss -1058.67479±0.00000  bestvalidloss -1078.44843  last_update 18\n",
      "train: iter 320  trainloss -1001.47264  validloss -835.63187±0.00000  bestvalidloss -1078.44843  last_update 19\n",
      "train: iter 321  trainloss -1062.75293  validloss -1092.24419±0.00000  bestvalidloss -1092.24419  last_update 0\n",
      "train: iter 322  trainloss -921.35607  validloss -894.57742±0.00000  bestvalidloss -1092.24419  last_update 1\n",
      "train: iter 323  trainloss -1004.94594  validloss -1012.43027±0.00000  bestvalidloss -1092.24419  last_update 2\n",
      "train: iter 324  trainloss -630.96365  validloss -625.81565±0.00000  bestvalidloss -1092.24419  last_update 3\n",
      "train: iter 325  trainloss -923.89875  validloss -710.25382±0.00000  bestvalidloss -1092.24419  last_update 4\n",
      "train: iter 326  trainloss -1094.56211  validloss -1040.10711±0.00000  bestvalidloss -1092.24419  last_update 5\n",
      "train: iter 327  trainloss -1054.53664  validloss -1095.57110±0.00000  bestvalidloss -1095.57110  last_update 0\n",
      "train: iter 328  trainloss -989.88116  validloss -726.65140±0.00000  bestvalidloss -1095.57110  last_update 1\n",
      "train: iter 329  trainloss -1035.15911  validloss -1089.34963±0.00000  bestvalidloss -1095.57110  last_update 2\n",
      "train: iter 330  trainloss -957.45275  validloss -971.21361±0.00000  bestvalidloss -1095.57110  last_update 3\n",
      "train: iter 331  trainloss -498.02457  validloss -153.65652±0.00000  bestvalidloss -1095.57110  last_update 4\n",
      "train: iter 332  trainloss -830.41518  validloss -577.80242±0.00000  bestvalidloss -1095.57110  last_update 5\n",
      "train: iter 333  trainloss -916.66621  validloss -970.29229±0.00000  bestvalidloss -1095.57110  last_update 6\n",
      "train: iter 334  trainloss -871.72316  validloss -564.34223±0.00000  bestvalidloss -1095.57110  last_update 7\n",
      "train: iter 335  trainloss -1098.99439  validloss -1008.42246±0.00000  bestvalidloss -1095.57110  last_update 8\n",
      "train: iter 336  trainloss -842.30816  validloss -1099.56913±0.00000  bestvalidloss -1099.56913  last_update 0\n",
      "train: iter 337  trainloss -938.93437  validloss -908.56242±0.00000  bestvalidloss -1099.56913  last_update 1\n",
      "train: iter 338  trainloss -1012.49963  validloss -942.93727±0.00000  bestvalidloss -1099.56913  last_update 2\n",
      "train: iter 339  trainloss -961.70037  validloss -1060.60164±0.00000  bestvalidloss -1099.56913  last_update 3\n",
      "train: iter 340  trainloss -956.26528  validloss -849.30325±0.00000  bestvalidloss -1099.56913  last_update 4\n",
      "train: iter 341  trainloss -1051.47721  validloss -1022.32687±0.00000  bestvalidloss -1099.56913  last_update 5\n",
      "train: iter 342  trainloss -1106.41347  validloss -995.53705±0.00000  bestvalidloss -1099.56913  last_update 6\n",
      "train: iter 343  trainloss -930.10290  validloss -905.87631±0.00000  bestvalidloss -1099.56913  last_update 7\n",
      "train: iter 344  trainloss -1061.48163  validloss -960.72682±0.00000  bestvalidloss -1099.56913  last_update 8\n",
      "train: iter 345  trainloss -1038.48475  validloss -1085.83492±0.00000  bestvalidloss -1099.56913  last_update 9\n",
      "train: iter 346  trainloss -998.59461  validloss -1039.08859±0.00000  bestvalidloss -1099.56913  last_update 10\n",
      "train: iter 347  trainloss -1071.61181  validloss -1009.26095±0.00000  bestvalidloss -1099.56913  last_update 11\n",
      "train: iter 348  trainloss -844.30220  validloss -975.31680±0.00000  bestvalidloss -1099.56913  last_update 12\n",
      "train: iter 349  trainloss -881.70570  validloss -844.43621±0.00000  bestvalidloss -1099.56913  last_update 13\n",
      "train: iter 350  trainloss -961.97547  validloss -1016.56019±0.00000  bestvalidloss -1099.56913  last_update 14\n",
      "train: iter 351  trainloss -1047.53874  validloss -999.20617±0.00000  bestvalidloss -1099.56913  last_update 15\n",
      "train: iter 352  trainloss -1046.01272  validloss -1027.36820±0.00000  bestvalidloss -1099.56913  last_update 16\n",
      "train: iter 353  trainloss -1035.52056  validloss -966.38570±0.00000  bestvalidloss -1099.56913  last_update 17\n",
      "train: iter 354  trainloss -1085.60407  validloss -1071.17127±0.00000  bestvalidloss -1099.56913  last_update 18\n",
      "train: iter 355  trainloss -1027.33890  validloss -1060.71525±0.00000  bestvalidloss -1099.56913  last_update 19\n",
      "train: iter 356  trainloss -998.02141  validloss -1028.56148±0.00000  bestvalidloss -1099.56913  last_update 20\n",
      "train: iter 357  trainloss -1034.72951  validloss -1051.53156±0.00000  bestvalidloss -1099.56913  last_update 21\n",
      "train: iter 358  trainloss -1024.50222  validloss -1038.51529±0.00000  bestvalidloss -1099.56913  last_update 22\n",
      "train: iter 359  trainloss -1103.69299  validloss -1093.34516±0.00000  bestvalidloss -1099.56913  last_update 23\n",
      "train: iter 360  trainloss -1066.97663  validloss -1093.65642±0.00000  bestvalidloss -1099.56913  last_update 24\n",
      "train: iter 361  trainloss -745.72179  validloss -271.80589±0.00000  bestvalidloss -1099.56913  last_update 25\n",
      "train: iter 362  trainloss -913.27461  validloss -821.85757±0.00000  bestvalidloss -1099.56913  last_update 26\n",
      "train: iter 363  trainloss -1072.96710  validloss -999.20934±0.00000  bestvalidloss -1099.56913  last_update 27\n",
      "train: iter 364  trainloss -976.97708  validloss -1067.84169±0.00000  bestvalidloss -1099.56913  last_update 28\n",
      "train: iter 365  trainloss -1008.10056  validloss -806.71649±0.00000  bestvalidloss -1099.56913  last_update 29\n",
      "train: iter 366  trainloss -1085.04912  validloss -1079.09613±0.00000  bestvalidloss -1099.56913  last_update 30\n",
      "train: iter 367  trainloss -1118.15781  validloss -1121.47502±0.00000  bestvalidloss -1121.47502  last_update 0\n",
      "train: iter 368  trainloss -934.37744  validloss -980.74738±0.00000  bestvalidloss -1121.47502  last_update 1\n",
      "train: iter 369  trainloss -1091.31428  validloss -1067.41215±0.00000  bestvalidloss -1121.47502  last_update 2\n",
      "train: iter 370  trainloss -1059.67826  validloss -1087.41740±0.00000  bestvalidloss -1121.47502  last_update 3\n",
      "train: iter 371  trainloss -1041.53239  validloss -1052.91863±0.00000  bestvalidloss -1121.47502  last_update 4\n",
      "train: iter 372  trainloss -1100.25576  validloss -1099.37619±0.00000  bestvalidloss -1121.47502  last_update 5\n",
      "train: iter 373  trainloss -926.96644  validloss -913.57495±0.00000  bestvalidloss -1121.47502  last_update 6\n",
      "train: iter 374  trainloss -1094.00614  validloss -1032.78411±0.00000  bestvalidloss -1121.47502  last_update 7\n",
      "train: iter 375  trainloss -857.34639  validloss -972.80551±0.00000  bestvalidloss -1121.47502  last_update 8\n",
      "train: iter 376  trainloss -1015.56718  validloss -671.88136±0.00000  bestvalidloss -1121.47502  last_update 9\n",
      "train: iter 377  trainloss -1105.99768  validloss -1063.01799±0.00000  bestvalidloss -1121.47502  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 378  trainloss -974.36434  validloss -1017.73223±0.00000  bestvalidloss -1121.47502  last_update 11\n",
      "train: iter 379  trainloss -1024.51949  validloss -1044.67881±0.00000  bestvalidloss -1121.47502  last_update 12\n",
      "train: iter 380  trainloss -989.66121  validloss -1018.71917±0.00000  bestvalidloss -1121.47502  last_update 13\n",
      "train: iter 381  trainloss -1092.69918  validloss -1011.69547±0.00000  bestvalidloss -1121.47502  last_update 14\n",
      "train: iter 382  trainloss -993.95153  validloss -913.69109±0.00000  bestvalidloss -1121.47502  last_update 15\n",
      "train: iter 383  trainloss -915.35988  validloss -1037.44771±0.00000  bestvalidloss -1121.47502  last_update 16\n",
      "train: iter 384  trainloss -902.43690  validloss -960.20908±0.00000  bestvalidloss -1121.47502  last_update 17\n",
      "train: iter 385  trainloss -943.08151  validloss -625.38706±0.00000  bestvalidloss -1121.47502  last_update 18\n",
      "train: iter 386  trainloss -1114.78286  validloss -1068.09966±0.00000  bestvalidloss -1121.47502  last_update 19\n",
      "train: iter 387  trainloss -941.06596  validloss -1129.04219±0.00000  bestvalidloss -1129.04219  last_update 0\n",
      "train: iter 388  trainloss -877.72887  validloss -710.04266±0.00000  bestvalidloss -1129.04219  last_update 1\n",
      "train: iter 389  trainloss -1072.50647  validloss -1090.35507±0.00000  bestvalidloss -1129.04219  last_update 2\n",
      "train: iter 390  trainloss -1077.42472  validloss -930.58629±0.00000  bestvalidloss -1129.04219  last_update 3\n",
      "train: iter 391  trainloss -1037.06646  validloss -1104.57447±0.00000  bestvalidloss -1129.04219  last_update 4\n",
      "train: iter 392  trainloss -1070.59757  validloss -996.24426±0.00000  bestvalidloss -1129.04219  last_update 5\n",
      "train: iter 393  trainloss -1148.32239  validloss -1110.27610±0.00000  bestvalidloss -1129.04219  last_update 6\n",
      "train: iter 394  trainloss -746.86213  validloss -720.11174±0.00000  bestvalidloss -1129.04219  last_update 7\n",
      "train: iter 395  trainloss -1026.90961  validloss -1053.93115±0.00000  bestvalidloss -1129.04219  last_update 8\n",
      "train: iter 396  trainloss -1110.16621  validloss -1076.20369±0.00000  bestvalidloss -1129.04219  last_update 9\n",
      "train: iter 397  trainloss -1078.36168  validloss -1006.20672±0.00000  bestvalidloss -1129.04219  last_update 10\n",
      "train: iter 398  trainloss -1073.74565  validloss -1041.57362±0.00000  bestvalidloss -1129.04219  last_update 11\n",
      "train: iter 399  trainloss -1066.12330  validloss -1122.53737±0.00000  bestvalidloss -1129.04219  last_update 12\n",
      "train: iter 400  trainloss -1062.38472  validloss -1092.02976±0.00000  bestvalidloss -1129.04219  last_update 13\n",
      "train: iter 401  trainloss -1125.78430  validloss -1156.49314±0.00000  bestvalidloss -1156.49314  last_update 0\n",
      "train: iter 402  trainloss -1091.88108  validloss -1088.21934±0.00000  bestvalidloss -1156.49314  last_update 1\n",
      "train: iter 403  trainloss -1068.14006  validloss -1132.62966±0.00000  bestvalidloss -1156.49314  last_update 2\n",
      "train: iter 404  trainloss -1026.73222  validloss -1161.74408±0.00000  bestvalidloss -1161.74408  last_update 0\n",
      "train: iter 405  trainloss -1040.76296  validloss -1075.60926±0.00000  bestvalidloss -1161.74408  last_update 1\n",
      "train: iter 406  trainloss -1010.04341  validloss -1135.47834±0.00000  bestvalidloss -1161.74408  last_update 2\n",
      "train: iter 407  trainloss -1061.38090  validloss -951.88297±0.00000  bestvalidloss -1161.74408  last_update 3\n",
      "train: iter 408  trainloss -951.64408  validloss -1044.41814±0.00000  bestvalidloss -1161.74408  last_update 4\n",
      "train: iter 409  trainloss -980.98637  validloss -1060.96230±0.00000  bestvalidloss -1161.74408  last_update 5\n",
      "train: iter 410  trainloss -951.93793  validloss -794.58075±0.00000  bestvalidloss -1161.74408  last_update 6\n",
      "train: iter 411  trainloss -1069.93378  validloss -1046.92350±0.00000  bestvalidloss -1161.74408  last_update 7\n",
      "train: iter 412  trainloss -1154.86929  validloss -1133.56471±0.00000  bestvalidloss -1161.74408  last_update 8\n",
      "train: iter 413  trainloss -1105.22563  validloss -1134.40377±0.00000  bestvalidloss -1161.74408  last_update 9\n",
      "train: iter 414  trainloss -1186.24798  validloss -1159.86446±0.00000  bestvalidloss -1161.74408  last_update 10\n",
      "train: iter 415  trainloss -869.36470  validloss -1127.52064±0.00000  bestvalidloss -1161.74408  last_update 11\n",
      "train: iter 416  trainloss -782.04075  validloss -460.93523±0.00000  bestvalidloss -1161.74408  last_update 12\n",
      "train: iter 417  trainloss -997.29529  validloss -786.01601±0.00000  bestvalidloss -1161.74408  last_update 13\n",
      "train: iter 418  trainloss -1182.61863  validloss -1099.52935±0.00000  bestvalidloss -1161.74408  last_update 14\n",
      "train: iter 419  trainloss -1144.79048  validloss -1164.17615±0.00000  bestvalidloss -1164.17615  last_update 0\n",
      "train: iter 420  trainloss -994.40625  validloss -1022.25920±0.00000  bestvalidloss -1164.17615  last_update 1\n",
      "train: iter 421  trainloss -1033.81699  validloss -1031.30017±0.00000  bestvalidloss -1164.17615  last_update 2\n",
      "train: iter 422  trainloss -943.63682  validloss -1168.94741±0.00000  bestvalidloss -1168.94741  last_update 0\n",
      "train: iter 423  trainloss -1052.01040  validloss -991.89583±0.00000  bestvalidloss -1168.94741  last_update 1\n",
      "train: iter 424  trainloss -1174.04528  validloss -1165.14352±0.00000  bestvalidloss -1168.94741  last_update 2\n",
      "train: iter 425  trainloss -1061.01188  validloss -1135.15395±0.00000  bestvalidloss -1168.94741  last_update 3\n",
      "train: iter 426  trainloss -1166.05359  validloss -1105.96677±0.00000  bestvalidloss -1168.94741  last_update 4\n",
      "train: iter 427  trainloss -1028.04390  validloss -1128.57735±0.00000  bestvalidloss -1168.94741  last_update 5\n",
      "train: iter 428  trainloss -1137.16822  validloss -1050.81927±0.00000  bestvalidloss -1168.94741  last_update 6\n",
      "train: iter 429  trainloss -1169.45967  validloss -1189.62297±0.00000  bestvalidloss -1189.62297  last_update 0\n",
      "train: iter 430  trainloss -943.65925  validloss -1140.12488±0.00000  bestvalidloss -1189.62297  last_update 1\n",
      "train: iter 431  trainloss -1099.89684  validloss -931.75715±0.00000  bestvalidloss -1189.62297  last_update 2\n",
      "train: iter 432  trainloss -1018.04798  validloss -1161.16686±0.00000  bestvalidloss -1189.62297  last_update 3\n",
      "train: iter 433  trainloss -1111.09007  validloss -1106.01224±0.00000  bestvalidloss -1189.62297  last_update 4\n",
      "train: iter 434  trainloss -1015.60847  validloss -1062.79298±0.00000  bestvalidloss -1189.62297  last_update 5\n",
      "train: iter 435  trainloss -1168.09670  validloss -1044.29057±0.00000  bestvalidloss -1189.62297  last_update 6\n",
      "train: iter 436  trainloss -1119.37581  validloss -1184.78859±0.00000  bestvalidloss -1189.62297  last_update 7\n",
      "train: iter 437  trainloss -1010.70703  validloss -1149.70464±0.00000  bestvalidloss -1189.62297  last_update 8\n",
      "train: iter 438  trainloss -1123.29361  validloss -930.24763±0.00000  bestvalidloss -1189.62297  last_update 9\n",
      "train: iter 439  trainloss -1058.59568  validloss -1150.05304±0.00000  bestvalidloss -1189.62297  last_update 10\n",
      "train: iter 440  trainloss -1108.75503  validloss -981.30982±0.00000  bestvalidloss -1189.62297  last_update 11\n",
      "train: iter 441  trainloss -1048.21584  validloss -1224.58160±0.00000  bestvalidloss -1224.58160  last_update 0\n",
      "train: iter 442  trainloss -1150.54357  validloss -1039.96982±0.00000  bestvalidloss -1224.58160  last_update 1\n",
      "train: iter 443  trainloss -1095.33161  validloss -1148.88149±0.00000  bestvalidloss -1224.58160  last_update 2\n",
      "train: iter 444  trainloss -961.83708  validloss -780.00187±0.00000  bestvalidloss -1224.58160  last_update 3\n",
      "train: iter 445  trainloss -1054.75031  validloss -982.39019±0.00000  bestvalidloss -1224.58160  last_update 4\n",
      "train: iter 446  trainloss -996.77466  validloss -1117.93143±0.00000  bestvalidloss -1224.58160  last_update 5\n",
      "train: iter 447  trainloss -1124.38089  validloss -1082.65172±0.00000  bestvalidloss -1224.58160  last_update 6\n",
      "train: iter 448  trainloss -996.04978  validloss -1044.57443±0.00000  bestvalidloss -1224.58160  last_update 7\n",
      "train: iter 449  trainloss -1158.83216  validloss -943.88057±0.00000  bestvalidloss -1224.58160  last_update 8\n",
      "train: iter 450  trainloss -850.93161  validloss -1187.97090±0.00000  bestvalidloss -1224.58160  last_update 9\n",
      "train: iter 451  trainloss -975.74638  validloss -788.42144±0.00000  bestvalidloss -1224.58160  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 452  trainloss -950.55691  validloss -1067.94958±0.00000  bestvalidloss -1224.58160  last_update 11\n",
      "train: iter 453  trainloss -1142.18727  validloss -1086.34310±0.00000  bestvalidloss -1224.58160  last_update 12\n",
      "train: iter 454  trainloss -1195.18797  validloss -1168.63215±0.00000  bestvalidloss -1224.58160  last_update 13\n",
      "train: iter 455  trainloss -1036.10337  validloss -1173.07448±0.00000  bestvalidloss -1224.58160  last_update 14\n",
      "train: iter 456  trainloss -1208.13272  validloss -1151.79463±0.00000  bestvalidloss -1224.58160  last_update 15\n",
      "train: iter 457  trainloss -1116.07241  validloss -1212.02313±0.00000  bestvalidloss -1224.58160  last_update 16\n",
      "train: iter 458  trainloss -1108.46642  validloss -1119.98064±0.00000  bestvalidloss -1224.58160  last_update 17\n",
      "train: iter 459  trainloss -1218.34348  validloss -1173.92742±0.00000  bestvalidloss -1224.58160  last_update 18\n",
      "train: iter 460  trainloss -1013.27795  validloss -921.33567±0.00000  bestvalidloss -1224.58160  last_update 19\n",
      "train: iter 461  trainloss -982.41139  validloss -472.42449±0.00000  bestvalidloss -1224.58160  last_update 20\n",
      "train: iter 462  trainloss -1225.08857  validloss -1198.23339±0.00000  bestvalidloss -1224.58160  last_update 21\n",
      "train: iter 463  trainloss -1278.05828  validloss -1242.70077±0.00000  bestvalidloss -1242.70077  last_update 0\n",
      "train: iter 464  trainloss -1145.04867  validloss -1269.62009±0.00000  bestvalidloss -1269.62009  last_update 0\n",
      "train: iter 465  trainloss -1218.53773  validloss -1138.75802±0.00000  bestvalidloss -1269.62009  last_update 1\n",
      "train: iter 466  trainloss -1221.63033  validloss -1166.82804±0.00000  bestvalidloss -1269.62009  last_update 2\n",
      "train: iter 467  trainloss -1177.66899  validloss -1223.08499±0.00000  bestvalidloss -1269.62009  last_update 3\n",
      "train: iter 468  trainloss -1225.05107  validloss -1244.93354±0.00000  bestvalidloss -1269.62009  last_update 4\n",
      "train: iter 469  trainloss -1106.30185  validloss -1159.39160±0.00000  bestvalidloss -1269.62009  last_update 5\n",
      "train: iter 470  trainloss -1144.41282  validloss -985.59741±0.00000  bestvalidloss -1269.62009  last_update 6\n",
      "train: iter 471  trainloss -1224.65776  validloss -1172.81434±0.00000  bestvalidloss -1269.62009  last_update 7\n",
      "train: iter 472  trainloss -1096.03106  validloss -1271.47978±0.00000  bestvalidloss -1271.47978  last_update 0\n",
      "train: iter 473  trainloss -1040.49034  validloss -1123.11855±0.00000  bestvalidloss -1271.47978  last_update 1\n",
      "train: iter 474  trainloss -1144.54293  validloss -896.90300±0.00000  bestvalidloss -1271.47978  last_update 2\n",
      "train: iter 475  trainloss -1198.51257  validloss -1202.74294±0.00000  bestvalidloss -1271.47978  last_update 3\n",
      "train: iter 476  trainloss -1064.43303  validloss -1187.53481±0.00000  bestvalidloss -1271.47978  last_update 4\n",
      "train: iter 477  trainloss -1260.12644  validloss -1192.99293±0.00000  bestvalidloss -1271.47978  last_update 5\n",
      "train: iter 478  trainloss -1243.95831  validloss -1240.96697±0.00000  bestvalidloss -1271.47978  last_update 6\n",
      "train: iter 479  trainloss -1212.52052  validloss -1189.21134±0.00000  bestvalidloss -1271.47978  last_update 7\n",
      "train: iter 480  trainloss -1148.52720  validloss -1213.29778±0.00000  bestvalidloss -1271.47978  last_update 8\n",
      "train: iter 481  trainloss -1227.77264  validloss -1096.59444±0.00000  bestvalidloss -1271.47978  last_update 9\n",
      "train: iter 482  trainloss -1107.78142  validloss -1261.03949±0.00000  bestvalidloss -1271.47978  last_update 10\n",
      "train: iter 483  trainloss -1235.83842  validloss -1219.18283±0.00000  bestvalidloss -1271.47978  last_update 11\n",
      "train: iter 484  trainloss -1185.01366  validloss -1225.28989±0.00000  bestvalidloss -1271.47978  last_update 12\n",
      "train: iter 485  trainloss -1186.13382  validloss -1169.21623±0.00000  bestvalidloss -1271.47978  last_update 13\n",
      "train: iter 486  trainloss -1206.06264  validloss -1249.41781±0.00000  bestvalidloss -1271.47978  last_update 14\n",
      "train: iter 487  trainloss -1248.66123  validloss -1233.99121±0.00000  bestvalidloss -1271.47978  last_update 15\n",
      "train: iter 488  trainloss -63.26038  validloss -1085.11762±0.00000  bestvalidloss -1271.47978  last_update 16\n",
      "train: iter 489  trainloss -638.40955  validloss -481.48433±0.00000  bestvalidloss -1271.47978  last_update 17\n",
      "train: iter 490  trainloss -848.61743  validloss -635.91423±0.00000  bestvalidloss -1271.47978  last_update 18\n",
      "train: iter 491  trainloss -982.69777  validloss -1015.67169±0.00000  bestvalidloss -1271.47978  last_update 19\n",
      "train: iter 492  trainloss -921.78391  validloss -693.65034±0.00000  bestvalidloss -1271.47978  last_update 20\n",
      "train: iter 493  trainloss -1093.17678  validloss -1101.45368±0.00000  bestvalidloss -1271.47978  last_update 21\n",
      "train: iter 494  trainloss -1178.56109  validloss -1149.62769±0.00000  bestvalidloss -1271.47978  last_update 22\n",
      "train: iter 495  trainloss -1220.70361  validloss -1202.19773±0.00000  bestvalidloss -1271.47978  last_update 23\n",
      "train: iter 496  trainloss -1053.91878  validloss -1059.55604±0.00000  bestvalidloss -1271.47978  last_update 24\n",
      "train: iter 497  trainloss -1196.37774  validloss -1125.06046±0.00000  bestvalidloss -1271.47978  last_update 25\n",
      "train: iter 498  trainloss -1184.70309  validloss -1202.21577±0.00000  bestvalidloss -1271.47978  last_update 26\n",
      "train: iter 499  trainloss -1206.77582  validloss -1150.54951±0.00000  bestvalidloss -1271.47978  last_update 27\n",
      "train: iter 500  trainloss -1115.44459  validloss -1217.47132±0.00000  bestvalidloss -1271.47978  last_update 28\n",
      "train: iter 501  trainloss -1246.40522  validloss -1127.18101±0.00000  bestvalidloss -1271.47978  last_update 29\n",
      "train: iter 502  trainloss -1267.71498  validloss -1266.10864±0.00000  bestvalidloss -1271.47978  last_update 30\n",
      "train: iter 503  trainloss -1110.67786  validloss -1242.81821±0.00000  bestvalidloss -1271.47978  last_update 31\n",
      "train: iter 504  trainloss -1249.21270  validloss -1203.45898±0.00000  bestvalidloss -1271.47978  last_update 32\n",
      "train: iter 505  trainloss -1164.92875  validloss -1293.50684±0.00000  bestvalidloss -1293.50684  last_update 0\n",
      "train: iter 506  trainloss -1102.36458  validloss -1149.33524±0.00000  bestvalidloss -1293.50684  last_update 1\n",
      "train: iter 507  trainloss -1231.73678  validloss -1236.04592±0.00000  bestvalidloss -1293.50684  last_update 2\n",
      "train: iter 508  trainloss -1277.17094  validloss -1229.94066±0.00000  bestvalidloss -1293.50684  last_update 3\n",
      "train: iter 509  trainloss -1254.71083  validloss -1201.94603±0.00000  bestvalidloss -1293.50684  last_update 4\n",
      "train: iter 510  trainloss -1271.39100  validloss -1245.63461±0.00000  bestvalidloss -1293.50684  last_update 5\n",
      "train: iter 511  trainloss -1054.27524  validloss -1140.49646±0.00000  bestvalidloss -1293.50684  last_update 6\n",
      "train: iter 512  trainloss -1250.94866  validloss -1258.26687±0.00000  bestvalidloss -1293.50684  last_update 7\n",
      "train: iter 513  trainloss -1309.17924  validloss -1222.83545±0.00000  bestvalidloss -1293.50684  last_update 8\n",
      "train: iter 514  trainloss -1287.83779  validloss -1303.13265±0.00000  bestvalidloss -1303.13265  last_update 0\n",
      "train: iter 515  trainloss -922.15187  validloss -1286.42945±0.00000  bestvalidloss -1303.13265  last_update 1\n",
      "train: iter 516  trainloss -1180.34218  validloss -956.79277±0.00000  bestvalidloss -1303.13265  last_update 2\n",
      "train: iter 517  trainloss -1190.46196  validloss -1074.43099±0.00000  bestvalidloss -1303.13265  last_update 3\n",
      "train: iter 518  trainloss -1292.87883  validloss -1284.98380±0.00000  bestvalidloss -1303.13265  last_update 4\n",
      "train: iter 519  trainloss -1223.65999  validloss -1249.40776±0.00000  bestvalidloss -1303.13265  last_update 5\n",
      "train: iter 520  trainloss -1299.84901  validloss -1253.72247±0.00000  bestvalidloss -1303.13265  last_update 6\n",
      "train: iter 521  trainloss -1257.19962  validloss -1274.90962±0.00000  bestvalidloss -1303.13265  last_update 7\n",
      "train: iter 522  trainloss -993.78212  validloss -1148.28059±0.00000  bestvalidloss -1303.13265  last_update 8\n",
      "train: iter 523  trainloss -1174.63248  validloss -1018.39048±0.00000  bestvalidloss -1303.13265  last_update 9\n",
      "train: iter 524  trainloss -1285.65960  validloss -1237.39440±0.00000  bestvalidloss -1303.13265  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 525  trainloss -1301.26437  validloss -1292.06106±0.00000  bestvalidloss -1303.13265  last_update 11\n",
      "train: iter 526  trainloss -1301.52552  validloss -1305.33428±0.00000  bestvalidloss -1305.33428  last_update 0\n",
      "train: iter 527  trainloss -837.27979  validloss -1186.49875±0.00000  bestvalidloss -1305.33428  last_update 1\n",
      "train: iter 528  trainloss -1210.58864  validloss -1080.65771±0.00000  bestvalidloss -1305.33428  last_update 2\n",
      "train: iter 529  trainloss -1251.08563  validloss -1302.28101±0.00000  bestvalidloss -1305.33428  last_update 3\n",
      "train: iter 530  trainloss -1244.41993  validloss -1263.07276±0.00000  bestvalidloss -1305.33428  last_update 4\n",
      "train: iter 531  trainloss -1183.98720  validloss -799.25434±0.00000  bestvalidloss -1305.33428  last_update 5\n",
      "train: iter 532  trainloss -1195.61209  validloss -1075.73722±0.00000  bestvalidloss -1305.33428  last_update 6\n",
      "train: iter 533  trainloss -1248.20767  validloss -1171.87796±0.00000  bestvalidloss -1305.33428  last_update 7\n",
      "train: iter 534  trainloss -1297.75694  validloss -1245.62321±0.00000  bestvalidloss -1305.33428  last_update 8\n",
      "train: iter 535  trainloss -1053.06678  validloss -1273.26744±0.00000  bestvalidloss -1305.33428  last_update 9\n",
      "train: iter 536  trainloss -1044.06363  validloss -1225.55961±0.00000  bestvalidloss -1305.33428  last_update 10\n",
      "train: iter 537  trainloss -1260.16216  validloss -1194.39651±0.00000  bestvalidloss -1305.33428  last_update 11\n",
      "train: iter 538  trainloss -1254.73487  validloss -1278.34120±0.00000  bestvalidloss -1305.33428  last_update 12\n",
      "train: iter 539  trainloss -1072.49474  validloss -1305.13617±0.00000  bestvalidloss -1305.33428  last_update 13\n",
      "train: iter 540  trainloss -1211.58943  validloss -1066.24873±0.00000  bestvalidloss -1305.33428  last_update 14\n",
      "train: iter 541  trainloss -1322.05926  validloss -1301.19259±0.00000  bestvalidloss -1305.33428  last_update 15\n",
      "train: iter 542  trainloss -1311.53419  validloss -1258.81110±0.00000  bestvalidloss -1305.33428  last_update 16\n",
      "train: iter 543  trainloss -1246.51540  validloss -1241.98738±0.00000  bestvalidloss -1305.33428  last_update 17\n",
      "train: iter 544  trainloss -1267.37823  validloss -1242.31663±0.00000  bestvalidloss -1305.33428  last_update 18\n",
      "train: iter 545  trainloss -1257.01412  validloss -1287.82813±0.00000  bestvalidloss -1305.33428  last_update 19\n",
      "train: iter 546  trainloss -801.24341  validloss -607.47254±0.00000  bestvalidloss -1305.33428  last_update 20\n",
      "train: iter 547  trainloss -1054.34999  validloss -823.90164±0.00000  bestvalidloss -1305.33428  last_update 21\n",
      "train: iter 548  trainloss -1307.91904  validloss -1214.80316±0.00000  bestvalidloss -1305.33428  last_update 22\n",
      "train: iter 549  trainloss -1335.28866  validloss -1319.48974±0.00000  bestvalidloss -1319.48974  last_update 0\n",
      "train: iter 550  trainloss -1044.37029  validloss -1252.75287±0.00000  bestvalidloss -1319.48974  last_update 1\n",
      "train: iter 551  trainloss -1270.60097  validloss -1057.85618±0.00000  bestvalidloss -1319.48974  last_update 2\n",
      "train: iter 552  trainloss -1327.20763  validloss -1333.50573±0.00000  bestvalidloss -1333.50573  last_update 0\n",
      "train: iter 553  trainloss -1174.14068  validloss -1303.81692±0.00000  bestvalidloss -1333.50573  last_update 1\n",
      "train: iter 554  trainloss -1183.46789  validloss -1105.81122±0.00000  bestvalidloss -1333.50573  last_update 2\n",
      "train: iter 555  trainloss -1254.12692  validloss -1232.66094±0.00000  bestvalidloss -1333.50573  last_update 3\n",
      "train: iter 556  trainloss -1308.54704  validloss -1231.88833±0.00000  bestvalidloss -1333.50573  last_update 4\n",
      "train: iter 557  trainloss -957.95236  validloss -1003.41534±0.00000  bestvalidloss -1333.50573  last_update 5\n",
      "train: iter 558  trainloss -1325.06401  validloss -1247.80296±0.00000  bestvalidloss -1333.50573  last_update 6\n",
      "train: iter 559  trainloss -1214.41964  validloss -1298.47497±0.00000  bestvalidloss -1333.50573  last_update 7\n",
      "train: iter 560  trainloss -1271.77113  validloss -1136.24076±0.00000  bestvalidloss -1333.50573  last_update 8\n",
      "train: iter 561  trainloss -1336.76158  validloss -1309.05207±0.00000  bestvalidloss -1333.50573  last_update 9\n",
      "train: iter 562  trainloss -1287.75438  validloss -1279.88172±0.00000  bestvalidloss -1333.50573  last_update 10\n",
      "train: iter 563  trainloss -973.27034  validloss -941.04529±0.00000  bestvalidloss -1333.50573  last_update 11\n",
      "train: iter 564  trainloss -1093.38809  validloss -1224.41352±0.00000  bestvalidloss -1333.50573  last_update 12\n",
      "train: iter 565  trainloss -1101.31552  validloss -1198.48149±0.00000  bestvalidloss -1333.50573  last_update 13\n",
      "train: iter 566  trainloss -1335.16901  validloss -1292.68189±0.00000  bestvalidloss -1333.50573  last_update 14\n",
      "train: iter 567  trainloss -1322.62109  validloss -1359.56598±0.00000  bestvalidloss -1359.56598  last_update 0\n",
      "train: iter 568  trainloss -1341.29636  validloss -1349.99683±0.00000  bestvalidloss -1359.56598  last_update 1\n",
      "train: iter 569  trainloss -1110.93367  validloss -1268.52633±0.00000  bestvalidloss -1359.56598  last_update 2\n",
      "train: iter 570  trainloss -1294.17521  validloss -1212.25036±0.00000  bestvalidloss -1359.56598  last_update 3\n",
      "train: iter 571  trainloss -1308.51541  validloss -1327.29110±0.00000  bestvalidloss -1359.56598  last_update 4\n",
      "train: iter 572  trainloss -1124.24106  validloss -1216.11166±0.00000  bestvalidloss -1359.56598  last_update 5\n",
      "train: iter 573  trainloss -1306.07396  validloss -1300.57190±0.00000  bestvalidloss -1359.56598  last_update 6\n",
      "train: iter 574  trainloss -1234.47873  validloss -1304.77839±0.00000  bestvalidloss -1359.56598  last_update 7\n",
      "train: iter 575  trainloss -1292.20708  validloss -1211.23969±0.00000  bestvalidloss -1359.56598  last_update 8\n",
      "train: iter 576  trainloss -1373.63344  validloss -1363.91973±0.00000  bestvalidloss -1363.91973  last_update 0\n",
      "train: iter 577  trainloss -1027.00443  validloss -1221.89426±0.00000  bestvalidloss -1363.91973  last_update 1\n",
      "train: iter 578  trainloss -1240.07830  validloss -1001.31312±0.00000  bestvalidloss -1363.91973  last_update 2\n",
      "train: iter 579  trainloss -1234.41366  validloss -1262.87201±0.00000  bestvalidloss -1363.91973  last_update 3\n",
      "train: iter 580  trainloss -1228.03683  validloss -1102.39601±0.00000  bestvalidloss -1363.91973  last_update 4\n",
      "train: iter 581  trainloss -1352.94499  validloss -1275.18616±0.00000  bestvalidloss -1363.91973  last_update 5\n",
      "train: iter 582  trainloss -295.84116  validloss -1225.97433±0.00000  bestvalidloss -1363.91973  last_update 6\n",
      "train: iter 583  trainloss -1034.75649  validloss -804.72410±0.00000  bestvalidloss -1363.91973  last_update 7\n",
      "train: iter 584  trainloss -1139.68269  validloss -1161.52733±0.00000  bestvalidloss -1363.91973  last_update 8\n",
      "train: iter 585  trainloss -1313.97744  validloss -1266.13616±0.00000  bestvalidloss -1363.91973  last_update 9\n",
      "train: iter 586  trainloss -1341.68418  validloss -1309.85541±0.00000  bestvalidloss -1363.91973  last_update 10\n",
      "train: iter 587  trainloss -1348.67811  validloss -1336.75825±0.00000  bestvalidloss -1363.91973  last_update 11\n",
      "train: iter 588  trainloss -1240.40139  validloss -1335.42042±0.00000  bestvalidloss -1363.91973  last_update 12\n",
      "train: iter 589  trainloss -1307.64219  validloss -1204.87688±0.00000  bestvalidloss -1363.91973  last_update 13\n",
      "train: iter 590  trainloss -1296.49281  validloss -1335.98785±0.00000  bestvalidloss -1363.91973  last_update 14\n",
      "train: iter 591  trainloss -1304.71297  validloss -1136.68474±0.00000  bestvalidloss -1363.91973  last_update 15\n",
      "train: iter 592  trainloss -1209.40178  validloss -1346.47446±0.00000  bestvalidloss -1363.91973  last_update 16\n",
      "train: iter 593  trainloss -1324.14641  validloss -1304.12585±0.00000  bestvalidloss -1363.91973  last_update 17\n",
      "train: iter 594  trainloss -1255.89972  validloss -1350.56181±0.00000  bestvalidloss -1363.91973  last_update 18\n",
      "train: iter 595  trainloss -1329.71857  validloss -1278.09886±0.00000  bestvalidloss -1363.91973  last_update 19\n",
      "train: iter 596  trainloss -1263.04308  validloss -1279.11506±0.00000  bestvalidloss -1363.91973  last_update 20\n",
      "train: iter 597  trainloss -1294.79603  validloss -1281.32464±0.00000  bestvalidloss -1363.91973  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 598  trainloss -1223.98154  validloss -1296.67808±0.00000  bestvalidloss -1363.91973  last_update 22\n",
      "train: iter 599  trainloss -1328.01032  validloss -1191.62370±0.00000  bestvalidloss -1363.91973  last_update 23\n",
      "train: iter 600  trainloss -1129.24716  validloss -736.99544±0.00000  bestvalidloss -1363.91973  last_update 24\n",
      "train: iter 601  trainloss -1243.92633  validloss -1306.94865±0.00000  bestvalidloss -1363.91973  last_update 25\n",
      "train: iter 602  trainloss -1337.55273  validloss -1259.52564±0.00000  bestvalidloss -1363.91973  last_update 26\n",
      "train: iter 603  trainloss -1190.39880  validloss -1371.95710±0.00000  bestvalidloss -1371.95710  last_update 0\n",
      "train: iter 604  trainloss -1274.46194  validloss -1304.20790±0.00000  bestvalidloss -1371.95710  last_update 1\n",
      "train: iter 605  trainloss -1211.52413  validloss -1215.40157±0.00000  bestvalidloss -1371.95710  last_update 2\n",
      "train: iter 606  trainloss -1355.44109  validloss -1321.24082±0.00000  bestvalidloss -1371.95710  last_update 3\n",
      "train: iter 607  trainloss -1307.45800  validloss -1340.02718±0.00000  bestvalidloss -1371.95710  last_update 4\n",
      "train: iter 608  trainloss -1374.58367  validloss -1365.14158±0.00000  bestvalidloss -1371.95710  last_update 5\n",
      "train: iter 609  trainloss -1273.84907  validloss -1289.35034±0.00000  bestvalidloss -1371.95710  last_update 6\n",
      "train: iter 610  trainloss -1286.49146  validloss -1132.25561±0.00000  bestvalidloss -1371.95710  last_update 7\n",
      "train: iter 611  trainloss -1315.21713  validloss -1352.15339±0.00000  bestvalidloss -1371.95710  last_update 8\n",
      "train: iter 612  trainloss -1300.85430  validloss -1299.43860±0.00000  bestvalidloss -1371.95710  last_update 9\n",
      "train: iter 613  trainloss -1262.80898  validloss -1300.87643±0.00000  bestvalidloss -1371.95710  last_update 10\n",
      "train: iter 614  trainloss -1372.96854  validloss -1356.74152±0.00000  bestvalidloss -1371.95710  last_update 11\n",
      "train: iter 615  trainloss -1326.08275  validloss -1203.62262±0.00000  bestvalidloss -1371.95710  last_update 12\n",
      "train: iter 616  trainloss -784.05265  validloss -1378.67603±0.00000  bestvalidloss -1378.67603  last_update 0\n",
      "train: iter 617  trainloss -1057.50543  validloss -1023.54960±0.00000  bestvalidloss -1378.67603  last_update 1\n",
      "train: iter 618  trainloss -1265.21972  validloss -1125.19463±0.00000  bestvalidloss -1378.67603  last_update 2\n",
      "train: iter 619  trainloss -1378.49923  validloss -1344.52986±0.00000  bestvalidloss -1378.67603  last_update 3\n",
      "train: iter 620  trainloss -1315.58300  validloss -1386.61283±0.00000  bestvalidloss -1386.61283  last_update 0\n",
      "train: iter 621  trainloss -1269.33662  validloss -1232.93200±0.00000  bestvalidloss -1386.61283  last_update 1\n",
      "train: iter 622  trainloss -1294.61411  validloss -1258.30987±0.00000  bestvalidloss -1386.61283  last_update 2\n",
      "train: iter 623  trainloss -979.85507  validloss -1350.02544±0.00000  bestvalidloss -1386.61283  last_update 3\n",
      "train: iter 624  trainloss -1215.22871  validloss -1083.75597±0.00000  bestvalidloss -1386.61283  last_update 4\n",
      "train: iter 625  trainloss -1310.46957  validloss -1333.33661±0.00000  bestvalidloss -1386.61283  last_update 5\n",
      "train: iter 626  trainloss -1151.22375  validloss -1283.63832±0.00000  bestvalidloss -1386.61283  last_update 6\n",
      "train: iter 627  trainloss -1290.42182  validloss -1320.00239±0.00000  bestvalidloss -1386.61283  last_update 7\n",
      "train: iter 628  trainloss -1353.24981  validloss -1329.58287±0.00000  bestvalidloss -1386.61283  last_update 8\n",
      "train: iter 629  trainloss -1325.40363  validloss -1359.35087±0.00000  bestvalidloss -1386.61283  last_update 9\n",
      "train: iter 630  trainloss -1132.60135  validloss -1206.61137±0.00000  bestvalidloss -1386.61283  last_update 10\n",
      "train: iter 631  trainloss -1300.96025  validloss -1224.49127±0.00000  bestvalidloss -1386.61283  last_update 11\n",
      "train: iter 632  trainloss -1349.84604  validloss -1325.46279±0.00000  bestvalidloss -1386.61283  last_update 12\n",
      "train: iter 633  trainloss -1351.70426  validloss -1266.04311±0.00000  bestvalidloss -1386.61283  last_update 13\n",
      "train: iter 634  trainloss -1286.87929  validloss -1327.90461±0.00000  bestvalidloss -1386.61283  last_update 14\n",
      "train: iter 635  trainloss -1326.73382  validloss -1062.65541±0.00000  bestvalidloss -1386.61283  last_update 15\n",
      "train: iter 636  trainloss -1239.49673  validloss -1334.83124±0.00000  bestvalidloss -1386.61283  last_update 16\n",
      "train: iter 637  trainloss -1332.65506  validloss -1379.14552±0.00000  bestvalidloss -1386.61283  last_update 17\n",
      "train: iter 638  trainloss -1308.36895  validloss -1331.28670±0.00000  bestvalidloss -1386.61283  last_update 18\n",
      "train: iter 639  trainloss -1350.82314  validloss -1367.30178±0.00000  bestvalidloss -1386.61283  last_update 19\n",
      "train: iter 640  trainloss -1276.74296  validloss -1323.06102±0.00000  bestvalidloss -1386.61283  last_update 20\n",
      "train: iter 641  trainloss -1328.76823  validloss -1273.77590±0.00000  bestvalidloss -1386.61283  last_update 21\n",
      "train: iter 642  trainloss -1351.80455  validloss -1189.37795±0.00000  bestvalidloss -1386.61283  last_update 22\n",
      "train: iter 643  trainloss -1176.72181  validloss -1386.75137±0.00000  bestvalidloss -1386.75137  last_update 0\n",
      "train: iter 644  trainloss -1335.64760  validloss -1255.01284±0.00000  bestvalidloss -1386.75137  last_update 1\n",
      "train: iter 645  trainloss -1406.45993  validloss -1376.53939±0.00000  bestvalidloss -1386.75137  last_update 2\n",
      "train: iter 646  trainloss -1345.23639  validloss -1355.60977±0.00000  bestvalidloss -1386.75137  last_update 3\n",
      "train: iter 647  trainloss -1186.47244  validloss -1340.85140±0.00000  bestvalidloss -1386.75137  last_update 4\n",
      "train: iter 648  trainloss -1339.75282  validloss -1193.72983±0.00000  bestvalidloss -1386.75137  last_update 5\n",
      "train: iter 649  trainloss -1310.84826  validloss -1350.01661±0.00000  bestvalidloss -1386.75137  last_update 6\n",
      "train: iter 650  trainloss -1230.84163  validloss -1280.02887±0.00000  bestvalidloss -1386.75137  last_update 7\n",
      "train: iter 651  trainloss -1235.24137  validloss -1347.76342±0.00000  bestvalidloss -1386.75137  last_update 8\n",
      "train: iter 652  trainloss -1133.40843  validloss -1055.53286±0.00000  bestvalidloss -1386.75137  last_update 9\n",
      "train: iter 653  trainloss -944.82003  validloss -369.02338±0.00000  bestvalidloss -1386.75137  last_update 10\n",
      "train: iter 654  trainloss -1257.43255  validloss -1255.41310±0.00000  bestvalidloss -1386.75137  last_update 11\n",
      "train: iter 655  trainloss -1313.20876  validloss -1309.89375±0.00000  bestvalidloss -1386.75137  last_update 12\n",
      "train: iter 656  trainloss -1127.39270  validloss -1335.58623±0.00000  bestvalidloss -1386.75137  last_update 13\n",
      "train: iter 657  trainloss -1254.96267  validloss -1078.53872±0.00000  bestvalidloss -1386.75137  last_update 14\n",
      "train: iter 658  trainloss -1381.33394  validloss -1353.02255±0.00000  bestvalidloss -1386.75137  last_update 15\n",
      "train: iter 659  trainloss -1197.47956  validloss -1391.53401±0.00000  bestvalidloss -1391.53401  last_update 0\n",
      "train: iter 660  trainloss -1178.86900  validloss -1081.90273±0.00000  bestvalidloss -1391.53401  last_update 1\n",
      "train: iter 661  trainloss -1256.13582  validloss -900.92442±0.00000  bestvalidloss -1391.53401  last_update 2\n",
      "train: iter 662  trainloss -1362.45691  validloss -1370.66769±0.00000  bestvalidloss -1391.53401  last_update 3\n",
      "train: iter 663  trainloss -1324.06783  validloss -1290.35128±0.00000  bestvalidloss -1391.53401  last_update 4\n",
      "train: iter 664  trainloss -1337.99913  validloss -1341.61418±0.00000  bestvalidloss -1391.53401  last_update 5\n",
      "train: iter 665  trainloss -1316.35005  validloss -1275.98820±0.00000  bestvalidloss -1391.53401  last_update 6\n",
      "train: iter 666  trainloss -1350.93278  validloss -1377.53983±0.00000  bestvalidloss -1391.53401  last_update 7\n",
      "train: iter 667  trainloss -1363.90644  validloss -1283.45272±0.00000  bestvalidloss -1391.53401  last_update 8\n",
      "train: iter 668  trainloss -1254.97428  validloss -1347.37252±0.00000  bestvalidloss -1391.53401  last_update 9\n",
      "train: iter 669  trainloss -1168.19118  validloss -1057.47512±0.00000  bestvalidloss -1391.53401  last_update 10\n",
      "train: iter 670  trainloss -1332.32691  validloss -1262.44203±0.00000  bestvalidloss -1391.53401  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 671  trainloss -1341.86378  validloss -1365.60113±0.00000  bestvalidloss -1391.53401  last_update 12\n",
      "train: iter 672  trainloss -1324.43903  validloss -1224.56446±0.00000  bestvalidloss -1391.53401  last_update 13\n",
      "train: iter 673  trainloss -1318.87863  validloss -1376.66312±0.00000  bestvalidloss -1391.53401  last_update 14\n",
      "train: iter 674  trainloss -1270.69890  validloss -999.18773±0.00000  bestvalidloss -1391.53401  last_update 15\n",
      "train: iter 675  trainloss -1385.71217  validloss -1363.72581±0.00000  bestvalidloss -1391.53401  last_update 16\n",
      "train: iter 676  trainloss -1250.06202  validloss -1214.45684±0.00000  bestvalidloss -1391.53401  last_update 17\n",
      "train: iter 677  trainloss -1139.81387  validloss -1379.31643±0.00000  bestvalidloss -1391.53401  last_update 18\n",
      "train: iter 678  trainloss -1175.81494  validloss -1176.94470±0.00000  bestvalidloss -1391.53401  last_update 19\n",
      "train: iter 679  trainloss -1352.55191  validloss -1326.43863±0.00000  bestvalidloss -1391.53401  last_update 20\n",
      "train: iter 680  trainloss -1350.90660  validloss -1309.80038±0.00000  bestvalidloss -1391.53401  last_update 21\n",
      "train: iter 681  trainloss -1224.57894  validloss -1349.46768±0.00000  bestvalidloss -1391.53401  last_update 22\n",
      "train: iter 682  trainloss -1217.28997  validloss -1180.42143±0.00000  bestvalidloss -1391.53401  last_update 23\n",
      "train: iter 683  trainloss -1338.33758  validloss -1362.90000±0.00000  bestvalidloss -1391.53401  last_update 24\n",
      "train: iter 684  trainloss -1065.30122  validloss -916.11864±0.00000  bestvalidloss -1391.53401  last_update 25\n",
      "train: iter 685  trainloss -1283.18806  validloss -1255.24208±0.00000  bestvalidloss -1391.53401  last_update 26\n",
      "train: iter 686  trainloss -1364.22202  validloss -1304.04944±0.00000  bestvalidloss -1391.53401  last_update 27\n",
      "train: iter 687  trainloss -1372.82412  validloss -1364.52752±0.00000  bestvalidloss -1391.53401  last_update 28\n",
      "train: iter 688  trainloss -1362.10145  validloss -1361.64691±0.00000  bestvalidloss -1391.53401  last_update 29\n",
      "train: iter 689  trainloss -1409.00947  validloss -1333.79111±0.00000  bestvalidloss -1391.53401  last_update 30\n",
      "train: iter 690  trainloss -1331.92762  validloss -1422.63961±0.00000  bestvalidloss -1422.63961  last_update 0\n",
      "train: iter 691  trainloss -983.86318  validloss -772.84116±0.00000  bestvalidloss -1422.63961  last_update 1\n",
      "train: iter 692  trainloss -1343.67694  validloss -1281.34943±0.00000  bestvalidloss -1422.63961  last_update 2\n",
      "train: iter 693  trainloss -1369.62475  validloss -1381.64848±0.00000  bestvalidloss -1422.63961  last_update 3\n",
      "train: iter 694  trainloss -1427.42388  validloss -1395.96931±0.00000  bestvalidloss -1422.63961  last_update 4\n",
      "train: iter 695  trainloss -1334.85171  validloss -1416.70690±0.00000  bestvalidloss -1422.63961  last_update 5\n",
      "train: iter 696  trainloss -1229.96723  validloss -1212.81875±0.00000  bestvalidloss -1422.63961  last_update 6\n",
      "train: iter 697  trainloss -1343.32651  validloss -1184.09675±0.00000  bestvalidloss -1422.63961  last_update 7\n",
      "train: iter 698  trainloss -1259.28770  validloss -1263.39217±0.00000  bestvalidloss -1422.63961  last_update 8\n",
      "train: iter 699  trainloss -1333.38656  validloss -1377.59899±0.00000  bestvalidloss -1422.63961  last_update 9\n",
      "train: iter 700  trainloss -1359.39666  validloss -1277.51017±0.00000  bestvalidloss -1422.63961  last_update 10\n",
      "train: iter 701  trainloss -1392.67743  validloss -1382.81484±0.00000  bestvalidloss -1422.63961  last_update 11\n",
      "train: iter 702  trainloss -1318.53889  validloss -1360.72316±0.00000  bestvalidloss -1422.63961  last_update 12\n",
      "train: iter 703  trainloss -1220.38120  validloss -1081.38403±0.00000  bestvalidloss -1422.63961  last_update 13\n",
      "train: iter 704  trainloss -1325.69934  validloss -1261.68581±0.00000  bestvalidloss -1422.63961  last_update 14\n",
      "train: iter 705  trainloss -1392.81852  validloss -1385.94166±0.00000  bestvalidloss -1422.63961  last_update 15\n",
      "train: iter 706  trainloss -1362.95347  validloss -1351.27640±0.00000  bestvalidloss -1422.63961  last_update 16\n",
      "train: iter 707  trainloss -1307.20413  validloss -1355.80918±0.00000  bestvalidloss -1422.63961  last_update 17\n",
      "train: iter 708  trainloss -1316.87628  validloss -1351.18917±0.00000  bestvalidloss -1422.63961  last_update 18\n",
      "train: iter 709  trainloss -1273.76451  validloss -793.49330±0.00000  bestvalidloss -1422.63961  last_update 19\n",
      "train: iter 710  trainloss -1311.77819  validloss -1322.12560±0.00000  bestvalidloss -1422.63961  last_update 20\n",
      "train: iter 711  trainloss -1193.07578  validloss -1356.73559±0.00000  bestvalidloss -1422.63961  last_update 21\n",
      "train: iter 712  trainloss -1191.25677  validloss -1290.44261±0.00000  bestvalidloss -1422.63961  last_update 22\n",
      "train: iter 713  trainloss -1389.78309  validloss -1329.15888±0.00000  bestvalidloss -1422.63961  last_update 23\n",
      "train: iter 714  trainloss -1391.39519  validloss -1391.37217±0.00000  bestvalidloss -1422.63961  last_update 24\n",
      "train: iter 715  trainloss -1324.68355  validloss -1379.64492±0.00000  bestvalidloss -1422.63961  last_update 25\n",
      "train: iter 716  trainloss -1295.40719  validloss -1181.06036±0.00000  bestvalidloss -1422.63961  last_update 26\n",
      "train: iter 717  trainloss -1321.58477  validloss -1328.64624±0.00000  bestvalidloss -1422.63961  last_update 27\n",
      "train: iter 718  trainloss -1362.36993  validloss -1353.79075±0.00000  bestvalidloss -1422.63961  last_update 28\n",
      "train: iter 719  trainloss -1305.16585  validloss -1388.87060±0.00000  bestvalidloss -1422.63961  last_update 29\n",
      "train: iter 720  trainloss -1175.89771  validloss -999.56563±0.00000  bestvalidloss -1422.63961  last_update 30\n",
      "train: iter 721  trainloss -1275.15007  validloss -1252.22240±0.00000  bestvalidloss -1422.63961  last_update 31\n",
      "train: iter 722  trainloss -1421.24142  validloss -1375.05396±0.00000  bestvalidloss -1422.63961  last_update 32\n",
      "train: iter 723  trainloss -1292.20800  validloss -1369.07787±0.00000  bestvalidloss -1422.63961  last_update 33\n",
      "train: iter 724  trainloss -1353.69410  validloss -1299.44490±0.00000  bestvalidloss -1422.63961  last_update 34\n",
      "train: iter 725  trainloss -1360.16943  validloss -1361.59844±0.00000  bestvalidloss -1422.63961  last_update 35\n",
      "train: iter 726  trainloss -1306.90573  validloss -1346.72740±0.00000  bestvalidloss -1422.63961  last_update 36\n",
      "train: iter 727  trainloss -1288.63703  validloss -1057.99231±0.00000  bestvalidloss -1422.63961  last_update 37\n",
      "train: iter 728  trainloss -1273.75192  validloss -1333.33122±0.00000  bestvalidloss -1422.63961  last_update 38\n",
      "train: iter 729  trainloss -1325.30223  validloss -1277.80701±0.00000  bestvalidloss -1422.63961  last_update 39\n",
      "train: iter 730  trainloss -1375.67513  validloss -1225.57601±0.00000  bestvalidloss -1422.63961  last_update 40\n",
      "train: iter 731  trainloss -1350.79331  validloss -1407.54176±0.00000  bestvalidloss -1422.63961  last_update 41\n",
      "train: iter 732  trainloss -1279.59806  validloss -1204.94220±0.00000  bestvalidloss -1422.63961  last_update 42\n",
      "train: iter 733  trainloss -1413.71069  validloss -1388.69556±0.00000  bestvalidloss -1422.63961  last_update 43\n",
      "train: iter 734  trainloss -1400.71936  validloss -1427.39432±0.00000  bestvalidloss -1427.39432  last_update 0\n",
      "train: iter 735  trainloss -1323.71632  validloss -1357.77118±0.00000  bestvalidloss -1427.39432  last_update 1\n",
      "train: iter 736  trainloss -1439.01485  validloss -1407.26839±0.00000  bestvalidloss -1427.39432  last_update 2\n",
      "train: iter 737  trainloss -758.90724  validloss -1357.42237±0.00000  bestvalidloss -1427.39432  last_update 3\n",
      "train: iter 738  trainloss -1136.63172  validloss -798.25591±0.00000  bestvalidloss -1427.39432  last_update 4\n",
      "train: iter 739  trainloss -1312.35959  validloss -1259.02153±0.00000  bestvalidloss -1427.39432  last_update 5\n",
      "train: iter 740  trainloss -1272.02342  validloss -1330.93159±0.00000  bestvalidloss -1427.39432  last_update 6\n",
      "train: iter 741  trainloss -1249.23346  validloss -1289.98351±0.00000  bestvalidloss -1427.39432  last_update 7\n",
      "train: iter 742  trainloss -1367.11243  validloss -1350.75475±0.00000  bestvalidloss -1427.39432  last_update 8\n",
      "train: iter 743  trainloss -1350.24061  validloss -1359.31755±0.00000  bestvalidloss -1427.39432  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 744  trainloss -1370.22078  validloss -1253.11355±0.00000  bestvalidloss -1427.39432  last_update 10\n",
      "train: iter 745  trainloss -1298.81912  validloss -1331.21808±0.00000  bestvalidloss -1427.39432  last_update 11\n",
      "train: iter 746  trainloss -1257.00135  validloss -1346.90706±0.00000  bestvalidloss -1427.39432  last_update 12\n",
      "train: iter 747  trainloss -1374.98850  validloss -1392.34444±0.00000  bestvalidloss -1427.39432  last_update 13\n",
      "train: iter 748  trainloss -1420.18762  validloss -1373.96081±0.00000  bestvalidloss -1427.39432  last_update 14\n",
      "train: iter 749  trainloss -1445.85021  validloss -1354.13713±0.00000  bestvalidloss -1427.39432  last_update 15\n",
      "train: iter 750  trainloss -991.13560  validloss -1386.56453±0.00000  bestvalidloss -1427.39432  last_update 16\n",
      "train: iter 751  trainloss -1016.65091  validloss -1255.71899±0.00000  bestvalidloss -1427.39432  last_update 17\n",
      "train: iter 752  trainloss -1234.64327  validloss -1005.22044±0.00000  bestvalidloss -1427.39432  last_update 18\n",
      "train: iter 753  trainloss -1311.86653  validloss -1332.13248±0.00000  bestvalidloss -1427.39432  last_update 19\n",
      "train: iter 754  trainloss -1385.33206  validloss -1306.88297±0.00000  bestvalidloss -1427.39432  last_update 20\n",
      "train: iter 755  trainloss -1376.41402  validloss -1401.90693±0.00000  bestvalidloss -1427.39432  last_update 21\n",
      "train: iter 756  trainloss -1377.21121  validloss -1387.58905±0.00000  bestvalidloss -1427.39432  last_update 22\n",
      "train: iter 757  trainloss -1003.39996  validloss -147.48960±0.00000  bestvalidloss -1427.39432  last_update 23\n",
      "train: iter 758  trainloss -1298.90781  validloss -1262.32889±0.00000  bestvalidloss -1427.39432  last_update 24\n",
      "train: iter 759  trainloss -1375.46107  validloss -1357.61653±0.00000  bestvalidloss -1427.39432  last_update 25\n",
      "train: iter 760  trainloss -1410.07172  validloss -1389.09888±0.00000  bestvalidloss -1427.39432  last_update 26\n",
      "train: iter 761  trainloss -1430.34789  validloss -1412.82138±0.00000  bestvalidloss -1427.39432  last_update 27\n",
      "train: iter 762  trainloss -1423.95289  validloss -1393.22201±0.00000  bestvalidloss -1427.39432  last_update 28\n",
      "train: iter 763  trainloss -1404.59026  validloss -1409.99265±0.00000  bestvalidloss -1427.39432  last_update 29\n",
      "train: iter 764  trainloss -1327.55423  validloss -1213.51087±0.00000  bestvalidloss -1427.39432  last_update 30\n",
      "train: iter 765  trainloss -1318.19849  validloss -1352.21320±0.00000  bestvalidloss -1427.39432  last_update 31\n",
      "train: iter 766  trainloss -1433.75248  validloss -1409.88233±0.00000  bestvalidloss -1427.39432  last_update 32\n",
      "train: iter 767  trainloss -1368.78770  validloss -1414.26604±0.00000  bestvalidloss -1427.39432  last_update 33\n",
      "train: iter 768  trainloss -1035.48090  validloss -1227.71002±0.00000  bestvalidloss -1427.39432  last_update 34\n",
      "train: iter 769  trainloss -1387.10935  validloss -1391.34168±0.00000  bestvalidloss -1427.39432  last_update 35\n",
      "train: iter 770  trainloss -1337.73006  validloss -1366.95060±0.00000  bestvalidloss -1427.39432  last_update 36\n",
      "train: iter 771  trainloss -1364.44423  validloss -1296.83334±0.00000  bestvalidloss -1427.39432  last_update 37\n",
      "train: iter 772  trainloss -1390.13701  validloss -1386.96805±0.00000  bestvalidloss -1427.39432  last_update 38\n",
      "train: iter 773  trainloss -1377.24078  validloss -1403.36223±0.00000  bestvalidloss -1427.39432  last_update 39\n",
      "train: iter 774  trainloss -1264.32095  validloss -1326.85563±0.00000  bestvalidloss -1427.39432  last_update 40\n",
      "train: iter 775  trainloss -1370.10135  validloss -1321.25370±0.00000  bestvalidloss -1427.39432  last_update 41\n",
      "train: iter 776  trainloss -1420.22462  validloss -1420.28142±0.00000  bestvalidloss -1427.39432  last_update 42\n",
      "train: iter 777  trainloss -1252.14217  validloss -1137.58796±0.00000  bestvalidloss -1427.39432  last_update 43\n",
      "train: iter 778  trainloss -1304.25183  validloss -1254.08790±0.00000  bestvalidloss -1427.39432  last_update 44\n",
      "train: iter 779  trainloss -1374.76641  validloss -1354.91569±0.00000  bestvalidloss -1427.39432  last_update 45\n",
      "train: iter 780  trainloss -1373.00478  validloss -1383.38915±0.00000  bestvalidloss -1427.39432  last_update 46\n",
      "train: iter 781  trainloss -1096.96527  validloss -1353.06032±0.00000  bestvalidloss -1427.39432  last_update 47\n",
      "train: iter 782  trainloss -1341.16955  validloss -1285.41195±0.00000  bestvalidloss -1427.39432  last_update 48\n",
      "train: iter 783  trainloss -1356.36653  validloss -1370.79841±0.00000  bestvalidloss -1427.39432  last_update 49\n",
      "train: iter 784  trainloss -1374.38688  validloss -1355.97516±0.00000  bestvalidloss -1427.39432  last_update 50\n",
      "train: iter 785  trainloss -1415.72531  validloss -1409.91746±0.00000  bestvalidloss -1427.39432  last_update 51\n",
      "train: iter 786  trainloss -1423.67433  validloss -1338.14423±0.00000  bestvalidloss -1427.39432  last_update 52\n",
      "train: iter 787  trainloss -1443.44539  validloss -1405.14049±0.00000  bestvalidloss -1427.39432  last_update 53\n",
      "train: iter 788  trainloss -1382.23585  validloss -1354.73574±0.00000  bestvalidloss -1427.39432  last_update 54\n",
      "train: iter 789  trainloss -1328.63945  validloss -1289.80561±0.00000  bestvalidloss -1427.39432  last_update 55\n",
      "train: iter 790  trainloss -1338.23491  validloss -1329.86025±0.00000  bestvalidloss -1427.39432  last_update 56\n",
      "train: iter 791  trainloss -1415.42639  validloss -1409.64079±0.00000  bestvalidloss -1427.39432  last_update 57\n",
      "train: iter 792  trainloss -1388.54055  validloss -1434.61725±0.00000  bestvalidloss -1434.61725  last_update 0\n",
      "train: iter 793  trainloss -1375.19987  validloss -1408.41816±0.00000  bestvalidloss -1434.61725  last_update 1\n",
      "train: iter 794  trainloss -1437.41776  validloss -1420.51764±0.00000  bestvalidloss -1434.61725  last_update 2\n",
      "train: iter 795  trainloss -1374.67819  validloss -1403.08893±0.00000  bestvalidloss -1434.61725  last_update 3\n",
      "train: iter 796  trainloss -752.43792  validloss -1396.80354±0.00000  bestvalidloss -1434.61725  last_update 4\n",
      "train: iter 797  trainloss -1170.18980  validloss -726.65882±0.00000  bestvalidloss -1434.61725  last_update 5\n",
      "train: iter 798  trainloss -1376.80176  validloss -1346.86869±0.00000  bestvalidloss -1434.61725  last_update 6\n",
      "train: iter 799  trainloss -1162.20742  validloss -1385.13478±0.00000  bestvalidloss -1434.61725  last_update 7\n",
      "train: iter 800  trainloss -1338.12547  validloss -1039.32105±0.00000  bestvalidloss -1434.61725  last_update 8\n",
      "train: iter 801  trainloss -1267.00862  validloss -1390.17260±0.00000  bestvalidloss -1434.61725  last_update 9\n",
      "train: iter 802  trainloss -1395.98433  validloss -1362.86789±0.00000  bestvalidloss -1434.61725  last_update 10\n",
      "train: iter 803  trainloss -1396.95012  validloss -1366.32105±0.00000  bestvalidloss -1434.61725  last_update 11\n",
      "train: iter 804  trainloss -1371.43072  validloss -1337.91952±0.00000  bestvalidloss -1434.61725  last_update 12\n",
      "train: iter 805  trainloss -1409.46864  validloss -1404.33485±0.00000  bestvalidloss -1434.61725  last_update 13\n",
      "train: iter 806  trainloss -764.27933  validloss -1330.84563±0.00000  bestvalidloss -1434.61725  last_update 14\n",
      "train: iter 807  trainloss -1152.61331  validloss -1020.21379±0.00000  bestvalidloss -1434.61725  last_update 15\n",
      "train: iter 808  trainloss -1290.72055  validloss -1204.07553±0.00000  bestvalidloss -1434.61725  last_update 16\n",
      "train: iter 809  trainloss -1322.24274  validloss -1297.99087±0.00000  bestvalidloss -1434.61725  last_update 17\n",
      "train: iter 810  trainloss -1316.13199  validloss -1242.45181±0.00000  bestvalidloss -1434.61725  last_update 18\n",
      "train: iter 811  trainloss -1378.33485  validloss -1329.06064±0.00000  bestvalidloss -1434.61725  last_update 19\n",
      "train: iter 812  trainloss -1134.46747  validloss -1365.84736±0.00000  bestvalidloss -1434.61725  last_update 20\n",
      "train: iter 813  trainloss -1257.64171  validloss -1195.05931±0.00000  bestvalidloss -1434.61725  last_update 21\n",
      "train: iter 814  trainloss -1374.42838  validloss -1346.92540±0.00000  bestvalidloss -1434.61725  last_update 22\n",
      "train: iter 815  trainloss -1403.36906  validloss -1383.82131±0.00000  bestvalidloss -1434.61725  last_update 23\n",
      "train: iter 816  trainloss -1421.06018  validloss -1390.05608±0.00000  bestvalidloss -1434.61725  last_update 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 817  trainloss -1296.60805  validloss -1327.78615±0.00000  bestvalidloss -1434.61725  last_update 25\n",
      "train: iter 818  trainloss -1335.33315  validloss -1332.35091±0.00000  bestvalidloss -1434.61725  last_update 26\n",
      "train: iter 819  trainloss -1446.18660  validloss -1382.22217±0.00000  bestvalidloss -1434.61725  last_update 27\n",
      "train: iter 820  trainloss -1369.50611  validloss -1405.20157±0.00000  bestvalidloss -1434.61725  last_update 28\n",
      "train: iter 821  trainloss -1416.25920  validloss -1404.75802±0.00000  bestvalidloss -1434.61725  last_update 29\n",
      "train: iter 822  trainloss -1434.15949  validloss -1389.20360±0.00000  bestvalidloss -1434.61725  last_update 30\n",
      "train: iter 823  trainloss -1326.28155  validloss -1379.99005±0.00000  bestvalidloss -1434.61725  last_update 31\n",
      "train: iter 824  trainloss -1255.98635  validloss -1240.86900±0.00000  bestvalidloss -1434.61725  last_update 32\n",
      "train: iter 825  trainloss -1430.10381  validloss -1385.34823±0.00000  bestvalidloss -1434.61725  last_update 33\n",
      "train: iter 826  trainloss -1399.75139  validloss -1424.35680±0.00000  bestvalidloss -1434.61725  last_update 34\n",
      "train: iter 827  trainloss -1439.25998  validloss -1410.22304±0.00000  bestvalidloss -1434.61725  last_update 35\n",
      "train: iter 828  trainloss -1308.03220  validloss -1351.64302±0.00000  bestvalidloss -1434.61725  last_update 36\n",
      "train: iter 829  trainloss -1101.46027  validloss -1041.39216±0.00000  bestvalidloss -1434.61725  last_update 37\n",
      "train: iter 830  trainloss -1387.85454  validloss -1315.93741±0.00000  bestvalidloss -1434.61725  last_update 38\n",
      "train: iter 831  trainloss -1383.28798  validloss -1401.76517±0.00000  bestvalidloss -1434.61725  last_update 39\n",
      "train: iter 832  trainloss -1440.58073  validloss -1402.06757±0.00000  bestvalidloss -1434.61725  last_update 40\n",
      "train: iter 833  trainloss -1301.88349  validloss -1385.31444±0.00000  bestvalidloss -1434.61725  last_update 41\n",
      "train: iter 834  trainloss -1331.55507  validloss -1358.75506±0.00000  bestvalidloss -1434.61725  last_update 42\n",
      "train: iter 835  trainloss -1446.37943  validloss -1415.32786±0.00000  bestvalidloss -1434.61725  last_update 43\n",
      "train: iter 836  trainloss -1370.58948  validloss -1425.78497±0.00000  bestvalidloss -1434.61725  last_update 44\n",
      "train: iter 837  trainloss -1414.00623  validloss -1361.18254±0.00000  bestvalidloss -1434.61725  last_update 45\n",
      "train: iter 838  trainloss -1365.21267  validloss -1302.70016±0.00000  bestvalidloss -1434.61725  last_update 46\n",
      "train: iter 839  trainloss -1438.12840  validloss -1326.73246±0.00000  bestvalidloss -1434.61725  last_update 47\n",
      "train: iter 840  trainloss -1359.74295  validloss -1452.13914±0.00000  bestvalidloss -1452.13914  last_update 0\n",
      "train: iter 841  trainloss 1513.04760  validloss -852.71086±0.00000  bestvalidloss -1452.13914  last_update 1\n",
      "train: iter 842  trainloss -276.38728  validloss 41.66507±0.00000  bestvalidloss -1452.13914  last_update 2\n",
      "train: iter 843  trainloss -765.74016  validloss -520.69389±0.00000  bestvalidloss -1452.13914  last_update 3\n",
      "train: iter 844  trainloss -996.45755  validloss -946.65317±0.00000  bestvalidloss -1452.13914  last_update 4\n",
      "train: iter 845  trainloss -1132.43194  validloss -1102.66567±0.00000  bestvalidloss -1452.13914  last_update 5\n",
      "train: iter 846  trainloss -1181.91417  validloss -1175.09313±0.00000  bestvalidloss -1452.13914  last_update 6\n",
      "train: iter 847  trainloss -1258.75049  validloss -1257.96390±0.00000  bestvalidloss -1452.13914  last_update 7\n",
      "train: iter 848  trainloss -1302.28625  validloss -1253.54998±0.00000  bestvalidloss -1452.13914  last_update 8\n",
      "train: iter 849  trainloss -1293.27501  validloss -1317.92667±0.00000  bestvalidloss -1452.13914  last_update 9\n",
      "train: iter 850  trainloss -1185.24483  validloss -1229.31927±0.00000  bestvalidloss -1452.13914  last_update 10\n",
      "train: iter 851  trainloss -1322.73853  validloss -1291.84508±0.00000  bestvalidloss -1452.13914  last_update 11\n",
      "train: iter 852  trainloss -1338.32447  validloss -1287.03979±0.00000  bestvalidloss -1452.13914  last_update 12\n",
      "train: iter 853  trainloss -1349.25670  validloss -1358.02967±0.00000  bestvalidloss -1452.13914  last_update 13\n",
      "train: iter 854  trainloss -1403.26450  validloss -1392.63083±0.00000  bestvalidloss -1452.13914  last_update 14\n",
      "train: iter 855  trainloss -1301.14225  validloss -1384.97986±0.00000  bestvalidloss -1452.13914  last_update 15\n",
      "train: iter 856  trainloss -1336.02018  validloss -1303.10146±0.00000  bestvalidloss -1452.13914  last_update 16\n",
      "train: iter 857  trainloss -1419.64669  validloss -1396.85865±0.00000  bestvalidloss -1452.13914  last_update 17\n",
      "train: iter 858  trainloss -1428.92707  validloss -1399.56933±0.00000  bestvalidloss -1452.13914  last_update 18\n",
      "train: iter 859  trainloss -1179.80956  validloss -1406.35291±0.00000  bestvalidloss -1452.13914  last_update 19\n",
      "train: iter 860  trainloss -1375.22333  validloss -1318.25028±0.00000  bestvalidloss -1452.13914  last_update 20\n",
      "train: iter 861  trainloss -1362.05406  validloss -1368.91615±0.00000  bestvalidloss -1452.13914  last_update 21\n",
      "train: iter 862  trainloss -1418.15648  validloss -1401.42747±0.00000  bestvalidloss -1452.13914  last_update 22\n",
      "train: iter 863  trainloss -1427.10370  validloss -1416.21725±0.00000  bestvalidloss -1452.13914  last_update 23\n",
      "train: iter 864  trainloss -1436.18862  validloss -1419.20302±0.00000  bestvalidloss -1452.13914  last_update 24\n",
      "train: iter 865  trainloss -1424.99978  validloss -1401.07517±0.00000  bestvalidloss -1452.13914  last_update 25\n",
      "train: iter 866  trainloss -1409.04901  validloss -1401.79165±0.00000  bestvalidloss -1452.13914  last_update 26\n",
      "train: iter 867  trainloss -1389.83069  validloss -1400.79865±0.00000  bestvalidloss -1452.13914  last_update 27\n",
      "train: iter 868  trainloss -1374.99777  validloss -1420.08752±0.00000  bestvalidloss -1452.13914  last_update 28\n",
      "train: iter 869  trainloss -1388.02065  validloss -1332.11304±0.00000  bestvalidloss -1452.13914  last_update 29\n",
      "train: iter 870  trainloss -1412.64992  validloss -1428.87228±0.00000  bestvalidloss -1452.13914  last_update 30\n",
      "train: iter 871  trainloss -1437.93880  validloss -1431.56026±0.00000  bestvalidloss -1452.13914  last_update 31\n",
      "train: iter 872  trainloss -1451.69569  validloss -1440.02782±0.00000  bestvalidloss -1452.13914  last_update 32\n",
      "train: iter 873  trainloss -1344.45729  validloss -1415.28632±0.00000  bestvalidloss -1452.13914  last_update 33\n",
      "train: iter 874  trainloss -1424.86594  validloss -1342.35994±0.00000  bestvalidloss -1452.13914  last_update 34\n",
      "train: iter 875  trainloss -1406.59380  validloss -1428.07914±0.00000  bestvalidloss -1452.13914  last_update 35\n",
      "train: iter 876  trainloss -1310.30927  validloss -1354.94912±0.00000  bestvalidloss -1452.13914  last_update 36\n",
      "train: iter 877  trainloss -1436.33951  validloss -1391.47426±0.00000  bestvalidloss -1452.13914  last_update 37\n",
      "train: iter 878  trainloss -1473.00740  validloss -1444.93006±0.00000  bestvalidloss -1452.13914  last_update 38\n",
      "train: iter 879  trainloss -1369.36488  validloss -1463.05570±0.00000  bestvalidloss -1463.05570  last_update 0\n",
      "train: iter 880  trainloss -1389.13246  validloss -1368.58401±0.00000  bestvalidloss -1463.05570  last_update 1\n",
      "train: iter 881  trainloss -1412.52142  validloss -1409.34026±0.00000  bestvalidloss -1463.05570  last_update 2\n",
      "train: iter 882  trainloss -1439.26848  validloss -1429.80769±0.00000  bestvalidloss -1463.05570  last_update 3\n",
      "train: iter 883  trainloss -1446.98322  validloss -1415.77359±0.00000  bestvalidloss -1463.05570  last_update 4\n",
      "train: iter 884  trainloss -1340.44158  validloss -1405.89699±0.00000  bestvalidloss -1463.05570  last_update 5\n",
      "train: iter 885  trainloss -1456.15905  validloss -1402.13954±0.00000  bestvalidloss -1463.05570  last_update 6\n",
      "train: iter 886  trainloss -1439.07923  validloss -1404.01540±0.00000  bestvalidloss -1463.05570  last_update 7\n",
      "train: iter 887  trainloss -1246.56989  validloss -1051.42507±0.00000  bestvalidloss -1463.05570  last_update 8\n",
      "train: iter 888  trainloss -1330.10992  validloss -1360.93164±0.00000  bestvalidloss -1463.05570  last_update 9\n",
      "train: iter 889  trainloss -1431.20315  validloss -1404.73335±0.00000  bestvalidloss -1463.05570  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 890  trainloss -1461.74688  validloss -1400.32085±0.00000  bestvalidloss -1463.05570  last_update 11\n",
      "train: iter 891  trainloss -1451.38043  validloss -1413.87721±0.00000  bestvalidloss -1463.05570  last_update 12\n",
      "train: iter 892  trainloss -1358.42515  validloss -1430.97391±0.00000  bestvalidloss -1463.05570  last_update 13\n",
      "train: iter 893  trainloss -1402.56114  validloss -1409.28995±0.00000  bestvalidloss -1463.05570  last_update 14\n",
      "train: iter 894  trainloss -1320.81043  validloss -1326.36862±0.00000  bestvalidloss -1463.05570  last_update 15\n",
      "train: iter 895  trainloss -1391.31749  validloss -1374.51704±0.00000  bestvalidloss -1463.05570  last_update 16\n",
      "train: iter 896  trainloss -1404.77103  validloss -1421.65290±0.00000  bestvalidloss -1463.05570  last_update 17\n",
      "train: iter 897  trainloss -1413.31329  validloss -1352.78415±0.00000  bestvalidloss -1463.05570  last_update 18\n",
      "train: iter 898  trainloss -1433.82708  validloss -1386.37175±0.00000  bestvalidloss -1463.05570  last_update 19\n",
      "train: iter 899  trainloss -1422.50131  validloss -1449.25386±0.00000  bestvalidloss -1463.05570  last_update 20\n",
      "train: iter 900  trainloss -1433.74216  validloss -1361.07236±0.00000  bestvalidloss -1463.05570  last_update 21\n",
      "train: iter 901  trainloss -1167.06666  validloss -1295.19578±0.00000  bestvalidloss -1463.05570  last_update 22\n",
      "train: iter 902  trainloss -1423.56652  validloss -1400.25492±0.00000  bestvalidloss -1463.05570  last_update 23\n",
      "train: iter 903  trainloss -1334.89948  validloss -1424.37388±0.00000  bestvalidloss -1463.05570  last_update 24\n",
      "train: iter 904  trainloss -1449.07898  validloss -1416.35916±0.00000  bestvalidloss -1463.05570  last_update 25\n",
      "train: iter 905  trainloss -1404.28487  validloss -1370.39858±0.00000  bestvalidloss -1463.05570  last_update 26\n",
      "train: iter 906  trainloss -1382.11275  validloss -1416.78269±0.00000  bestvalidloss -1463.05570  last_update 27\n",
      "train: iter 907  trainloss -1383.57995  validloss -1422.07066±0.00000  bestvalidloss -1463.05570  last_update 28\n",
      "train: iter 908  trainloss -1343.93250  validloss -1247.92315±0.00000  bestvalidloss -1463.05570  last_update 29\n",
      "train: iter 909  trainloss -1372.53830  validloss -1427.89422±0.00000  bestvalidloss -1463.05570  last_update 30\n",
      "train: iter 910  trainloss -1445.81430  validloss -1349.99309±0.00000  bestvalidloss -1463.05570  last_update 31\n",
      "train: iter 911  trainloss -1270.62388  validloss -1449.53385±0.00000  bestvalidloss -1463.05570  last_update 32\n",
      "train: iter 912  trainloss -1323.12709  validloss -1239.86281±0.00000  bestvalidloss -1463.05570  last_update 33\n",
      "train: iter 913  trainloss -1405.67124  validloss -1390.68102±0.00000  bestvalidloss -1463.05570  last_update 34\n",
      "train: iter 914  trainloss -1438.35905  validloss -1385.95680±0.00000  bestvalidloss -1463.05570  last_update 35\n",
      "train: iter 915  trainloss -1425.48969  validloss -1397.49939±0.00000  bestvalidloss -1463.05570  last_update 36\n",
      "train: iter 916  trainloss -1377.00584  validloss -1429.03880±0.00000  bestvalidloss -1463.05570  last_update 37\n",
      "train: iter 917  trainloss -1393.72177  validloss -1387.41044±0.00000  bestvalidloss -1463.05570  last_update 38\n",
      "train: iter 918  trainloss -1475.23757  validloss -1421.81177±0.00000  bestvalidloss -1463.05570  last_update 39\n",
      "train: iter 919  trainloss -1393.33004  validloss -1407.96079±0.00000  bestvalidloss -1463.05570  last_update 40\n",
      "train: iter 920  trainloss -1427.40824  validloss -1395.56121±0.00000  bestvalidloss -1463.05570  last_update 41\n",
      "train: iter 921  trainloss -1335.71820  validloss -1345.22087±0.00000  bestvalidloss -1463.05570  last_update 42\n",
      "train: iter 922  trainloss -1452.21692  validloss -1398.61266±0.00000  bestvalidloss -1463.05570  last_update 43\n",
      "train: iter 923  trainloss -1381.32186  validloss -1440.14146±0.00000  bestvalidloss -1463.05570  last_update 44\n",
      "train: iter 924  trainloss -1427.56257  validloss -1407.74371±0.00000  bestvalidloss -1463.05570  last_update 45\n",
      "train: iter 925  trainloss -1447.98273  validloss -1444.41301±0.00000  bestvalidloss -1463.05570  last_update 46\n",
      "train: iter 926  trainloss -1389.98359  validloss -1430.92903±0.00000  bestvalidloss -1463.05570  last_update 47\n",
      "train: iter 927  trainloss -1374.57044  validloss -1297.97259±0.00000  bestvalidloss -1463.05570  last_update 48\n",
      "train: iter 928  trainloss -1469.99595  validloss -1422.45580±0.00000  bestvalidloss -1463.05570  last_update 49\n",
      "train: iter 929  trainloss -1315.07946  validloss -1437.45089±0.00000  bestvalidloss -1463.05570  last_update 50\n",
      "train: iter 930  trainloss -1346.97611  validloss -1163.41307±0.00000  bestvalidloss -1463.05570  last_update 51\n",
      "train: iter 931  trainloss -1379.73825  validloss -1328.76031±0.00000  bestvalidloss -1463.05570  last_update 52\n",
      "train: iter 932  trainloss -1463.38720  validloss -1453.34532±0.00000  bestvalidloss -1463.05570  last_update 53\n",
      "train: iter 933  trainloss -1404.34382  validloss -1462.02265±0.00000  bestvalidloss -1463.05570  last_update 54\n",
      "train: iter 934  trainloss -1417.48351  validloss -1384.33594±0.00000  bestvalidloss -1463.05570  last_update 55\n",
      "train: iter 935  trainloss -1360.49777  validloss -1411.40247±0.00000  bestvalidloss -1463.05570  last_update 56\n",
      "train: iter 936  trainloss -1462.62663  validloss -1398.84473±0.00000  bestvalidloss -1463.05570  last_update 57\n",
      "train: iter 937  trainloss -1306.60181  validloss -1455.96460±0.00000  bestvalidloss -1463.05570  last_update 58\n",
      "train: iter 938  trainloss -1105.94636  validloss -1092.53163±0.00000  bestvalidloss -1463.05570  last_update 59\n",
      "train: iter 939  trainloss -1403.24659  validloss -1320.85417±0.00000  bestvalidloss -1463.05570  last_update 60\n",
      "train: iter 940  trainloss -1441.15309  validloss -1420.13767±0.00000  bestvalidloss -1463.05570  last_update 61\n",
      "train: iter 941  trainloss -1446.41172  validloss -1438.37969±0.00000  bestvalidloss -1463.05570  last_update 62\n",
      "train: iter 942  trainloss -1409.80143  validloss -1372.24071±0.00000  bestvalidloss -1463.05570  last_update 63\n",
      "train: iter 943  trainloss -1326.60374  validloss -1439.04034±0.00000  bestvalidloss -1463.05570  last_update 64\n",
      "train: iter 944  trainloss -1374.30272  validloss -1412.06805±0.00000  bestvalidloss -1463.05570  last_update 65\n",
      "train: iter 945  trainloss -1429.56813  validloss -1407.56417±0.00000  bestvalidloss -1463.05570  last_update 66\n",
      "train: iter 946  trainloss -1327.60852  validloss -1405.09319±0.00000  bestvalidloss -1463.05570  last_update 67\n",
      "train: iter 947  trainloss -1395.80665  validloss -1357.55146±0.00000  bestvalidloss -1463.05570  last_update 68\n",
      "train: iter 948  trainloss -1448.41665  validloss -1440.19720±0.00000  bestvalidloss -1463.05570  last_update 69\n",
      "train: iter 949  trainloss -1425.32792  validloss -1441.37576±0.00000  bestvalidloss -1463.05570  last_update 70\n",
      "train: iter 950  trainloss -1426.42255  validloss -1400.19409±0.00000  bestvalidloss -1463.05570  last_update 71\n",
      "train: iter 951  trainloss -1444.18892  validloss -1442.69794±0.00000  bestvalidloss -1463.05570  last_update 72\n",
      "train: iter 952  trainloss -1350.03871  validloss -1407.67096±0.00000  bestvalidloss -1463.05570  last_update 73\n",
      "train: iter 953  trainloss -1414.47842  validloss -1436.36537±0.00000  bestvalidloss -1463.05570  last_update 74\n",
      "train: iter 954  trainloss -1183.89947  validloss -1402.06145±0.00000  bestvalidloss -1463.05570  last_update 75\n",
      "train: iter 955  trainloss -1369.79338  validloss -1344.90507±0.00000  bestvalidloss -1463.05570  last_update 76\n",
      "train: iter 956  trainloss -1379.79921  validloss -1364.55058±0.00000  bestvalidloss -1463.05570  last_update 77\n",
      "train: iter 957  trainloss -1356.28846  validloss -1442.41255±0.00000  bestvalidloss -1463.05570  last_update 78\n",
      "train: iter 958  trainloss -1423.12423  validloss -1371.96580±0.00000  bestvalidloss -1463.05570  last_update 79\n",
      "train: iter 959  trainloss -1471.86171  validloss -1442.12077±0.00000  bestvalidloss -1463.05570  last_update 80\n",
      "train: iter 960  trainloss -1227.17033  validloss -1427.13044±0.00000  bestvalidloss -1463.05570  last_update 81\n",
      "train: iter 961  trainloss -314.37450  validloss -865.05713±0.00000  bestvalidloss -1463.05570  last_update 82\n",
      "train: iter 962  trainloss -812.64780  validloss -1097.40430±0.00000  bestvalidloss -1463.05570  last_update 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 963  trainloss -1163.51432  validloss -1123.35218±0.00000  bestvalidloss -1463.05570  last_update 84\n",
      "train: iter 964  trainloss -1316.44640  validloss -1300.08059±0.00000  bestvalidloss -1463.05570  last_update 85\n",
      "train: iter 965  trainloss -1376.90992  validloss -1361.36039±0.00000  bestvalidloss -1463.05570  last_update 86\n",
      "train: iter 966  trainloss -1390.19564  validloss -1378.87980±0.00000  bestvalidloss -1463.05570  last_update 87\n",
      "train: iter 967  trainloss -1419.35831  validloss -1394.26102±0.00000  bestvalidloss -1463.05570  last_update 88\n",
      "train: iter 968  trainloss -1389.43444  validloss -1407.30311±0.00000  bestvalidloss -1463.05570  last_update 89\n",
      "train: iter 969  trainloss -1420.63966  validloss -1422.30797±0.00000  bestvalidloss -1463.05570  last_update 90\n",
      "train: iter 970  trainloss -1388.84224  validloss -1344.39544±0.00000  bestvalidloss -1463.05570  last_update 91\n",
      "train: iter 971  trainloss -1448.38583  validloss -1441.89336±0.00000  bestvalidloss -1463.05570  last_update 92\n",
      "train: iter 972  trainloss -1445.87679  validloss -1441.69400±0.00000  bestvalidloss -1463.05570  last_update 93\n",
      "train: iter 973  trainloss -1362.43550  validloss -1445.59387±0.00000  bestvalidloss -1463.05570  last_update 94\n",
      "train: iter 974  trainloss -1413.22948  validloss -1336.16916±0.00000  bestvalidloss -1463.05570  last_update 95\n",
      "train: iter 975  trainloss -1462.08305  validloss -1391.72361±0.00000  bestvalidloss -1463.05570  last_update 96\n",
      "train: iter 976  trainloss -1488.66649  validloss -1471.72592±0.00000  bestvalidloss -1471.72592  last_update 0\n",
      "train: iter 977  trainloss -1418.21163  validloss -1415.11263±0.00000  bestvalidloss -1471.72592  last_update 1\n",
      "train: iter 978  trainloss -1397.88190  validloss -1336.38559±0.00000  bestvalidloss -1471.72592  last_update 2\n",
      "train: iter 979  trainloss -1466.03298  validloss -1423.97031±0.00000  bestvalidloss -1471.72592  last_update 3\n",
      "train: iter 980  trainloss -1456.46598  validloss -1451.30721±0.00000  bestvalidloss -1471.72592  last_update 4\n",
      "train: iter 981  trainloss -1186.52788  validloss -1390.59853±0.00000  bestvalidloss -1471.72592  last_update 5\n",
      "train: iter 982  trainloss -1381.14777  validloss -1277.45835±0.00000  bestvalidloss -1471.72592  last_update 6\n",
      "train: iter 983  trainloss -1446.40649  validloss -1444.78170±0.00000  bestvalidloss -1471.72592  last_update 7\n",
      "train: iter 984  trainloss -1409.95207  validloss -1429.28845±0.00000  bestvalidloss -1471.72592  last_update 8\n",
      "train: iter 985  trainloss -1462.10593  validloss -1398.92708±0.00000  bestvalidloss -1471.72592  last_update 9\n",
      "train: iter 986  trainloss -1344.83710  validloss -1456.42258±0.00000  bestvalidloss -1471.72592  last_update 10\n",
      "train: iter 987  trainloss -1426.74693  validloss -1362.68960±0.00000  bestvalidloss -1471.72592  last_update 11\n",
      "train: iter 988  trainloss -1444.33298  validloss -1414.30218±0.00000  bestvalidloss -1471.72592  last_update 12\n",
      "train: iter 989  trainloss -1450.85560  validloss -1469.47539±0.00000  bestvalidloss -1471.72592  last_update 13\n",
      "train: iter 990  trainloss -1279.20260  validloss -1349.11517±0.00000  bestvalidloss -1471.72592  last_update 14\n",
      "train: iter 991  trainloss -1441.16620  validloss -1379.68219±0.00000  bestvalidloss -1471.72592  last_update 15\n",
      "train: iter 992  trainloss -1366.38169  validloss -1429.38234±0.00000  bestvalidloss -1471.72592  last_update 16\n",
      "train: iter 993  trainloss -1429.42675  validloss -1268.81857±0.00000  bestvalidloss -1471.72592  last_update 17\n",
      "train: iter 994  trainloss -1480.23613  validloss -1441.32065±0.00000  bestvalidloss -1471.72592  last_update 18\n",
      "train: iter 995  trainloss -1406.92427  validloss -1431.64063±0.00000  bestvalidloss -1471.72592  last_update 19\n",
      "train: iter 996  trainloss -1367.63911  validloss -1340.67871±0.00000  bestvalidloss -1471.72592  last_update 20\n",
      "train: iter 997  trainloss -1298.14044  validloss -1427.65021±0.00000  bestvalidloss -1471.72592  last_update 21\n",
      "train: iter 998  trainloss -1220.48999  validloss -1192.39729±0.00000  bestvalidloss -1471.72592  last_update 22\n",
      "train: iter 999  trainloss -1448.41193  validloss -1400.66465±0.00000  bestvalidloss -1471.72592  last_update 23\n",
      "train: iter 1000  trainloss -1434.32158  validloss -1448.29732±0.00000  bestvalidloss -1471.72592  last_update 24\n",
      "train: iter 1001  trainloss -1474.90168  validloss -1428.77153±0.00000  bestvalidloss -1471.72592  last_update 25\n",
      "train: iter 1002  trainloss -1438.16282  validloss -1454.68815±0.00000  bestvalidloss -1471.72592  last_update 26\n",
      "train: iter 1003  trainloss -1377.64832  validloss -1223.68666±0.00000  bestvalidloss -1471.72592  last_update 27\n",
      "train: iter 1004  trainloss -1482.43036  validloss -1448.72864±0.00000  bestvalidloss -1471.72592  last_update 28\n",
      "train: iter 1005  trainloss -1394.99815  validloss -1472.39662±0.00000  bestvalidloss -1472.39662  last_update 0\n",
      "train: iter 1006  trainloss -1292.61299  validloss -1284.21680±0.00000  bestvalidloss -1472.39662  last_update 1\n",
      "train: iter 1007  trainloss -1429.17221  validloss -1421.96957±0.00000  bestvalidloss -1472.39662  last_update 2\n",
      "train: iter 1008  trainloss -1440.71601  validloss -1410.88081±0.00000  bestvalidloss -1472.39662  last_update 3\n",
      "train: iter 1009  trainloss -1453.24313  validloss -1429.20283±0.00000  bestvalidloss -1472.39662  last_update 4\n",
      "train: iter 1010  trainloss -1437.03364  validloss -1454.17270±0.00000  bestvalidloss -1472.39662  last_update 5\n",
      "train: iter 1011  trainloss -1258.98571  validloss -1395.67720±0.00000  bestvalidloss -1472.39662  last_update 6\n",
      "train: iter 1012  trainloss -1396.77290  validloss -1362.90808±0.00000  bestvalidloss -1472.39662  last_update 7\n",
      "train: iter 1013  trainloss -1411.46684  validloss -1362.80117±0.00000  bestvalidloss -1472.39662  last_update 8\n",
      "train: iter 1014  trainloss -1481.12391  validloss -1438.02685±0.00000  bestvalidloss -1472.39662  last_update 9\n",
      "train: iter 1015  trainloss -1088.46161  validloss -1480.36628±0.00000  bestvalidloss -1480.36628  last_update 0\n",
      "train: iter 1016  trainloss -1001.23491  validloss -1013.65924±0.00000  bestvalidloss -1480.36628  last_update 1\n",
      "train: iter 1017  trainloss -1386.95269  validloss -1318.48563±0.00000  bestvalidloss -1480.36628  last_update 2\n",
      "train: iter 1018  trainloss -1449.16323  validloss -1411.57765±0.00000  bestvalidloss -1480.36628  last_update 3\n",
      "train: iter 1019  trainloss -1479.36183  validloss -1438.53359±0.00000  bestvalidloss -1480.36628  last_update 4\n",
      "train: iter 1020  trainloss -1476.32938  validloss -1458.67632±0.00000  bestvalidloss -1480.36628  last_update 5\n",
      "train: iter 1021  trainloss -1311.82921  validloss -1458.21497±0.00000  bestvalidloss -1480.36628  last_update 6\n",
      "train: iter 1022  trainloss -1343.08172  validloss -1353.38573±0.00000  bestvalidloss -1480.36628  last_update 7\n",
      "train: iter 1023  trainloss -1478.47228  validloss -1437.53556±0.00000  bestvalidloss -1480.36628  last_update 8\n",
      "train: iter 1024  trainloss -1481.31013  validloss -1391.06994±0.00000  bestvalidloss -1480.36628  last_update 9\n",
      "train: iter 1025  trainloss -1385.23787  validloss -1446.75079±0.00000  bestvalidloss -1480.36628  last_update 10\n",
      "train: iter 1026  trainloss -1330.12220  validloss -1281.09444±0.00000  bestvalidloss -1480.36628  last_update 11\n",
      "train: iter 1027  trainloss -1420.32996  validloss -1366.96669±0.00000  bestvalidloss -1480.36628  last_update 12\n",
      "train: iter 1028  trainloss -1466.75129  validloss -1416.23814±0.00000  bestvalidloss -1480.36628  last_update 13\n",
      "train: iter 1029  trainloss -1435.59723  validloss -1446.57923±0.00000  bestvalidloss -1480.36628  last_update 14\n",
      "train: iter 1030  trainloss -1371.75773  validloss -1420.99531±0.00000  bestvalidloss -1480.36628  last_update 15\n",
      "train: iter 1031  trainloss -1440.84352  validloss -1431.76956±0.00000  bestvalidloss -1480.36628  last_update 16\n",
      "train: iter 1032  trainloss -1405.85255  validloss -1408.18019±0.00000  bestvalidloss -1480.36628  last_update 17\n",
      "train: iter 1033  trainloss -1423.15130  validloss -1314.16715±0.00000  bestvalidloss -1480.36628  last_update 18\n",
      "train: iter 1034  trainloss -1494.07252  validloss -1465.59297±0.00000  bestvalidloss -1480.36628  last_update 19\n",
      "train: iter 1035  trainloss -1268.68672  validloss -1458.22845±0.00000  bestvalidloss -1480.36628  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1036  trainloss -1431.55649  validloss -1358.99490±0.00000  bestvalidloss -1480.36628  last_update 21\n",
      "train: iter 1037  trainloss -1459.31346  validloss -1445.91869±0.00000  bestvalidloss -1480.36628  last_update 22\n",
      "train: iter 1038  trainloss -1452.65532  validloss -1422.10975±0.00000  bestvalidloss -1480.36628  last_update 23\n",
      "train: iter 1039  trainloss -1465.47474  validloss -1416.49558±0.00000  bestvalidloss -1480.36628  last_update 24\n",
      "train: iter 1040  trainloss -1405.37777  validloss -1427.57917±0.00000  bestvalidloss -1480.36628  last_update 25\n",
      "train: iter 1041  trainloss -1348.36758  validloss -1377.77444±0.00000  bestvalidloss -1480.36628  last_update 26\n",
      "train: iter 1042  trainloss -1406.09902  validloss -1394.45734±0.00000  bestvalidloss -1480.36628  last_update 27\n",
      "train: iter 1043  trainloss -1496.37560  validloss -1446.97574±0.00000  bestvalidloss -1480.36628  last_update 28\n",
      "train: iter 1044  trainloss -1430.74507  validloss -1494.84219±0.00000  bestvalidloss -1494.84219  last_update 0\n",
      "train: iter 1045  trainloss -1291.45765  validloss -1404.94871±0.00000  bestvalidloss -1494.84219  last_update 1\n",
      "train: iter 1046  trainloss -1365.47639  validloss -1391.92022±0.00000  bestvalidloss -1494.84219  last_update 2\n",
      "train: iter 1047  trainloss -1476.50889  validloss -1424.90331±0.00000  bestvalidloss -1494.84219  last_update 3\n",
      "train: iter 1048  trainloss -1468.85580  validloss -1453.78963±0.00000  bestvalidloss -1494.84219  last_update 4\n",
      "train: iter 1049  trainloss -1359.94613  validloss -1463.98141±0.00000  bestvalidloss -1494.84219  last_update 5\n",
      "train: iter 1050  trainloss -1366.38513  validloss -1235.19180±0.00000  bestvalidloss -1494.84219  last_update 6\n",
      "train: iter 1051  trainloss -1473.31787  validloss -1457.15669±0.00000  bestvalidloss -1494.84219  last_update 7\n",
      "train: iter 1052  trainloss -1466.12589  validloss -1456.14406±0.00000  bestvalidloss -1494.84219  last_update 8\n",
      "train: iter 1053  trainloss -1411.79624  validloss -1449.00572±0.00000  bestvalidloss -1494.84219  last_update 9\n",
      "train: iter 1054  trainloss 1104.48218  validloss -1115.59861±0.00000  bestvalidloss -1494.84219  last_update 10\n",
      "train: iter 1055  trainloss -807.27186  validloss -541.23832±0.00000  bestvalidloss -1494.84219  last_update 11\n",
      "train: iter 1056  trainloss -1178.18027  validloss -1075.16168±0.00000  bestvalidloss -1494.84219  last_update 12\n",
      "train: iter 1057  trainloss -1305.17572  validloss -1282.45309±0.00000  bestvalidloss -1494.84219  last_update 13\n",
      "train: iter 1058  trainloss -1251.19803  validloss -1319.71349±0.00000  bestvalidloss -1494.84219  last_update 14\n",
      "train: iter 1059  trainloss -1229.86168  validloss -994.96606±0.00000  bestvalidloss -1494.84219  last_update 15\n",
      "train: iter 1060  trainloss -1416.56511  validloss -1386.05871±0.00000  bestvalidloss -1494.84219  last_update 16\n",
      "train: iter 1061  trainloss -1382.60906  validloss -1416.35384±0.00000  bestvalidloss -1494.84219  last_update 17\n",
      "train: iter 1062  trainloss -1418.87280  validloss -1386.69831±0.00000  bestvalidloss -1494.84219  last_update 18\n",
      "train: iter 1063  trainloss -1432.42084  validloss -1417.59488±0.00000  bestvalidloss -1494.84219  last_update 19\n",
      "train: iter 1064  trainloss -1376.56250  validloss -1431.99556±0.00000  bestvalidloss -1494.84219  last_update 20\n",
      "train: iter 1065  trainloss -1456.58697  validloss -1404.83333±0.00000  bestvalidloss -1494.84219  last_update 21\n",
      "train: iter 1066  trainloss -1465.92278  validloss -1421.65304±0.00000  bestvalidloss -1494.84219  last_update 22\n",
      "train: iter 1067  trainloss -1463.14513  validloss -1457.78706±0.00000  bestvalidloss -1494.84219  last_update 23\n",
      "train: iter 1068  trainloss -1479.33961  validloss -1463.25179±0.00000  bestvalidloss -1494.84219  last_update 24\n",
      "train: iter 1069  trainloss -1469.31119  validloss -1449.51217±0.00000  bestvalidloss -1494.84219  last_update 25\n",
      "train: iter 1070  trainloss -1421.14134  validloss -1429.22726±0.00000  bestvalidloss -1494.84219  last_update 26\n",
      "train: iter 1071  trainloss -1483.68317  validloss -1451.67328±0.00000  bestvalidloss -1494.84219  last_update 27\n",
      "train: iter 1072  trainloss -1445.41965  validloss -1444.35475±0.00000  bestvalidloss -1494.84219  last_update 28\n",
      "train: iter 1073  trainloss -1463.37604  validloss -1422.44595±0.00000  bestvalidloss -1494.84219  last_update 29\n",
      "train: iter 1074  trainloss -87.29370  validloss -1402.68978±0.00000  bestvalidloss -1494.84219  last_update 30\n",
      "train: iter 1075  trainloss -570.77911  validloss -465.60136±0.00000  bestvalidloss -1494.84219  last_update 31\n",
      "train: iter 1076  trainloss -1156.32585  validloss -888.58540±0.00000  bestvalidloss -1494.84219  last_update 32\n",
      "train: iter 1077  trainloss -1295.03661  validloss -1288.51821±0.00000  bestvalidloss -1494.84219  last_update 33\n",
      "train: iter 1078  trainloss -1267.78105  validloss -1355.70961±0.00000  bestvalidloss -1494.84219  last_update 34\n",
      "train: iter 1079  trainloss -1348.58899  validloss -1320.51285±0.00000  bestvalidloss -1494.84219  last_update 35\n",
      "train: iter 1080  trainloss -1414.97219  validloss -1400.35880±0.00000  bestvalidloss -1494.84219  last_update 36\n",
      "train: iter 1081  trainloss -1430.14700  validloss -1414.74359±0.00000  bestvalidloss -1494.84219  last_update 37\n",
      "train: iter 1082  trainloss -1440.90824  validloss -1405.13475±0.00000  bestvalidloss -1494.84219  last_update 38\n",
      "train: iter 1083  trainloss -1396.30290  validloss -1419.76367±0.00000  bestvalidloss -1494.84219  last_update 39\n",
      "train: iter 1084  trainloss -1449.96274  validloss -1379.03286±0.00000  bestvalidloss -1494.84219  last_update 40\n",
      "train: iter 1085  trainloss -1384.96921  validloss -1355.03283±0.00000  bestvalidloss -1494.84219  last_update 41\n",
      "train: iter 1086  trainloss -1392.98385  validloss -1425.03788±0.00000  bestvalidloss -1494.84219  last_update 42\n",
      "train: iter 1087  trainloss -1424.85708  validloss -1399.88379±0.00000  bestvalidloss -1494.84219  last_update 43\n",
      "train: iter 1088  trainloss -1411.05020  validloss -1443.04509±0.00000  bestvalidloss -1494.84219  last_update 44\n",
      "train: iter 1089  trainloss -1469.97966  validloss -1458.04937±0.00000  bestvalidloss -1494.84219  last_update 45\n",
      "train: iter 1090  trainloss -1327.27477  validloss -1452.41479±0.00000  bestvalidloss -1494.84219  last_update 46\n",
      "train: iter 1091  trainloss -1410.52500  validloss -1278.44536±0.00000  bestvalidloss -1494.84219  last_update 47\n",
      "train: iter 1092  trainloss -1475.43900  validloss -1426.96583±0.00000  bestvalidloss -1494.84219  last_update 48\n",
      "train: iter 1093  trainloss -1475.53439  validloss -1384.12709±0.00000  bestvalidloss -1494.84219  last_update 49\n",
      "train: iter 1094  trainloss -1486.81913  validloss -1404.46736±0.00000  bestvalidloss -1494.84219  last_update 50\n",
      "train: iter 1095  trainloss -1460.08366  validloss -1473.35918±0.00000  bestvalidloss -1494.84219  last_update 51\n",
      "train: iter 1096  trainloss -1455.08741  validloss -1418.63610±0.00000  bestvalidloss -1494.84219  last_update 52\n",
      "train: iter 1097  trainloss -1461.19275  validloss -1446.30424±0.00000  bestvalidloss -1494.84219  last_update 53\n",
      "train: iter 1098  trainloss -1482.45477  validloss -1436.55278±0.00000  bestvalidloss -1494.84219  last_update 54\n",
      "train: iter 1099  trainloss -1480.93357  validloss -1454.77413±0.00000  bestvalidloss -1494.84219  last_update 55\n",
      "train: iter 1100  trainloss -1502.02850  validloss -1457.02864±0.00000  bestvalidloss -1494.84219  last_update 56\n",
      "train: iter 1101  trainloss -1451.59863  validloss -1399.04518±0.00000  bestvalidloss -1494.84219  last_update 57\n",
      "train: iter 1102  trainloss -1437.00521  validloss -1467.01808±0.00000  bestvalidloss -1494.84219  last_update 58\n",
      "train: iter 1103  trainloss -1454.48033  validloss -1460.76039±0.00000  bestvalidloss -1494.84219  last_update 59\n",
      "train: iter 1104  trainloss -1312.92662  validloss -1224.06324±0.00000  bestvalidloss -1494.84219  last_update 60\n",
      "train: iter 1105  trainloss -1475.83755  validloss -1428.40043±0.00000  bestvalidloss -1494.84219  last_update 61\n",
      "train: iter 1106  trainloss -1435.24529  validloss -1468.90433±0.00000  bestvalidloss -1494.84219  last_update 62\n",
      "train: iter 1107  trainloss -1493.61169  validloss -1462.65831±0.00000  bestvalidloss -1494.84219  last_update 63\n",
      "train: iter 1108  trainloss -1432.03557  validloss -1455.68833±0.00000  bestvalidloss -1494.84219  last_update 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1109  trainloss -1270.71973  validloss -1378.75458±0.00000  bestvalidloss -1494.84219  last_update 65\n",
      "train: iter 1110  trainloss -1439.50060  validloss -1337.74445±0.00000  bestvalidloss -1494.84219  last_update 66\n",
      "train: iter 1111  trainloss -1496.17325  validloss -1470.55782±0.00000  bestvalidloss -1494.84219  last_update 67\n",
      "train: iter 1112  trainloss -1412.62549  validloss -1450.94808±0.00000  bestvalidloss -1494.84219  last_update 68\n",
      "train: iter 1113  trainloss -1426.77356  validloss -1429.78749±0.00000  bestvalidloss -1494.84219  last_update 69\n",
      "train: iter 1114  trainloss -1369.77044  validloss -1335.78666±0.00000  bestvalidloss -1494.84219  last_update 70\n",
      "train: iter 1115  trainloss -1494.17005  validloss -1449.55115±0.00000  bestvalidloss -1494.84219  last_update 71\n",
      "train: iter 1116  trainloss -1500.34129  validloss -1479.85433±0.00000  bestvalidloss -1494.84219  last_update 72\n",
      "train: iter 1117  trainloss -1505.02720  validloss -1473.55305±0.00000  bestvalidloss -1494.84219  last_update 73\n",
      "train: iter 1118  trainloss -1341.90620  validloss -1446.03521±0.00000  bestvalidloss -1494.84219  last_update 74\n",
      "train: iter 1119  trainloss -1425.44877  validloss -1369.07384±0.00000  bestvalidloss -1494.84219  last_update 75\n",
      "train: iter 1120  trainloss -1450.93110  validloss -1349.06379±0.00000  bestvalidloss -1494.84219  last_update 76\n",
      "train: iter 1121  trainloss -1467.08147  validloss -1443.03546±0.00000  bestvalidloss -1494.84219  last_update 77\n",
      "train: iter 1122  trainloss -1433.84720  validloss -1459.43698±0.00000  bestvalidloss -1494.84219  last_update 78\n",
      "train: iter 1123  trainloss -1400.27897  validloss -1302.74727±0.00000  bestvalidloss -1494.84219  last_update 79\n",
      "train: iter 1124  trainloss -1463.11058  validloss -1418.72092±0.00000  bestvalidloss -1494.84219  last_update 80\n",
      "train: iter 1125  trainloss -1446.51208  validloss -1450.12649±0.00000  bestvalidloss -1494.84219  last_update 81\n",
      "train: iter 1126  trainloss -1353.77732  validloss -1348.40630±0.00000  bestvalidloss -1494.84219  last_update 82\n",
      "train: iter 1127  trainloss -1347.74220  validloss -1394.75921±0.00000  bestvalidloss -1494.84219  last_update 83\n",
      "train: iter 1128  trainloss -1432.93012  validloss -1237.90052±0.00000  bestvalidloss -1494.84219  last_update 84\n",
      "train: iter 1129  trainloss -1473.15371  validloss -1450.07814±0.00000  bestvalidloss -1494.84219  last_update 85\n",
      "train: iter 1130  trainloss -1431.40629  validloss -1332.09145±0.00000  bestvalidloss -1494.84219  last_update 86\n",
      "train: iter 1131  trainloss -1513.25933  validloss -1477.74690±0.00000  bestvalidloss -1494.84219  last_update 87\n",
      "train: iter 1132  trainloss -988.24261  validloss -1469.51460±0.00000  bestvalidloss -1494.84219  last_update 88\n",
      "train: iter 1133  trainloss -1123.89510  validloss -964.57114±0.00000  bestvalidloss -1494.84219  last_update 89\n",
      "train: iter 1134  trainloss -1317.10101  validloss -1264.32362±0.00000  bestvalidloss -1494.84219  last_update 90\n",
      "train: iter 1135  trainloss -1418.68386  validloss -1388.38481±0.00000  bestvalidloss -1494.84219  last_update 91\n",
      "train: iter 1136  trainloss -1443.24992  validloss -1424.52776±0.00000  bestvalidloss -1494.84219  last_update 92\n",
      "train: iter 1137  trainloss -1175.72376  validloss -1114.12598±0.00000  bestvalidloss -1494.84219  last_update 93\n",
      "train: iter 1138  trainloss -1390.15915  validloss -1378.89835±0.00000  bestvalidloss -1494.84219  last_update 94\n",
      "train: iter 1139  trainloss -1434.45924  validloss -1400.74367±0.00000  bestvalidloss -1494.84219  last_update 95\n",
      "train: iter 1140  trainloss -1435.64339  validloss -1429.09538±0.00000  bestvalidloss -1494.84219  last_update 96\n",
      "train: iter 1141  trainloss -1462.32356  validloss -1437.78297±0.00000  bestvalidloss -1494.84219  last_update 97\n",
      "train: iter 1142  trainloss -1477.45883  validloss -1449.29352±0.00000  bestvalidloss -1494.84219  last_update 98\n",
      "train: iter 1143  trainloss -1448.62000  validloss -1442.87768±0.00000  bestvalidloss -1494.84219  last_update 99\n",
      "train: iter 1144  trainloss -1388.24099  validloss -1375.81673±0.00000  bestvalidloss -1494.84219  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.2022) penalty_target_max tensor(5.0192)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 3.83015  validloss 3.98944±0.00000  bestvalidloss 3.98944  last_update 0\n",
      "train: iter 1  trainloss 3.55689  validloss 3.68759±0.00000  bestvalidloss 3.68759  last_update 0\n",
      "train: iter 2  trainloss 3.32648  validloss 3.43913±0.00000  bestvalidloss 3.43913  last_update 0\n",
      "train: iter 3  trainloss 3.14100  validloss 3.22841±0.00000  bestvalidloss 3.22841  last_update 0\n",
      "train: iter 4  trainloss 2.98132  validloss 3.06349±0.00000  bestvalidloss 3.06349  last_update 0\n",
      "train: iter 5  trainloss 2.84368  validloss 2.92065±0.00000  bestvalidloss 2.92065  last_update 0\n",
      "train: iter 6  trainloss 2.72465  validloss 2.77460±0.00000  bestvalidloss 2.77460  last_update 0\n",
      "train: iter 7  trainloss 2.61786  validloss 2.67123±0.00000  bestvalidloss 2.67123  last_update 0\n",
      "train: iter 8  trainloss 2.51329  validloss 2.56740±0.00000  bestvalidloss 2.56740  last_update 0\n",
      "train: iter 9  trainloss 2.42774  validloss 2.47382±0.00000  bestvalidloss 2.47382  last_update 0\n",
      "train: iter 10  trainloss 2.35231  validloss 2.37967±0.00000  bestvalidloss 2.37967  last_update 0\n",
      "train: iter 11  trainloss 2.26817  validloss 2.31272±0.00000  bestvalidloss 2.31272  last_update 0\n",
      "train: iter 12  trainloss 2.19657  validloss 2.22645±0.00000  bestvalidloss 2.22645  last_update 0\n",
      "train: iter 13  trainloss 2.12615  validloss 2.15620±0.00000  bestvalidloss 2.15620  last_update 0\n",
      "train: iter 14  trainloss 2.05673  validloss 2.09713±0.00000  bestvalidloss 2.09713  last_update 0\n",
      "train: iter 15  trainloss 1.99835  validloss 2.02489±0.00000  bestvalidloss 2.02489  last_update 0\n",
      "train: iter 16  trainloss 1.93035  validloss 1.96374±0.00000  bestvalidloss 1.96374  last_update 0\n",
      "train: iter 17  trainloss 1.87026  validloss 1.90611±0.00000  bestvalidloss 1.90611  last_update 0\n",
      "train: iter 18  trainloss 1.80347  validloss 1.83272±0.00000  bestvalidloss 1.83272  last_update 0\n",
      "train: iter 19  trainloss 1.73091  validloss 1.76702±0.00000  bestvalidloss 1.76702  last_update 0\n",
      "train: iter 20  trainloss 1.66962  validloss 1.70789±0.00000  bestvalidloss 1.70789  last_update 0\n",
      "train: iter 21  trainloss 1.60691  validloss 1.64335±0.00000  bestvalidloss 1.64335  last_update 0\n",
      "train: iter 22  trainloss 1.53457  validloss 1.55123±0.00000  bestvalidloss 1.55123  last_update 0\n",
      "train: iter 23  trainloss 1.46783  validloss 1.50802±0.00000  bestvalidloss 1.50802  last_update 0\n",
      "train: iter 24  trainloss 1.41303  validloss 1.42868±0.00000  bestvalidloss 1.42868  last_update 0\n",
      "train: iter 25  trainloss 1.33780  validloss 1.35719±0.00000  bestvalidloss 1.35719  last_update 0\n",
      "train: iter 26  trainloss 1.26250  validloss 1.29526±0.00000  bestvalidloss 1.29526  last_update 0\n",
      "train: iter 27  trainloss 1.19267  validloss 1.22058±0.00000  bestvalidloss 1.22058  last_update 0\n",
      "train: iter 28  trainloss 1.10678  validloss 1.15350±0.00000  bestvalidloss 1.15350  last_update 0\n",
      "train: iter 29  trainloss 1.04558  validloss 1.08753±0.00000  bestvalidloss 1.08753  last_update 0\n",
      "train: iter 30  trainloss 0.97767  validloss 1.01820±0.00000  bestvalidloss 1.01820  last_update 0\n",
      "train: iter 31  trainloss 0.89422  validloss 0.91592±0.00000  bestvalidloss 0.91592  last_update 0\n",
      "train: iter 32  trainloss 0.84060  validloss 0.86682±0.00000  bestvalidloss 0.86682  last_update 0\n",
      "train: iter 33  trainloss 0.77443  validloss 0.78670±0.00000  bestvalidloss 0.78670  last_update 0\n",
      "train: iter 34  trainloss 0.71820  validloss 0.70151±0.00000  bestvalidloss 0.70151  last_update 0\n",
      "train: iter 35  trainloss 0.64999  validloss 0.66137±0.00000  bestvalidloss 0.66137  last_update 0\n",
      "train: iter 36  trainloss 0.61745  validloss 0.62946±0.00000  bestvalidloss 0.62946  last_update 0\n",
      "train: iter 37  trainloss 0.56640  validloss 0.56966±0.00000  bestvalidloss 0.56966  last_update 0\n",
      "train: iter 38  trainloss 0.50838  validloss 0.53982±0.00000  bestvalidloss 0.53982  last_update 0\n",
      "train: iter 39  trainloss 0.45796  validloss 0.50246±0.00000  bestvalidloss 0.50246  last_update 0\n",
      "train: iter 40  trainloss 0.41468  validloss 0.40307±0.00000  bestvalidloss 0.40307  last_update 0\n",
      "train: iter 41  trainloss 0.36732  validloss 0.37305±0.00000  bestvalidloss 0.37305  last_update 0\n",
      "train: iter 42  trainloss 0.34164  validloss 0.31735±0.00000  bestvalidloss 0.31735  last_update 0\n",
      "train: iter 43  trainloss 0.28854  validloss 0.27528±0.00000  bestvalidloss 0.27528  last_update 0\n",
      "train: iter 44  trainloss 0.23019  validloss 0.26735±0.00000  bestvalidloss 0.26735  last_update 0\n",
      "train: iter 45  trainloss 0.18343  validloss 0.21099±0.00000  bestvalidloss 0.21099  last_update 0\n",
      "train: iter 46  trainloss 0.15862  validloss 0.11818±0.00000  bestvalidloss 0.11818  last_update 0\n",
      "train: iter 47  trainloss 0.11721  validloss 0.10012±0.00000  bestvalidloss 0.10012  last_update 0\n",
      "train: iter 48  trainloss 0.07759  validloss 0.06160±0.00000  bestvalidloss 0.06160  last_update 0\n",
      "train: iter 49  trainloss 0.02589  validloss 0.03299±0.00000  bestvalidloss 0.03299  last_update 0\n",
      "train: iter 50  trainloss -0.00142  validloss -0.02320±0.00000  bestvalidloss -0.02320  last_update 0\n",
      "train: iter 51  trainloss -0.05125  validloss -0.06711±0.00000  bestvalidloss -0.06711  last_update 0\n",
      "train: iter 52  trainloss -0.07563  validloss -0.10330±0.00000  bestvalidloss -0.10330  last_update 0\n",
      "train: iter 53  trainloss -0.12957  validloss -0.09575±0.00000  bestvalidloss -0.10330  last_update 1\n",
      "train: iter 54  trainloss -0.16069  validloss -0.15271±0.00000  bestvalidloss -0.15271  last_update 0\n",
      "train: iter 55  trainloss -0.18395  validloss -0.21042±0.00000  bestvalidloss -0.21042  last_update 0\n",
      "train: iter 56  trainloss -0.23253  validloss -0.24556±0.00000  bestvalidloss -0.24556  last_update 0\n",
      "train: iter 57  trainloss -0.25738  validloss -0.26858±0.00000  bestvalidloss -0.26858  last_update 0\n",
      "train: iter 58  trainloss -0.27225  validloss -0.31951±0.00000  bestvalidloss -0.31951  last_update 0\n",
      "train: iter 59  trainloss -0.32123  validloss -0.31403±0.00000  bestvalidloss -0.31951  last_update 1\n",
      "train: iter 60  trainloss -0.38711  validloss -0.41662±0.00000  bestvalidloss -0.41662  last_update 0\n",
      "train: iter 61  trainloss -0.39286  validloss -0.41907±0.00000  bestvalidloss -0.41907  last_update 0\n",
      "train: iter 62  trainloss -0.44590  validloss -0.48899±0.00000  bestvalidloss -0.48899  last_update 0\n",
      "train: iter 63  trainloss -0.47540  validloss -0.51321±0.00000  bestvalidloss -0.51321  last_update 0\n",
      "train: iter 64  trainloss -0.51020  validloss -0.53827±0.00000  bestvalidloss -0.53827  last_update 0\n",
      "train: iter 65  trainloss -0.52134  validloss -0.57246±0.00000  bestvalidloss -0.57246  last_update 0\n",
      "train: iter 66  trainloss -0.53992  validloss -0.63286±0.00000  bestvalidloss -0.63286  last_update 0\n",
      "train: iter 67  trainloss -0.59403  validloss -0.63493±0.00000  bestvalidloss -0.63493  last_update 0\n",
      "train: iter 68  trainloss -0.62432  validloss -0.68353±0.00000  bestvalidloss -0.68353  last_update 0\n",
      "train: iter 69  trainloss -0.64868  validloss -0.71813±0.00000  bestvalidloss -0.71813  last_update 0\n",
      "train: iter 70  trainloss -0.61720  validloss -0.74149±0.00000  bestvalidloss -0.74149  last_update 0\n",
      "train: iter 71  trainloss -0.69363  validloss -0.76407±0.00000  bestvalidloss -0.76407  last_update 0\n",
      "train: iter 72  trainloss -0.68656  validloss -0.76385±0.00000  bestvalidloss -0.76407  last_update 1\n",
      "train: iter 73  trainloss -0.69698  validloss -0.77467±0.00000  bestvalidloss -0.77467  last_update 0\n",
      "train: iter 74  trainloss -0.73758  validloss -0.83826±0.00000  bestvalidloss -0.83826  last_update 0\n",
      "train: iter 75  trainloss -0.78862  validloss -0.86644±0.00000  bestvalidloss -0.86644  last_update 0\n",
      "train: iter 76  trainloss -0.76608  validloss -0.93481±0.00000  bestvalidloss -0.93481  last_update 0\n",
      "train: iter 77  trainloss -0.81652  validloss -0.94171±0.00000  bestvalidloss -0.94171  last_update 0\n",
      "train: iter 78  trainloss -0.78792  validloss -0.98998±0.00000  bestvalidloss -0.98998  last_update 0\n",
      "train: iter 79  trainloss -0.83365  validloss -0.93810±0.00000  bestvalidloss -0.98998  last_update 1\n",
      "train: iter 80  trainloss -0.86257  validloss -0.97327±0.00000  bestvalidloss -0.98998  last_update 2\n",
      "train: iter 81  trainloss -0.84440  validloss -1.04101±0.00000  bestvalidloss -1.04101  last_update 0\n",
      "train: iter 82  trainloss -0.89542  validloss -1.02169±0.00000  bestvalidloss -1.04101  last_update 1\n",
      "train: iter 83  trainloss -0.86800  validloss -1.00927±0.00000  bestvalidloss -1.04101  last_update 2\n",
      "train: iter 84  trainloss -0.91511  validloss -1.01208±0.00000  bestvalidloss -1.04101  last_update 3\n",
      "train: iter 85  trainloss -0.90115  validloss -1.06122±0.00000  bestvalidloss -1.06122  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 86  trainloss -0.93829  validloss -1.07374±0.00000  bestvalidloss -1.07374  last_update 0\n",
      "train: iter 87  trainloss -0.91000  validloss -1.07028±0.00000  bestvalidloss -1.07374  last_update 1\n",
      "train: iter 88  trainloss -0.89580  validloss -1.06309±0.00000  bestvalidloss -1.07374  last_update 2\n",
      "train: iter 89  trainloss -0.96010  validloss -1.11791±0.00000  bestvalidloss -1.11791  last_update 0\n",
      "train: iter 90  trainloss -0.94697  validloss -1.10998±0.00000  bestvalidloss -1.11791  last_update 1\n",
      "train: iter 91  trainloss -0.97223  validloss -1.12983±0.00000  bestvalidloss -1.12983  last_update 0\n",
      "train: iter 92  trainloss -0.90325  validloss -1.12557±0.00000  bestvalidloss -1.12983  last_update 1\n",
      "train: iter 93  trainloss -0.90766  validloss -1.17108±0.00000  bestvalidloss -1.17108  last_update 0\n",
      "train: iter 94  trainloss -0.96754  validloss -1.17069±0.00000  bestvalidloss -1.17108  last_update 1\n",
      "train: iter 95  trainloss -1.01197  validloss -1.15332±0.00000  bestvalidloss -1.17108  last_update 2\n",
      "train: iter 96  trainloss -0.96175  validloss -1.17062±0.00000  bestvalidloss -1.17108  last_update 3\n",
      "train: iter 97  trainloss -1.02244  validloss -1.20302±0.00000  bestvalidloss -1.20302  last_update 0\n",
      "train: iter 98  trainloss -1.00453  validloss -1.16978±0.00000  bestvalidloss -1.20302  last_update 1\n",
      "train: iter 99  trainloss -0.90630  validloss -1.16564±0.00000  bestvalidloss -1.20302  last_update 2\n",
      "train: iter 100  trainloss -0.99544  validloss -1.20949±0.00000  bestvalidloss -1.20949  last_update 0\n",
      "train: iter 101  trainloss -0.98320  validloss -1.24361±0.00000  bestvalidloss -1.24361  last_update 0\n",
      "train: iter 102  trainloss -0.96447  validloss -1.22791±0.00000  bestvalidloss -1.24361  last_update 1\n",
      "train: iter 103  trainloss -0.98016  validloss -1.21674±0.00000  bestvalidloss -1.24361  last_update 2\n",
      "train: iter 104  trainloss -0.94294  validloss -1.24823±0.00000  bestvalidloss -1.24823  last_update 0\n",
      "train: iter 105  trainloss -0.97933  validloss -1.22961±0.00000  bestvalidloss -1.24823  last_update 1\n",
      "train: iter 106  trainloss -0.99862  validloss -1.22048±0.00000  bestvalidloss -1.24823  last_update 2\n",
      "train: iter 107  trainloss -1.03979  validloss -1.25250±0.00000  bestvalidloss -1.25250  last_update 0\n",
      "train: iter 108  trainloss -1.02937  validloss -1.26732±0.00000  bestvalidloss -1.26732  last_update 0\n",
      "train: iter 109  trainloss -0.96688  validloss -1.20332±0.00000  bestvalidloss -1.26732  last_update 1\n",
      "train: iter 110  trainloss -1.00196  validloss -1.27861±0.00000  bestvalidloss -1.27861  last_update 0\n",
      "train: iter 111  trainloss -0.98839  validloss -1.19975±0.00000  bestvalidloss -1.27861  last_update 1\n",
      "train: iter 112  trainloss -0.98526  validloss -1.25118±0.00000  bestvalidloss -1.27861  last_update 2\n",
      "train: iter 113  trainloss -1.00878  validloss -1.29591±0.00000  bestvalidloss -1.29591  last_update 0\n",
      "train: iter 114  trainloss -1.02869  validloss -1.24887±0.00000  bestvalidloss -1.29591  last_update 1\n",
      "train: iter 115  trainloss -0.98193  validloss -1.23978±0.00000  bestvalidloss -1.29591  last_update 2\n",
      "train: iter 116  trainloss -1.01823  validloss -1.28159±0.00000  bestvalidloss -1.29591  last_update 3\n",
      "train: iter 117  trainloss -1.03770  validloss -1.31111±0.00000  bestvalidloss -1.31111  last_update 0\n",
      "train: iter 118  trainloss -1.04762  validloss -1.31855±0.00000  bestvalidloss -1.31855  last_update 0\n",
      "train: iter 119  trainloss -0.98951  validloss -1.30687±0.00000  bestvalidloss -1.31855  last_update 1\n",
      "train: iter 120  trainloss -1.03352  validloss -1.29146±0.00000  bestvalidloss -1.31855  last_update 2\n",
      "train: iter 121  trainloss -1.03467  validloss -1.31669±0.00000  bestvalidloss -1.31855  last_update 3\n",
      "train: iter 122  trainloss -0.99270  validloss -1.30749±0.00000  bestvalidloss -1.31855  last_update 4\n",
      "train: iter 123  trainloss -1.02731  validloss -1.32898±0.00000  bestvalidloss -1.32898  last_update 0\n",
      "train: iter 124  trainloss -0.95921  validloss -1.34387±0.00000  bestvalidloss -1.34387  last_update 0\n",
      "train: iter 125  trainloss -1.07507  validloss -1.33016±0.00000  bestvalidloss -1.34387  last_update 1\n",
      "train: iter 126  trainloss -1.03097  validloss -1.30307±0.00000  bestvalidloss -1.34387  last_update 2\n",
      "train: iter 127  trainloss -1.03820  validloss -1.28440±0.00000  bestvalidloss -1.34387  last_update 3\n",
      "train: iter 128  trainloss -1.02128  validloss -1.33679±0.00000  bestvalidloss -1.34387  last_update 4\n",
      "train: iter 129  trainloss -1.04461  validloss -1.29281±0.00000  bestvalidloss -1.34387  last_update 5\n",
      "train: iter 130  trainloss -0.97576  validloss -1.30542±0.00000  bestvalidloss -1.34387  last_update 6\n",
      "train: iter 131  trainloss -0.99572  validloss -1.35501±0.00000  bestvalidloss -1.35501  last_update 0\n",
      "train: iter 132  trainloss -1.04831  validloss -1.28494±0.00000  bestvalidloss -1.35501  last_update 1\n",
      "train: iter 133  trainloss -1.03836  validloss -1.37445±0.00000  bestvalidloss -1.37445  last_update 0\n",
      "train: iter 134  trainloss -1.03281  validloss -1.31260±0.00000  bestvalidloss -1.37445  last_update 1\n",
      "train: iter 135  trainloss -1.03182  validloss -1.28092±0.00000  bestvalidloss -1.37445  last_update 2\n",
      "train: iter 136  trainloss -1.09872  validloss -1.29523±0.00000  bestvalidloss -1.37445  last_update 3\n",
      "train: iter 137  trainloss -0.97946  validloss -1.33329±0.00000  bestvalidloss -1.37445  last_update 4\n",
      "train: iter 138  trainloss -0.99587  validloss -1.28715±0.00000  bestvalidloss -1.37445  last_update 5\n",
      "train: iter 139  trainloss -1.00442  validloss -1.30677±0.00000  bestvalidloss -1.37445  last_update 6\n",
      "train: iter 140  trainloss -1.05566  validloss -1.33752±0.00000  bestvalidloss -1.37445  last_update 7\n",
      "train: iter 141  trainloss -1.02714  validloss -1.29857±0.00000  bestvalidloss -1.37445  last_update 8\n",
      "train: iter 142  trainloss -1.02069  validloss -1.37182±0.00000  bestvalidloss -1.37445  last_update 9\n",
      "train: iter 143  trainloss -1.03762  validloss -1.31662±0.00000  bestvalidloss -1.37445  last_update 10\n",
      "train: iter 144  trainloss -1.03978  validloss -1.30092±0.00000  bestvalidloss -1.37445  last_update 11\n",
      "train: iter 145  trainloss -1.08209  validloss -1.35768±0.00000  bestvalidloss -1.37445  last_update 12\n",
      "train: iter 146  trainloss -0.94843  validloss -1.30706±0.00000  bestvalidloss -1.37445  last_update 13\n",
      "train: iter 147  trainloss -1.06994  validloss -1.39171±0.00000  bestvalidloss -1.39171  last_update 0\n",
      "train: iter 148  trainloss -1.01283  validloss -1.37628±0.00000  bestvalidloss -1.39171  last_update 1\n",
      "train: iter 149  trainloss -1.06136  validloss -1.34697±0.00000  bestvalidloss -1.39171  last_update 2\n",
      "train: iter 150  trainloss -0.99871  validloss -1.38175±0.00000  bestvalidloss -1.39171  last_update 3\n",
      "train: iter 151  trainloss -1.02199  validloss -1.33292±0.00000  bestvalidloss -1.39171  last_update 4\n",
      "train: iter 152  trainloss -0.99243  validloss -1.31952±0.00000  bestvalidloss -1.39171  last_update 5\n",
      "train: iter 153  trainloss -1.05443  validloss -1.40402±0.00000  bestvalidloss -1.40402  last_update 0\n",
      "train: iter 154  trainloss -0.98046  validloss -1.34217±0.00000  bestvalidloss -1.40402  last_update 1\n",
      "train: iter 155  trainloss -1.03608  validloss -1.31292±0.00000  bestvalidloss -1.40402  last_update 2\n",
      "train: iter 156  trainloss -0.98710  validloss -1.31586±0.00000  bestvalidloss -1.40402  last_update 3\n",
      "train: iter 157  trainloss -1.03869  validloss -1.40832±0.00000  bestvalidloss -1.40832  last_update 0\n",
      "train: iter 158  trainloss -1.04238  validloss -1.32194±0.00000  bestvalidloss -1.40832  last_update 1\n",
      "train: iter 159  trainloss -1.00748  validloss -1.35726±0.00000  bestvalidloss -1.40832  last_update 2\n",
      "train: iter 160  trainloss -1.01109  validloss -1.38306±0.00000  bestvalidloss -1.40832  last_update 3\n",
      "train: iter 161  trainloss -0.92658  validloss -1.36195±0.00000  bestvalidloss -1.40832  last_update 4\n",
      "train: iter 162  trainloss -0.95035  validloss -1.38504±0.00000  bestvalidloss -1.40832  last_update 5\n",
      "train: iter 163  trainloss -1.06568  validloss -1.38260±0.00000  bestvalidloss -1.40832  last_update 6\n",
      "train: iter 164  trainloss -0.99310  validloss -1.37020±0.00000  bestvalidloss -1.40832  last_update 7\n",
      "train: iter 165  trainloss -1.05561  validloss -1.38197±0.00000  bestvalidloss -1.40832  last_update 8\n",
      "train: iter 166  trainloss -1.04805  validloss -1.37177±0.00000  bestvalidloss -1.40832  last_update 9\n",
      "train: iter 167  trainloss -0.98569  validloss -1.30628±0.00000  bestvalidloss -1.40832  last_update 10\n",
      "train: iter 168  trainloss -1.03512  validloss -1.32799±0.00000  bestvalidloss -1.40832  last_update 11\n",
      "train: iter 169  trainloss -1.05527  validloss -1.35510±0.00000  bestvalidloss -1.40832  last_update 12\n",
      "train: iter 170  trainloss -0.97547  validloss -1.37252±0.00000  bestvalidloss -1.40832  last_update 13\n",
      "train: iter 171  trainloss -1.04568  validloss -1.33726±0.00000  bestvalidloss -1.40832  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 172  trainloss -1.07534  validloss -1.31960±0.00000  bestvalidloss -1.40832  last_update 15\n",
      "train: iter 173  trainloss -0.96440  validloss -1.40709±0.00000  bestvalidloss -1.40832  last_update 16\n",
      "train: iter 174  trainloss -0.93723  validloss -1.37469±0.00000  bestvalidloss -1.40832  last_update 17\n",
      "train: iter 175  trainloss -1.02775  validloss -1.41968±0.00000  bestvalidloss -1.41968  last_update 0\n",
      "train: iter 176  trainloss -1.03065  validloss -1.31080±0.00000  bestvalidloss -1.41968  last_update 1\n",
      "train: iter 177  trainloss -1.10023  validloss -1.39121±0.00000  bestvalidloss -1.41968  last_update 2\n",
      "train: iter 178  trainloss -1.05674  validloss -1.40357±0.00000  bestvalidloss -1.41968  last_update 3\n",
      "train: iter 179  trainloss -1.06221  validloss -1.39632±0.00000  bestvalidloss -1.41968  last_update 4\n",
      "train: iter 180  trainloss -0.92650  validloss -1.31936±0.00000  bestvalidloss -1.41968  last_update 5\n",
      "train: iter 181  trainloss -0.97939  validloss -1.37225±0.00000  bestvalidloss -1.41968  last_update 6\n",
      "train: iter 182  trainloss -1.02179  validloss -1.37486±0.00000  bestvalidloss -1.41968  last_update 7\n",
      "train: iter 183  trainloss -0.99665  validloss -1.36239±0.00000  bestvalidloss -1.41968  last_update 8\n",
      "train: iter 184  trainloss -0.98741  validloss -1.38226±0.00000  bestvalidloss -1.41968  last_update 9\n",
      "train: iter 185  trainloss -1.05161  validloss -1.36801±0.00000  bestvalidloss -1.41968  last_update 10\n",
      "train: iter 186  trainloss -1.04112  validloss -1.33178±0.00000  bestvalidloss -1.41968  last_update 11\n",
      "train: iter 187  trainloss -1.03152  validloss -1.34238±0.00000  bestvalidloss -1.41968  last_update 12\n",
      "train: iter 188  trainloss -1.00590  validloss -1.42300±0.00000  bestvalidloss -1.42300  last_update 0\n",
      "train: iter 189  trainloss -0.95685  validloss -1.40098±0.00000  bestvalidloss -1.42300  last_update 1\n",
      "train: iter 190  trainloss -1.08631  validloss -1.35773±0.00000  bestvalidloss -1.42300  last_update 2\n",
      "train: iter 191  trainloss -0.98691  validloss -1.39400±0.00000  bestvalidloss -1.42300  last_update 3\n",
      "train: iter 192  trainloss -0.91775  validloss -1.35822±0.00000  bestvalidloss -1.42300  last_update 4\n",
      "train: iter 193  trainloss -1.02270  validloss -1.35868±0.00000  bestvalidloss -1.42300  last_update 5\n",
      "train: iter 194  trainloss -1.06432  validloss -1.35718±0.00000  bestvalidloss -1.42300  last_update 6\n",
      "train: iter 195  trainloss -0.96313  validloss -1.41504±0.00000  bestvalidloss -1.42300  last_update 7\n",
      "train: iter 196  trainloss -0.99541  validloss -1.40177±0.00000  bestvalidloss -1.42300  last_update 8\n",
      "train: iter 197  trainloss -0.96341  validloss -1.33876±0.00000  bestvalidloss -1.42300  last_update 9\n",
      "train: iter 198  trainloss -1.08676  validloss -1.44834±0.00000  bestvalidloss -1.44834  last_update 0\n",
      "train: iter 199  trainloss -1.03008  validloss -1.38720±0.00000  bestvalidloss -1.44834  last_update 1\n",
      "train: iter 200  trainloss -1.04256  validloss -1.36303±0.00000  bestvalidloss -1.44834  last_update 2\n",
      "train: iter 201  trainloss -1.03560  validloss -1.39175±0.00000  bestvalidloss -1.44834  last_update 3\n",
      "train: iter 202  trainloss -1.01875  validloss -1.36703±0.00000  bestvalidloss -1.44834  last_update 4\n",
      "train: iter 203  trainloss -1.06000  validloss -1.36541±0.00000  bestvalidloss -1.44834  last_update 5\n",
      "train: iter 204  trainloss -1.08543  validloss -1.35696±0.00000  bestvalidloss -1.44834  last_update 6\n",
      "train: iter 205  trainloss -1.06268  validloss -1.37850±0.00000  bestvalidloss -1.44834  last_update 7\n",
      "train: iter 206  trainloss -1.06806  validloss -1.37500±0.00000  bestvalidloss -1.44834  last_update 8\n",
      "train: iter 207  trainloss -1.06449  validloss -1.38181±0.00000  bestvalidloss -1.44834  last_update 9\n",
      "train: iter 208  trainloss -1.00561  validloss -1.37471±0.00000  bestvalidloss -1.44834  last_update 10\n",
      "train: iter 209  trainloss -1.03166  validloss -1.33330±0.00000  bestvalidloss -1.44834  last_update 11\n",
      "train: iter 210  trainloss -1.05623  validloss -1.40226±0.00000  bestvalidloss -1.44834  last_update 12\n",
      "train: iter 211  trainloss -0.94445  validloss -1.38148±0.00000  bestvalidloss -1.44834  last_update 13\n",
      "train: iter 212  trainloss -0.98216  validloss -1.39988±0.00000  bestvalidloss -1.44834  last_update 14\n",
      "train: iter 213  trainloss -1.00764  validloss -1.39871±0.00000  bestvalidloss -1.44834  last_update 15\n",
      "train: iter 214  trainloss -0.99163  validloss -1.41962±0.00000  bestvalidloss -1.44834  last_update 16\n",
      "train: iter 215  trainloss -1.08862  validloss -1.37063±0.00000  bestvalidloss -1.44834  last_update 17\n",
      "train: iter 216  trainloss -1.01403  validloss -1.43410±0.00000  bestvalidloss -1.44834  last_update 18\n",
      "train: iter 217  trainloss -1.02416  validloss -1.41461±0.00000  bestvalidloss -1.44834  last_update 19\n",
      "train: iter 218  trainloss -0.95763  validloss -1.37661±0.00000  bestvalidloss -1.44834  last_update 20\n",
      "train: iter 219  trainloss -1.00875  validloss -1.41720±0.00000  bestvalidloss -1.44834  last_update 21\n",
      "train: iter 220  trainloss -1.04941  validloss -1.39994±0.00000  bestvalidloss -1.44834  last_update 22\n",
      "train: iter 221  trainloss -1.10755  validloss -1.35036±0.00000  bestvalidloss -1.44834  last_update 23\n",
      "train: iter 222  trainloss -1.10610  validloss -1.38636±0.00000  bestvalidloss -1.44834  last_update 24\n",
      "train: iter 223  trainloss -0.99694  validloss -1.33221±0.00000  bestvalidloss -1.44834  last_update 25\n",
      "train: iter 224  trainloss -0.97430  validloss -1.42048±0.00000  bestvalidloss -1.44834  last_update 26\n",
      "train: iter 225  trainloss -1.07976  validloss -1.43297±0.00000  bestvalidloss -1.44834  last_update 27\n",
      "train: iter 226  trainloss -0.94375  validloss -1.38643±0.00000  bestvalidloss -1.44834  last_update 28\n",
      "train: iter 227  trainloss -1.06173  validloss -1.35808±0.00000  bestvalidloss -1.44834  last_update 29\n",
      "train: iter 228  trainloss -1.03269  validloss -1.44094±0.00000  bestvalidloss -1.44834  last_update 30\n",
      "train: iter 229  trainloss -1.07591  validloss -1.40189±0.00000  bestvalidloss -1.44834  last_update 31\n",
      "train: iter 230  trainloss -1.00803  validloss -1.40401±0.00000  bestvalidloss -1.44834  last_update 32\n",
      "train: iter 231  trainloss -1.11781  validloss -1.37902±0.00000  bestvalidloss -1.44834  last_update 33\n",
      "train: iter 232  trainloss -0.97729  validloss -1.40993±0.00000  bestvalidloss -1.44834  last_update 34\n",
      "train: iter 233  trainloss -0.96949  validloss -1.36220±0.00000  bestvalidloss -1.44834  last_update 35\n",
      "train: iter 234  trainloss -0.97701  validloss -1.39320±0.00000  bestvalidloss -1.44834  last_update 36\n",
      "train: iter 235  trainloss -0.88696  validloss -1.38253±0.00000  bestvalidloss -1.44834  last_update 37\n",
      "train: iter 236  trainloss -0.97062  validloss -1.44602±0.00000  bestvalidloss -1.44834  last_update 38\n",
      "train: iter 237  trainloss -0.97915  validloss -1.40425±0.00000  bestvalidloss -1.44834  last_update 39\n",
      "train: iter 238  trainloss -0.99726  validloss -1.44687±0.00000  bestvalidloss -1.44834  last_update 40\n",
      "train: iter 239  trainloss -0.99765  validloss -1.38066±0.00000  bestvalidloss -1.44834  last_update 41\n",
      "train: iter 240  trainloss -1.01869  validloss -1.41943±0.00000  bestvalidloss -1.44834  last_update 42\n",
      "train: iter 241  trainloss -0.96315  validloss -1.43424±0.00000  bestvalidloss -1.44834  last_update 43\n",
      "train: iter 242  trainloss -1.01940  validloss -1.37279±0.00000  bestvalidloss -1.44834  last_update 44\n",
      "train: iter 243  trainloss -0.99687  validloss -1.31402±0.00000  bestvalidloss -1.44834  last_update 45\n",
      "train: iter 244  trainloss -0.97477  validloss -1.36807±0.00000  bestvalidloss -1.44834  last_update 46\n",
      "train: iter 245  trainloss -0.98930  validloss -1.32437±0.00000  bestvalidloss -1.44834  last_update 47\n",
      "train: iter 246  trainloss -1.02691  validloss -1.38312±0.00000  bestvalidloss -1.44834  last_update 48\n",
      "train: iter 247  trainloss -1.11464  validloss -1.34937±0.00000  bestvalidloss -1.44834  last_update 49\n",
      "train: iter 248  trainloss -1.03330  validloss -1.36966±0.00000  bestvalidloss -1.44834  last_update 50\n",
      "train: iter 249  trainloss -0.97196  validloss -1.43128±0.00000  bestvalidloss -1.44834  last_update 51\n",
      "train: iter 250  trainloss -1.08049  validloss -1.38026±0.00000  bestvalidloss -1.44834  last_update 52\n",
      "train: iter 251  trainloss -1.08599  validloss -1.42084±0.00000  bestvalidloss -1.44834  last_update 53\n",
      "train: iter 252  trainloss -1.02299  validloss -1.30753±0.00000  bestvalidloss -1.44834  last_update 54\n",
      "train: iter 253  trainloss -0.99183  validloss -1.40105±0.00000  bestvalidloss -1.44834  last_update 55\n",
      "train: iter 254  trainloss -1.02215  validloss -1.34809±0.00000  bestvalidloss -1.44834  last_update 56\n",
      "train: iter 255  trainloss -0.98406  validloss -1.32955±0.00000  bestvalidloss -1.44834  last_update 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 256  trainloss -0.94677  validloss -1.45197±0.00000  bestvalidloss -1.45197  last_update 0\n",
      "train: iter 257  trainloss -1.04971  validloss -1.39576±0.00000  bestvalidloss -1.45197  last_update 1\n",
      "train: iter 258  trainloss -1.03017  validloss -1.35042±0.00000  bestvalidloss -1.45197  last_update 2\n",
      "train: iter 259  trainloss -1.03696  validloss -1.32932±0.00000  bestvalidloss -1.45197  last_update 3\n",
      "train: iter 260  trainloss -1.03013  validloss -1.41039±0.00000  bestvalidloss -1.45197  last_update 4\n",
      "train: iter 261  trainloss -0.99238  validloss -1.35751±0.00000  bestvalidloss -1.45197  last_update 5\n",
      "train: iter 262  trainloss -0.99976  validloss -1.37394±0.00000  bestvalidloss -1.45197  last_update 6\n",
      "train: iter 263  trainloss -1.00200  validloss -1.38563±0.00000  bestvalidloss -1.45197  last_update 7\n",
      "train: iter 264  trainloss -1.00653  validloss -1.39355±0.00000  bestvalidloss -1.45197  last_update 8\n",
      "train: iter 265  trainloss -1.07504  validloss -1.37463±0.00000  bestvalidloss -1.45197  last_update 9\n",
      "train: iter 266  trainloss -0.99247  validloss -1.40220±0.00000  bestvalidloss -1.45197  last_update 10\n",
      "train: iter 267  trainloss -1.07411  validloss -1.41453±0.00000  bestvalidloss -1.45197  last_update 11\n",
      "train: iter 268  trainloss -1.01980  validloss -1.37862±0.00000  bestvalidloss -1.45197  last_update 12\n",
      "train: iter 269  trainloss -0.89733  validloss -1.37479±0.00000  bestvalidloss -1.45197  last_update 13\n",
      "train: iter 270  trainloss -0.94807  validloss -1.39708±0.00000  bestvalidloss -1.45197  last_update 14\n",
      "train: iter 271  trainloss -1.00096  validloss -1.30608±0.00000  bestvalidloss -1.45197  last_update 15\n",
      "train: iter 272  trainloss -0.94726  validloss -1.39274±0.00000  bestvalidloss -1.45197  last_update 16\n",
      "train: iter 273  trainloss -0.97300  validloss -1.29765±0.00000  bestvalidloss -1.45197  last_update 17\n",
      "train: iter 274  trainloss -0.98196  validloss -1.42897±0.00000  bestvalidloss -1.45197  last_update 18\n",
      "train: iter 275  trainloss -1.05563  validloss -1.36648±0.00000  bestvalidloss -1.45197  last_update 19\n",
      "train: iter 276  trainloss -1.08641  validloss -1.39040±0.00000  bestvalidloss -1.45197  last_update 20\n",
      "train: iter 277  trainloss -1.00781  validloss -1.38065±0.00000  bestvalidloss -1.45197  last_update 21\n",
      "train: iter 278  trainloss -1.06213  validloss -1.37808±0.00000  bestvalidloss -1.45197  last_update 22\n",
      "train: iter 279  trainloss -0.96420  validloss -1.38733±0.00000  bestvalidloss -1.45197  last_update 23\n",
      "train: iter 280  trainloss -1.04838  validloss -1.34000±0.00000  bestvalidloss -1.45197  last_update 24\n",
      "train: iter 281  trainloss -1.01878  validloss -1.41185±0.00000  bestvalidloss -1.45197  last_update 25\n",
      "train: iter 282  trainloss -1.02043  validloss -1.36116±0.00000  bestvalidloss -1.45197  last_update 26\n",
      "train: iter 283  trainloss -0.95702  validloss -1.38406±0.00000  bestvalidloss -1.45197  last_update 27\n",
      "train: iter 284  trainloss -0.99857  validloss -1.31607±0.00000  bestvalidloss -1.45197  last_update 28\n",
      "train: iter 285  trainloss -1.07639  validloss -1.40593±0.00000  bestvalidloss -1.45197  last_update 29\n",
      "train: iter 286  trainloss -0.96047  validloss -1.38808±0.00000  bestvalidloss -1.45197  last_update 30\n",
      "train: iter 287  trainloss -0.98722  validloss -1.41143±0.00000  bestvalidloss -1.45197  last_update 31\n",
      "train: iter 288  trainloss -0.96532  validloss -1.38731±0.00000  bestvalidloss -1.45197  last_update 32\n",
      "train: iter 289  trainloss -1.04489  validloss -1.31199±0.00000  bestvalidloss -1.45197  last_update 33\n",
      "train: iter 290  trainloss -1.05970  validloss -1.38186±0.00000  bestvalidloss -1.45197  last_update 34\n",
      "train: iter 291  trainloss -1.02753  validloss -1.39982±0.00000  bestvalidloss -1.45197  last_update 35\n",
      "train: iter 292  trainloss -1.02336  validloss -1.43320±0.00000  bestvalidloss -1.45197  last_update 36\n",
      "train: iter 293  trainloss -0.98296  validloss -1.32662±0.00000  bestvalidloss -1.45197  last_update 37\n",
      "train: iter 294  trainloss -1.01826  validloss -1.46082±0.00000  bestvalidloss -1.46082  last_update 0\n",
      "train: iter 295  trainloss -1.09621  validloss -1.34354±0.00000  bestvalidloss -1.46082  last_update 1\n",
      "train: iter 296  trainloss -0.97030  validloss -1.39014±0.00000  bestvalidloss -1.46082  last_update 2\n",
      "train: iter 297  trainloss -1.03322  validloss -1.42087±0.00000  bestvalidloss -1.46082  last_update 3\n",
      "train: iter 298  trainloss -1.05455  validloss -1.39843±0.00000  bestvalidloss -1.46082  last_update 4\n",
      "train: iter 299  trainloss -1.05408  validloss -1.35659±0.00000  bestvalidloss -1.46082  last_update 5\n",
      "train: iter 300  trainloss -0.99512  validloss -1.36019±0.00000  bestvalidloss -1.46082  last_update 6\n",
      "train: iter 301  trainloss -0.99672  validloss -1.35189±0.00000  bestvalidloss -1.46082  last_update 7\n",
      "train: iter 302  trainloss -0.99436  validloss -1.38739±0.00000  bestvalidloss -1.46082  last_update 8\n",
      "train: iter 303  trainloss -1.02376  validloss -1.34536±0.00000  bestvalidloss -1.46082  last_update 9\n",
      "train: iter 304  trainloss -0.99495  validloss -1.38818±0.00000  bestvalidloss -1.46082  last_update 10\n",
      "train: iter 305  trainloss -1.06675  validloss -1.38494±0.00000  bestvalidloss -1.46082  last_update 11\n",
      "train: iter 306  trainloss -1.03045  validloss -1.38198±0.00000  bestvalidloss -1.46082  last_update 12\n",
      "train: iter 307  trainloss -0.88610  validloss -1.41962±0.00000  bestvalidloss -1.46082  last_update 13\n",
      "train: iter 308  trainloss -0.94596  validloss -1.41369±0.00000  bestvalidloss -1.46082  last_update 14\n",
      "train: iter 309  trainloss -0.99824  validloss -1.34305±0.00000  bestvalidloss -1.46082  last_update 15\n",
      "train: iter 310  trainloss -1.08718  validloss -1.37435±0.00000  bestvalidloss -1.46082  last_update 16\n",
      "train: iter 311  trainloss -1.08269  validloss -1.36325±0.00000  bestvalidloss -1.46082  last_update 17\n",
      "train: iter 312  trainloss -1.06551  validloss -1.39626±0.00000  bestvalidloss -1.46082  last_update 18\n",
      "train: iter 313  trainloss -1.08878  validloss -1.38149±0.00000  bestvalidloss -1.46082  last_update 19\n",
      "train: iter 314  trainloss -1.02735  validloss -1.35110±0.00000  bestvalidloss -1.46082  last_update 20\n",
      "train: iter 315  trainloss -0.97381  validloss -1.34667±0.00000  bestvalidloss -1.46082  last_update 21\n",
      "train: iter 316  trainloss -1.05258  validloss -1.41525±0.00000  bestvalidloss -1.46082  last_update 22\n",
      "train: iter 317  trainloss -0.93348  validloss -1.37177±0.00000  bestvalidloss -1.46082  last_update 23\n",
      "train: iter 318  trainloss -1.01107  validloss -1.46152±0.00000  bestvalidloss -1.46152  last_update 0\n",
      "train: iter 319  trainloss -1.05984  validloss -1.39784±0.00000  bestvalidloss -1.46152  last_update 1\n",
      "train: iter 320  trainloss -1.03834  validloss -1.36713±0.00000  bestvalidloss -1.46152  last_update 2\n",
      "train: iter 321  trainloss -1.09464  validloss -1.35211±0.00000  bestvalidloss -1.46152  last_update 3\n",
      "train: iter 322  trainloss -1.03403  validloss -1.42541±0.00000  bestvalidloss -1.46152  last_update 4\n",
      "train: iter 323  trainloss -1.09172  validloss -1.35432±0.00000  bestvalidloss -1.46152  last_update 5\n",
      "train: iter 324  trainloss -0.97911  validloss -1.38209±0.00000  bestvalidloss -1.46152  last_update 6\n",
      "train: iter 325  trainloss -1.05432  validloss -1.38068±0.00000  bestvalidloss -1.46152  last_update 7\n",
      "train: iter 326  trainloss -1.08169  validloss -1.29703±0.00000  bestvalidloss -1.46152  last_update 8\n",
      "train: iter 327  trainloss -1.00753  validloss -1.38296±0.00000  bestvalidloss -1.46152  last_update 9\n",
      "train: iter 328  trainloss -1.14781  validloss -1.38022±0.00000  bestvalidloss -1.46152  last_update 10\n",
      "train: iter 329  trainloss -0.97910  validloss -1.36648±0.00000  bestvalidloss -1.46152  last_update 11\n",
      "train: iter 330  trainloss -1.07708  validloss -1.39513±0.00000  bestvalidloss -1.46152  last_update 12\n",
      "train: iter 331  trainloss -1.03308  validloss -1.43966±0.00000  bestvalidloss -1.46152  last_update 13\n",
      "train: iter 332  trainloss -1.09181  validloss -1.37684±0.00000  bestvalidloss -1.46152  last_update 14\n",
      "train: iter 333  trainloss -1.01503  validloss -1.36634±0.00000  bestvalidloss -1.46152  last_update 15\n",
      "train: iter 334  trainloss -0.96092  validloss -1.43087±0.00000  bestvalidloss -1.46152  last_update 16\n",
      "train: iter 335  trainloss -1.05808  validloss -1.41888±0.00000  bestvalidloss -1.46152  last_update 17\n",
      "train: iter 336  trainloss -1.04125  validloss -1.41015±0.00000  bestvalidloss -1.46152  last_update 18\n",
      "train: iter 337  trainloss -1.02727  validloss -1.38348±0.00000  bestvalidloss -1.46152  last_update 19\n",
      "train: iter 338  trainloss -0.95239  validloss -1.39530±0.00000  bestvalidloss -1.46152  last_update 20\n",
      "train: iter 339  trainloss -1.07764  validloss -1.46819±0.00000  bestvalidloss -1.46819  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 340  trainloss -0.99297  validloss -1.38079±0.00000  bestvalidloss -1.46819  last_update 1\n",
      "train: iter 341  trainloss -1.01127  validloss -1.41972±0.00000  bestvalidloss -1.46819  last_update 2\n",
      "train: iter 342  trainloss -1.06582  validloss -1.40930±0.00000  bestvalidloss -1.46819  last_update 3\n",
      "train: iter 343  trainloss -1.00554  validloss -1.44265±0.00000  bestvalidloss -1.46819  last_update 4\n",
      "train: iter 344  trainloss -1.03576  validloss -1.39163±0.00000  bestvalidloss -1.46819  last_update 5\n",
      "train: iter 345  trainloss -1.09996  validloss -1.31801±0.00000  bestvalidloss -1.46819  last_update 6\n",
      "train: iter 346  trainloss -0.97828  validloss -1.42129±0.00000  bestvalidloss -1.46819  last_update 7\n",
      "train: iter 347  trainloss -1.00292  validloss -1.43589±0.00000  bestvalidloss -1.46819  last_update 8\n",
      "train: iter 348  trainloss -1.02157  validloss -1.34448±0.00000  bestvalidloss -1.46819  last_update 9\n",
      "train: iter 349  trainloss -0.96544  validloss -1.36544±0.00000  bestvalidloss -1.46819  last_update 10\n",
      "train: iter 350  trainloss -0.92643  validloss -1.40371±0.00000  bestvalidloss -1.46819  last_update 11\n",
      "train: iter 351  trainloss -1.03811  validloss -1.42608±0.00000  bestvalidloss -1.46819  last_update 12\n",
      "train: iter 352  trainloss -1.01249  validloss -1.37691±0.00000  bestvalidloss -1.46819  last_update 13\n",
      "train: iter 353  trainloss -1.04124  validloss -1.44832±0.00000  bestvalidloss -1.46819  last_update 14\n",
      "train: iter 354  trainloss -0.93647  validloss -1.36143±0.00000  bestvalidloss -1.46819  last_update 15\n",
      "train: iter 355  trainloss -1.04192  validloss -1.40867±0.00000  bestvalidloss -1.46819  last_update 16\n",
      "train: iter 356  trainloss -1.04942  validloss -1.41475±0.00000  bestvalidloss -1.46819  last_update 17\n",
      "train: iter 357  trainloss -0.95528  validloss -1.37986±0.00000  bestvalidloss -1.46819  last_update 18\n",
      "train: iter 358  trainloss -1.06740  validloss -1.33090±0.00000  bestvalidloss -1.46819  last_update 19\n",
      "train: iter 359  trainloss -1.06475  validloss -1.40023±0.00000  bestvalidloss -1.46819  last_update 20\n",
      "train: iter 360  trainloss -1.03633  validloss -1.43392±0.00000  bestvalidloss -1.46819  last_update 21\n",
      "train: iter 361  trainloss -1.02374  validloss -1.40739±0.00000  bestvalidloss -1.46819  last_update 22\n",
      "train: iter 362  trainloss -1.04332  validloss -1.41326±0.00000  bestvalidloss -1.46819  last_update 23\n",
      "train: iter 363  trainloss -1.02661  validloss -1.39473±0.00000  bestvalidloss -1.46819  last_update 24\n",
      "train: iter 364  trainloss -1.05013  validloss -1.39024±0.00000  bestvalidloss -1.46819  last_update 25\n",
      "train: iter 365  trainloss -0.92547  validloss -1.41884±0.00000  bestvalidloss -1.46819  last_update 26\n",
      "train: iter 366  trainloss -1.00473  validloss -1.40206±0.00000  bestvalidloss -1.46819  last_update 27\n",
      "train: iter 367  trainloss -1.08408  validloss -1.42576±0.00000  bestvalidloss -1.46819  last_update 28\n",
      "train: iter 368  trainloss -1.02759  validloss -1.34367±0.00000  bestvalidloss -1.46819  last_update 29\n",
      "train: iter 369  trainloss -1.02530  validloss -1.35247±0.00000  bestvalidloss -1.46819  last_update 30\n",
      "train: iter 370  trainloss -1.06562  validloss -1.37808±0.00000  bestvalidloss -1.46819  last_update 31\n",
      "train: iter 371  trainloss -1.04293  validloss -1.36618±0.00000  bestvalidloss -1.46819  last_update 32\n",
      "train: iter 372  trainloss -1.00431  validloss -1.37349±0.00000  bestvalidloss -1.46819  last_update 33\n",
      "train: iter 373  trainloss -1.01327  validloss -1.39239±0.00000  bestvalidloss -1.46819  last_update 34\n",
      "train: iter 374  trainloss -1.00617  validloss -1.36948±0.00000  bestvalidloss -1.46819  last_update 35\n",
      "train: iter 375  trainloss -1.01992  validloss -1.35586±0.00000  bestvalidloss -1.46819  last_update 36\n",
      "train: iter 376  trainloss -1.11531  validloss -1.39616±0.00000  bestvalidloss -1.46819  last_update 37\n",
      "train: iter 377  trainloss -1.01893  validloss -1.40646±0.00000  bestvalidloss -1.46819  last_update 38\n",
      "train: iter 378  trainloss -1.00104  validloss -1.40858±0.00000  bestvalidloss -1.46819  last_update 39\n",
      "train: iter 379  trainloss -0.99730  validloss -1.39356±0.00000  bestvalidloss -1.46819  last_update 40\n",
      "train: iter 380  trainloss -1.07363  validloss -1.34064±0.00000  bestvalidloss -1.46819  last_update 41\n",
      "train: iter 381  trainloss -1.06146  validloss -1.43609±0.00000  bestvalidloss -1.46819  last_update 42\n",
      "train: iter 382  trainloss -0.96479  validloss -1.41234±0.00000  bestvalidloss -1.46819  last_update 43\n",
      "train: iter 383  trainloss -1.05642  validloss -1.43433±0.00000  bestvalidloss -1.46819  last_update 44\n",
      "train: iter 384  trainloss -0.94096  validloss -1.40894±0.00000  bestvalidloss -1.46819  last_update 45\n",
      "train: iter 385  trainloss -1.00490  validloss -1.29964±0.00000  bestvalidloss -1.46819  last_update 46\n",
      "train: iter 386  trainloss -1.01572  validloss -1.41619±0.00000  bestvalidloss -1.46819  last_update 47\n",
      "train: iter 387  trainloss -1.12030  validloss -1.41059±0.00000  bestvalidloss -1.46819  last_update 48\n",
      "train: iter 388  trainloss -1.02811  validloss -1.43850±0.00000  bestvalidloss -1.46819  last_update 49\n",
      "train: iter 389  trainloss -1.09885  validloss -1.41767±0.00000  bestvalidloss -1.46819  last_update 50\n",
      "train: iter 390  trainloss -1.07124  validloss -1.33914±0.00000  bestvalidloss -1.46819  last_update 51\n",
      "train: iter 391  trainloss -1.07889  validloss -1.42426±0.00000  bestvalidloss -1.46819  last_update 52\n",
      "train: iter 392  trainloss -1.04855  validloss -1.38243±0.00000  bestvalidloss -1.46819  last_update 53\n",
      "train: iter 393  trainloss -0.95050  validloss -1.37177±0.00000  bestvalidloss -1.46819  last_update 54\n",
      "train: iter 394  trainloss -0.95286  validloss -1.44340±0.00000  bestvalidloss -1.46819  last_update 55\n",
      "train: iter 395  trainloss -1.04147  validloss -1.42596±0.00000  bestvalidloss -1.46819  last_update 56\n",
      "train: iter 396  trainloss -0.99266  validloss -1.37706±0.00000  bestvalidloss -1.46819  last_update 57\n",
      "train: iter 397  trainloss -0.97189  validloss -1.39193±0.00000  bestvalidloss -1.46819  last_update 58\n",
      "train: iter 398  trainloss -0.97888  validloss -1.36283±0.00000  bestvalidloss -1.46819  last_update 59\n",
      "train: iter 399  trainloss -1.01970  validloss -1.41726±0.00000  bestvalidloss -1.46819  last_update 60\n",
      "train: iter 400  trainloss -0.98589  validloss -1.38029±0.00000  bestvalidloss -1.46819  last_update 61\n",
      "train: iter 401  trainloss -1.08768  validloss -1.39625±0.00000  bestvalidloss -1.46819  last_update 62\n",
      "train: iter 402  trainloss -1.00272  validloss -1.40734±0.00000  bestvalidloss -1.46819  last_update 63\n",
      "train: iter 403  trainloss -0.95798  validloss -1.35407±0.00000  bestvalidloss -1.46819  last_update 64\n",
      "train: iter 404  trainloss -1.03071  validloss -1.37906±0.00000  bestvalidloss -1.46819  last_update 65\n",
      "train: iter 405  trainloss -1.01421  validloss -1.39645±0.00000  bestvalidloss -1.46819  last_update 66\n",
      "train: iter 406  trainloss -0.98579  validloss -1.43740±0.00000  bestvalidloss -1.46819  last_update 67\n",
      "train: iter 407  trainloss -1.00826  validloss -1.32006±0.00000  bestvalidloss -1.46819  last_update 68\n",
      "train: iter 408  trainloss -0.94760  validloss -1.40283±0.00000  bestvalidloss -1.46819  last_update 69\n",
      "train: iter 409  trainloss -1.08151  validloss -1.31994±0.00000  bestvalidloss -1.46819  last_update 70\n",
      "train: iter 410  trainloss -0.95244  validloss -1.31372±0.00000  bestvalidloss -1.46819  last_update 71\n",
      "train: iter 411  trainloss -1.00797  validloss -1.39408±0.00000  bestvalidloss -1.46819  last_update 72\n",
      "train: iter 412  trainloss -1.07577  validloss -1.37132±0.00000  bestvalidloss -1.46819  last_update 73\n",
      "train: iter 413  trainloss -1.04916  validloss -1.42208±0.00000  bestvalidloss -1.46819  last_update 74\n",
      "train: iter 414  trainloss -0.96001  validloss -1.40234±0.00000  bestvalidloss -1.46819  last_update 75\n",
      "train: iter 415  trainloss -1.00462  validloss -1.33665±0.00000  bestvalidloss -1.46819  last_update 76\n",
      "train: iter 416  trainloss -1.01437  validloss -1.34522±0.00000  bestvalidloss -1.46819  last_update 77\n",
      "train: iter 417  trainloss -0.94223  validloss -1.37222±0.00000  bestvalidloss -1.46819  last_update 78\n",
      "train: iter 418  trainloss -0.95204  validloss -1.42961±0.00000  bestvalidloss -1.46819  last_update 79\n",
      "train: iter 419  trainloss -1.09936  validloss -1.37607±0.00000  bestvalidloss -1.46819  last_update 80\n",
      "train: iter 420  trainloss -0.98631  validloss -1.45064±0.00000  bestvalidloss -1.46819  last_update 81\n",
      "train: iter 421  trainloss -1.11407  validloss -1.38196±0.00000  bestvalidloss -1.46819  last_update 82\n",
      "train: iter 422  trainloss -0.98472  validloss -1.39980±0.00000  bestvalidloss -1.46819  last_update 83\n",
      "train: iter 423  trainloss -1.02788  validloss -1.38218±0.00000  bestvalidloss -1.46819  last_update 84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 424  trainloss -1.02282  validloss -1.43497±0.00000  bestvalidloss -1.46819  last_update 85\n",
      "train: iter 425  trainloss -0.99348  validloss -1.39167±0.00000  bestvalidloss -1.46819  last_update 86\n",
      "train: iter 426  trainloss -0.93029  validloss -1.40268±0.00000  bestvalidloss -1.46819  last_update 87\n",
      "train: iter 427  trainloss -1.09772  validloss -1.40525±0.00000  bestvalidloss -1.46819  last_update 88\n",
      "train: iter 428  trainloss -0.99360  validloss -1.36749±0.00000  bestvalidloss -1.46819  last_update 89\n",
      "train: iter 429  trainloss -0.98057  validloss -1.36370±0.00000  bestvalidloss -1.46819  last_update 90\n",
      "train: iter 430  trainloss -1.05126  validloss -1.40140±0.00000  bestvalidloss -1.46819  last_update 91\n",
      "train: iter 431  trainloss -1.04946  validloss -1.37581±0.00000  bestvalidloss -1.46819  last_update 92\n",
      "train: iter 432  trainloss -1.03672  validloss -1.36749±0.00000  bestvalidloss -1.46819  last_update 93\n",
      "train: iter 433  trainloss -1.03570  validloss -1.37746±0.00000  bestvalidloss -1.46819  last_update 94\n",
      "train: iter 434  trainloss -1.04442  validloss -1.42569±0.00000  bestvalidloss -1.46819  last_update 95\n",
      "train: iter 435  trainloss -1.05714  validloss -1.40198±0.00000  bestvalidloss -1.46819  last_update 96\n",
      "train: iter 436  trainloss -0.98690  validloss -1.38387±0.00000  bestvalidloss -1.46819  last_update 97\n",
      "train: iter 437  trainloss -0.93854  validloss -1.35842±0.00000  bestvalidloss -1.46819  last_update 98\n",
      "train: iter 438  trainloss -1.02941  validloss -1.42503±0.00000  bestvalidloss -1.46819  last_update 99\n",
      "train: iter 439  trainloss -0.96923  validloss -1.40512±0.00000  bestvalidloss -1.46819  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 2.0526, -0.0515, -5.2343, -2.5054], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 58.33872  validloss 62.89735±0.00000  bestvalidloss 62.89735  last_update 0\n",
      "train: iter 1  trainloss 43.67336  validloss 49.60050±0.00000  bestvalidloss 49.60050  last_update 0\n",
      "train: iter 2  trainloss 31.47649  validloss 35.61171±0.00000  bestvalidloss 35.61171  last_update 0\n",
      "train: iter 3  trainloss 23.45629  validloss 25.76270±0.00000  bestvalidloss 25.76270  last_update 0\n",
      "train: iter 4  trainloss 18.37481  validloss 19.76637±0.00000  bestvalidloss 19.76637  last_update 0\n",
      "train: iter 5  trainloss 14.95266  validloss 15.82541±0.00000  bestvalidloss 15.82541  last_update 0\n",
      "train: iter 6  trainloss 12.71885  validloss 13.38539±0.00000  bestvalidloss 13.38539  last_update 0\n",
      "train: iter 7  trainloss 11.10360  validloss 11.55510±0.00000  bestvalidloss 11.55510  last_update 0\n",
      "train: iter 8  trainloss 9.96175  validloss 10.17691±0.00000  bestvalidloss 10.17691  last_update 0\n",
      "train: iter 9  trainloss 9.27065  validloss 9.39070±0.00000  bestvalidloss 9.39070  last_update 0\n",
      "train: iter 10  trainloss 8.61815  validloss 8.82391±0.00000  bestvalidloss 8.82391  last_update 0\n",
      "train: iter 11  trainloss 8.23008  validloss 8.60353±0.00000  bestvalidloss 8.60353  last_update 0\n",
      "train: iter 12  trainloss 7.86190  validloss 8.01969±0.00000  bestvalidloss 8.01969  last_update 0\n",
      "train: iter 13  trainloss 7.51066  validloss 7.94339±0.00000  bestvalidloss 7.94339  last_update 0\n",
      "train: iter 14  trainloss 7.09003  validloss 7.70120±0.00000  bestvalidloss 7.70120  last_update 0\n",
      "train: iter 15  trainloss 6.86050  validloss 7.43472±0.00000  bestvalidloss 7.43472  last_update 0\n",
      "train: iter 16  trainloss 6.64434  validloss 7.22620±0.00000  bestvalidloss 7.22620  last_update 0\n",
      "train: iter 17  trainloss 6.33001  validloss 6.94632±0.00000  bestvalidloss 6.94632  last_update 0\n",
      "train: iter 18  trainloss 6.14841  validloss 6.77842±0.00000  bestvalidloss 6.77842  last_update 0\n",
      "train: iter 19  trainloss 5.91532  validloss 6.48957±0.00000  bestvalidloss 6.48957  last_update 0\n",
      "train: iter 20  trainloss 5.66057  validloss 6.29020±0.00000  bestvalidloss 6.29020  last_update 0\n",
      "train: iter 21  trainloss 5.38796  validloss 6.29615±0.00000  bestvalidloss 6.29020  last_update 1\n",
      "train: iter 22  trainloss 5.18213  validloss 5.80402±0.00000  bestvalidloss 5.80402  last_update 0\n",
      "train: iter 23  trainloss 4.94770  validloss 5.64869±0.00000  bestvalidloss 5.64869  last_update 0\n",
      "train: iter 24  trainloss 4.73021  validloss 5.34672±0.00000  bestvalidloss 5.34672  last_update 0\n",
      "train: iter 25  trainloss 4.46736  validloss 5.09243±0.00000  bestvalidloss 5.09243  last_update 0\n",
      "train: iter 26  trainloss 4.29580  validloss 4.97284±0.00000  bestvalidloss 4.97284  last_update 0\n",
      "train: iter 27  trainloss 4.12568  validloss 4.63924±0.00000  bestvalidloss 4.63924  last_update 0\n",
      "train: iter 28  trainloss 4.03493  validloss 4.48693±0.00000  bestvalidloss 4.48693  last_update 0\n",
      "train: iter 29  trainloss 4.05072  validloss 4.69450±0.00000  bestvalidloss 4.48693  last_update 1\n",
      "train: iter 30  trainloss 3.86620  validloss 4.53799±0.00000  bestvalidloss 4.48693  last_update 2\n",
      "train: iter 31  trainloss 3.81328  validloss 4.47742±0.00000  bestvalidloss 4.47742  last_update 0\n",
      "train: iter 32  trainloss 3.83206  validloss 4.51244±0.00000  bestvalidloss 4.47742  last_update 1\n",
      "train: iter 33  trainloss 3.79218  validloss 4.46094±0.00000  bestvalidloss 4.46094  last_update 0\n",
      "train: iter 34  trainloss 3.71924  validloss 4.52826±0.00000  bestvalidloss 4.46094  last_update 1\n",
      "train: iter 35  trainloss 3.74555  validloss 4.24062±0.00000  bestvalidloss 4.24062  last_update 0\n",
      "train: iter 36  trainloss 3.74324  validloss 4.32172±0.00000  bestvalidloss 4.24062  last_update 1\n",
      "train: iter 37  trainloss 3.72718  validloss 4.29736±0.00000  bestvalidloss 4.24062  last_update 2\n",
      "train: iter 38  trainloss 3.70192  validloss 4.60166±0.00000  bestvalidloss 4.24062  last_update 3\n",
      "train: iter 39  trainloss 3.71748  validloss 4.39021±0.00000  bestvalidloss 4.24062  last_update 4\n",
      "train: iter 40  trainloss 3.66535  validloss 4.51114±0.00000  bestvalidloss 4.24062  last_update 5\n",
      "train: iter 41  trainloss 3.65359  validloss 4.47112±0.00000  bestvalidloss 4.24062  last_update 6\n",
      "train: iter 42  trainloss 3.60660  validloss 4.45948±0.00000  bestvalidloss 4.24062  last_update 7\n",
      "train: iter 43  trainloss 3.67362  validloss 4.45275±0.00000  bestvalidloss 4.24062  last_update 8\n",
      "train: iter 44  trainloss 3.64832  validloss 4.27587±0.00000  bestvalidloss 4.24062  last_update 9\n",
      "train: iter 45  trainloss 3.65566  validloss 4.39911±0.00000  bestvalidloss 4.24062  last_update 10\n",
      "train: iter 46  trainloss 3.60496  validloss 4.45615±0.00000  bestvalidloss 4.24062  last_update 11\n",
      "train: iter 47  trainloss 3.64061  validloss 4.26397±0.00000  bestvalidloss 4.24062  last_update 12\n",
      "train: iter 48  trainloss 3.59162  validloss 4.22815±0.00000  bestvalidloss 4.22815  last_update 0\n",
      "train: iter 49  trainloss 3.55474  validloss 4.43537±0.00000  bestvalidloss 4.22815  last_update 1\n",
      "train: iter 50  trainloss 3.60463  validloss 4.33475±0.00000  bestvalidloss 4.22815  last_update 2\n",
      "train: iter 51  trainloss 3.63125  validloss 4.40123±0.00000  bestvalidloss 4.22815  last_update 3\n",
      "train: iter 52  trainloss 3.54597  validloss 4.43350±0.00000  bestvalidloss 4.22815  last_update 4\n",
      "train: iter 53  trainloss 3.57814  validloss 4.45506±0.00000  bestvalidloss 4.22815  last_update 5\n",
      "train: iter 54  trainloss 3.56456  validloss 4.43683±0.00000  bestvalidloss 4.22815  last_update 6\n",
      "train: iter 55  trainloss 3.54188  validloss 4.31119±0.00000  bestvalidloss 4.22815  last_update 7\n",
      "train: iter 56  trainloss 3.54970  validloss 4.40304±0.00000  bestvalidloss 4.22815  last_update 8\n",
      "train: iter 57  trainloss 3.51055  validloss 4.31818±0.00000  bestvalidloss 4.22815  last_update 9\n",
      "train: iter 58  trainloss 3.51082  validloss 4.33733±0.00000  bestvalidloss 4.22815  last_update 10\n",
      "train: iter 59  trainloss 3.51970  validloss 4.39897±0.00000  bestvalidloss 4.22815  last_update 11\n",
      "train: iter 60  trainloss 3.55006  validloss 4.39124±0.00000  bestvalidloss 4.22815  last_update 12\n",
      "train: iter 61  trainloss 3.58184  validloss 4.31210±0.00000  bestvalidloss 4.22815  last_update 13\n",
      "train: iter 62  trainloss 3.55460  validloss 4.35347±0.00000  bestvalidloss 4.22815  last_update 14\n",
      "train: iter 63  trainloss 3.54046  validloss 4.19230±0.00000  bestvalidloss 4.19230  last_update 0\n",
      "train: iter 64  trainloss 3.50136  validloss 4.38644±0.00000  bestvalidloss 4.19230  last_update 1\n",
      "train: iter 65  trainloss 3.52728  validloss 4.23526±0.00000  bestvalidloss 4.19230  last_update 2\n",
      "train: iter 66  trainloss 3.53476  validloss 4.20401±0.00000  bestvalidloss 4.19230  last_update 3\n",
      "train: iter 67  trainloss 3.56373  validloss 4.34801±0.00000  bestvalidloss 4.19230  last_update 4\n",
      "train: iter 68  trainloss 3.57438  validloss 4.31725±0.00000  bestvalidloss 4.19230  last_update 5\n",
      "train: iter 69  trainloss 3.53568  validloss 4.23945±0.00000  bestvalidloss 4.19230  last_update 6\n",
      "train: iter 70  trainloss 3.52467  validloss 4.26445±0.00000  bestvalidloss 4.19230  last_update 7\n",
      "train: iter 71  trainloss 3.56036  validloss 4.32487±0.00000  bestvalidloss 4.19230  last_update 8\n",
      "train: iter 72  trainloss 3.55452  validloss 4.26020±0.00000  bestvalidloss 4.19230  last_update 9\n",
      "train: iter 73  trainloss 3.51219  validloss 4.34718±0.00000  bestvalidloss 4.19230  last_update 10\n",
      "train: iter 74  trainloss 3.54643  validloss 4.55406±0.00000  bestvalidloss 4.19230  last_update 11\n",
      "train: iter 75  trainloss 3.53425  validloss 4.43192±0.00000  bestvalidloss 4.19230  last_update 12\n",
      "train: iter 76  trainloss 3.48168  validloss 4.31045±0.00000  bestvalidloss 4.19230  last_update 13\n",
      "train: iter 77  trainloss 3.51243  validloss 4.27694±0.00000  bestvalidloss 4.19230  last_update 14\n",
      "train: iter 78  trainloss 3.55566  validloss 4.36651±0.00000  bestvalidloss 4.19230  last_update 15\n",
      "train: iter 79  trainloss 3.49391  validloss 4.22070±0.00000  bestvalidloss 4.19230  last_update 16\n",
      "train: iter 80  trainloss 3.52148  validloss 4.43891±0.00000  bestvalidloss 4.19230  last_update 17\n",
      "train: iter 81  trainloss 3.51153  validloss 4.21201±0.00000  bestvalidloss 4.19230  last_update 18\n",
      "train: iter 82  trainloss 3.50804  validloss 4.41210±0.00000  bestvalidloss 4.19230  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 3.51048  validloss 4.25021±0.00000  bestvalidloss 4.19230  last_update 20\n",
      "train: iter 84  trainloss 3.52120  validloss 4.49622±0.00000  bestvalidloss 4.19230  last_update 21\n",
      "train: iter 85  trainloss 3.50211  validloss 4.24828±0.00000  bestvalidloss 4.19230  last_update 22\n",
      "train: iter 86  trainloss 3.48238  validloss 4.19868±0.00000  bestvalidloss 4.19230  last_update 23\n",
      "train: iter 87  trainloss 3.50836  validloss 4.39912±0.00000  bestvalidloss 4.19230  last_update 24\n",
      "train: iter 88  trainloss 3.49109  validloss 4.31306±0.00000  bestvalidloss 4.19230  last_update 25\n",
      "train: iter 89  trainloss 3.48115  validloss 4.43975±0.00000  bestvalidloss 4.19230  last_update 26\n",
      "train: iter 90  trainloss 3.48787  validloss 4.23992±0.00000  bestvalidloss 4.19230  last_update 27\n",
      "train: iter 91  trainloss 3.53080  validloss 4.30738±0.00000  bestvalidloss 4.19230  last_update 28\n",
      "train: iter 92  trainloss 3.50423  validloss 4.34321±0.00000  bestvalidloss 4.19230  last_update 29\n",
      "train: iter 93  trainloss 3.52942  validloss 4.37854±0.00000  bestvalidloss 4.19230  last_update 30\n",
      "train: iter 94  trainloss 3.50386  validloss 4.38079±0.00000  bestvalidloss 4.19230  last_update 31\n",
      "train: iter 95  trainloss 3.44870  validloss 4.31960±0.00000  bestvalidloss 4.19230  last_update 32\n",
      "train: iter 96  trainloss 3.47596  validloss 4.30751±0.00000  bestvalidloss 4.19230  last_update 33\n",
      "train: iter 97  trainloss 3.51801  validloss 4.19253±0.00000  bestvalidloss 4.19230  last_update 34\n",
      "train: iter 98  trainloss 3.43869  validloss 4.29095±0.00000  bestvalidloss 4.19230  last_update 35\n",
      "train: iter 99  trainloss 3.44027  validloss 4.46869±0.00000  bestvalidloss 4.19230  last_update 36\n",
      "train: iter 100  trainloss 3.47619  validloss 4.42836±0.00000  bestvalidloss 4.19230  last_update 37\n",
      "train: iter 101  trainloss 3.46728  validloss 4.32831±0.00000  bestvalidloss 4.19230  last_update 38\n",
      "train: iter 102  trainloss 3.48127  validloss 4.22351±0.00000  bestvalidloss 4.19230  last_update 39\n",
      "train: iter 103  trainloss 3.46143  validloss 4.31295±0.00000  bestvalidloss 4.19230  last_update 40\n",
      "train: iter 104  trainloss 3.47112  validloss 4.31031±0.00000  bestvalidloss 4.19230  last_update 41\n",
      "train: iter 105  trainloss 3.52849  validloss 4.30526±0.00000  bestvalidloss 4.19230  last_update 42\n",
      "train: iter 106  trainloss 3.44565  validloss 4.30681±0.00000  bestvalidloss 4.19230  last_update 43\n",
      "train: iter 107  trainloss 3.45280  validloss 4.40428±0.00000  bestvalidloss 4.19230  last_update 44\n",
      "train: iter 108  trainloss 3.47443  validloss 4.28899±0.00000  bestvalidloss 4.19230  last_update 45\n",
      "train: iter 109  trainloss 3.43478  validloss 4.24813±0.00000  bestvalidloss 4.19230  last_update 46\n",
      "train: iter 110  trainloss 3.51220  validloss 4.40822±0.00000  bestvalidloss 4.19230  last_update 47\n",
      "train: iter 111  trainloss 3.42645  validloss 4.32810±0.00000  bestvalidloss 4.19230  last_update 48\n",
      "train: iter 112  trainloss 3.41108  validloss 4.36484±0.00000  bestvalidloss 4.19230  last_update 49\n",
      "train: iter 113  trainloss 3.39761  validloss 4.31893±0.00000  bestvalidloss 4.19230  last_update 50\n",
      "train: iter 114  trainloss 3.45546  validloss 4.26390±0.00000  bestvalidloss 4.19230  last_update 51\n",
      "train: iter 115  trainloss 3.42693  validloss 4.27361±0.00000  bestvalidloss 4.19230  last_update 52\n",
      "train: iter 116  trainloss 3.47146  validloss 4.24658±0.00000  bestvalidloss 4.19230  last_update 53\n",
      "train: iter 117  trainloss 3.42966  validloss 4.33800±0.00000  bestvalidloss 4.19230  last_update 54\n",
      "train: iter 118  trainloss 3.44877  validloss 4.22755±0.00000  bestvalidloss 4.19230  last_update 55\n",
      "train: iter 119  trainloss 3.44357  validloss 4.45125±0.00000  bestvalidloss 4.19230  last_update 56\n",
      "train: iter 120  trainloss 3.44250  validloss 4.34986±0.00000  bestvalidloss 4.19230  last_update 57\n",
      "train: iter 121  trainloss 3.46539  validloss 4.16265±0.00000  bestvalidloss 4.16265  last_update 0\n",
      "train: iter 122  trainloss 3.47641  validloss 4.37108±0.00000  bestvalidloss 4.16265  last_update 1\n",
      "train: iter 123  trainloss 3.51072  validloss 4.32748±0.00000  bestvalidloss 4.16265  last_update 2\n",
      "train: iter 124  trainloss 3.40446  validloss 4.24389±0.00000  bestvalidloss 4.16265  last_update 3\n",
      "train: iter 125  trainloss 3.48465  validloss 4.22832±0.00000  bestvalidloss 4.16265  last_update 4\n",
      "train: iter 126  trainloss 3.44296  validloss 4.35782±0.00000  bestvalidloss 4.16265  last_update 5\n",
      "train: iter 127  trainloss 3.41689  validloss 4.44708±0.00000  bestvalidloss 4.16265  last_update 6\n",
      "train: iter 128  trainloss 3.47004  validloss 4.27027±0.00000  bestvalidloss 4.16265  last_update 7\n",
      "train: iter 129  trainloss 3.43130  validloss 4.33095±0.00000  bestvalidloss 4.16265  last_update 8\n",
      "train: iter 130  trainloss 3.45006  validloss 4.26930±0.00000  bestvalidloss 4.16265  last_update 9\n",
      "train: iter 131  trainloss 3.43504  validloss 4.41520±0.00000  bestvalidloss 4.16265  last_update 10\n",
      "train: iter 132  trainloss 3.39646  validloss 4.23788±0.00000  bestvalidloss 4.16265  last_update 11\n",
      "train: iter 133  trainloss 3.37601  validloss 4.22447±0.00000  bestvalidloss 4.16265  last_update 12\n",
      "train: iter 134  trainloss 3.46119  validloss 4.48052±0.00000  bestvalidloss 4.16265  last_update 13\n",
      "train: iter 135  trainloss 3.49337  validloss 4.43869±0.00000  bestvalidloss 4.16265  last_update 14\n",
      "train: iter 136  trainloss 3.40651  validloss 4.20888±0.00000  bestvalidloss 4.16265  last_update 15\n",
      "train: iter 137  trainloss 3.41149  validloss 4.44556±0.00000  bestvalidloss 4.16265  last_update 16\n",
      "train: iter 138  trainloss 3.45533  validloss 4.32360±0.00000  bestvalidloss 4.16265  last_update 17\n",
      "train: iter 139  trainloss 3.49473  validloss 4.35565±0.00000  bestvalidloss 4.16265  last_update 18\n",
      "train: iter 140  trainloss 3.44554  validloss 4.28888±0.00000  bestvalidloss 4.16265  last_update 19\n",
      "train: iter 141  trainloss 3.42846  validloss 4.22372±0.00000  bestvalidloss 4.16265  last_update 20\n",
      "train: iter 142  trainloss 3.41194  validloss 4.15613±0.00000  bestvalidloss 4.15613  last_update 0\n",
      "train: iter 143  trainloss 3.41860  validloss 4.22341±0.00000  bestvalidloss 4.15613  last_update 1\n",
      "train: iter 144  trainloss 3.43234  validloss 4.25256±0.00000  bestvalidloss 4.15613  last_update 2\n",
      "train: iter 145  trainloss 3.43889  validloss 4.23015±0.00000  bestvalidloss 4.15613  last_update 3\n",
      "train: iter 146  trainloss 3.41995  validloss 4.20152±0.00000  bestvalidloss 4.15613  last_update 4\n",
      "train: iter 147  trainloss 3.39388  validloss 4.27978±0.00000  bestvalidloss 4.15613  last_update 5\n",
      "train: iter 148  trainloss 3.39274  validloss 4.35377±0.00000  bestvalidloss 4.15613  last_update 6\n",
      "train: iter 149  trainloss 3.38974  validloss 4.49922±0.00000  bestvalidloss 4.15613  last_update 7\n",
      "train: iter 150  trainloss 3.41377  validloss 4.28794±0.00000  bestvalidloss 4.15613  last_update 8\n",
      "train: iter 151  trainloss 3.40642  validloss 4.22670±0.00000  bestvalidloss 4.15613  last_update 9\n",
      "train: iter 152  trainloss 3.41852  validloss 4.30047±0.00000  bestvalidloss 4.15613  last_update 10\n",
      "train: iter 153  trainloss 3.41678  validloss 4.29706±0.00000  bestvalidloss 4.15613  last_update 11\n",
      "train: iter 154  trainloss 3.44036  validloss 4.19225±0.00000  bestvalidloss 4.15613  last_update 12\n",
      "train: iter 155  trainloss 3.43932  validloss 4.26492±0.00000  bestvalidloss 4.15613  last_update 13\n",
      "train: iter 156  trainloss 3.39714  validloss 4.25481±0.00000  bestvalidloss 4.15613  last_update 14\n",
      "train: iter 157  trainloss 3.42526  validloss 4.24670±0.00000  bestvalidloss 4.15613  last_update 15\n",
      "train: iter 158  trainloss 3.42607  validloss 4.27483±0.00000  bestvalidloss 4.15613  last_update 16\n",
      "train: iter 159  trainloss 3.40583  validloss 4.46456±0.00000  bestvalidloss 4.15613  last_update 17\n",
      "train: iter 160  trainloss 3.40579  validloss 4.27613±0.00000  bestvalidloss 4.15613  last_update 18\n",
      "train: iter 161  trainloss 3.39042  validloss 4.18250±0.00000  bestvalidloss 4.15613  last_update 19\n",
      "train: iter 162  trainloss 3.43492  validloss 4.35061±0.00000  bestvalidloss 4.15613  last_update 20\n",
      "train: iter 163  trainloss 3.42185  validloss 4.32711±0.00000  bestvalidloss 4.15613  last_update 21\n",
      "train: iter 164  trainloss 3.40980  validloss 4.30318±0.00000  bestvalidloss 4.15613  last_update 22\n",
      "train: iter 165  trainloss 3.45668  validloss 4.26290±0.00000  bestvalidloss 4.15613  last_update 23\n",
      "train: iter 166  trainloss 3.41034  validloss 4.22783±0.00000  bestvalidloss 4.15613  last_update 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 3.43347  validloss 4.16263±0.00000  bestvalidloss 4.15613  last_update 25\n",
      "train: iter 168  trainloss 3.40114  validloss 4.22458±0.00000  bestvalidloss 4.15613  last_update 26\n",
      "train: iter 169  trainloss 3.45370  validloss 4.26495±0.00000  bestvalidloss 4.15613  last_update 27\n",
      "train: iter 170  trainloss 3.38947  validloss 4.28133±0.00000  bestvalidloss 4.15613  last_update 28\n",
      "train: iter 171  trainloss 3.43299  validloss 4.26475±0.00000  bestvalidloss 4.15613  last_update 29\n",
      "train: iter 172  trainloss 3.37951  validloss 4.19178±0.00000  bestvalidloss 4.15613  last_update 30\n",
      "train: iter 173  trainloss 3.42898  validloss 4.36507±0.00000  bestvalidloss 4.15613  last_update 31\n",
      "train: iter 174  trainloss 3.47314  validloss 4.14390±0.00000  bestvalidloss 4.14390  last_update 0\n",
      "train: iter 175  trainloss 3.41725  validloss 4.25469±0.00000  bestvalidloss 4.14390  last_update 1\n",
      "train: iter 176  trainloss 3.39648  validloss 4.36441±0.00000  bestvalidloss 4.14390  last_update 2\n",
      "train: iter 177  trainloss 3.37403  validloss 4.27391±0.00000  bestvalidloss 4.14390  last_update 3\n",
      "train: iter 178  trainloss 3.40891  validloss 4.24218±0.00000  bestvalidloss 4.14390  last_update 4\n",
      "train: iter 179  trainloss 3.40045  validloss 4.26860±0.00000  bestvalidloss 4.14390  last_update 5\n",
      "train: iter 180  trainloss 3.38598  validloss 4.46905±0.00000  bestvalidloss 4.14390  last_update 6\n",
      "train: iter 181  trainloss 3.39300  validloss 4.13325±0.00000  bestvalidloss 4.13325  last_update 0\n",
      "train: iter 182  trainloss 3.42639  validloss 4.27479±0.00000  bestvalidloss 4.13325  last_update 1\n",
      "train: iter 183  trainloss 3.39373  validloss 4.30147±0.00000  bestvalidloss 4.13325  last_update 2\n",
      "train: iter 184  trainloss 3.42932  validloss 4.16125±0.00000  bestvalidloss 4.13325  last_update 3\n",
      "train: iter 185  trainloss 3.45452  validloss 4.25026±0.00000  bestvalidloss 4.13325  last_update 4\n",
      "train: iter 186  trainloss 3.43808  validloss 4.41317±0.00000  bestvalidloss 4.13325  last_update 5\n",
      "train: iter 187  trainloss 3.42930  validloss 4.25652±0.00000  bestvalidloss 4.13325  last_update 6\n",
      "train: iter 188  trainloss 3.42253  validloss 4.22523±0.00000  bestvalidloss 4.13325  last_update 7\n",
      "train: iter 189  trainloss 3.40692  validloss 4.26710±0.00000  bestvalidloss 4.13325  last_update 8\n",
      "train: iter 190  trainloss 3.40891  validloss 4.15070±0.00000  bestvalidloss 4.13325  last_update 9\n",
      "train: iter 191  trainloss 3.36553  validloss 4.26599±0.00000  bestvalidloss 4.13325  last_update 10\n",
      "train: iter 192  trainloss 3.40803  validloss 4.28963±0.00000  bestvalidloss 4.13325  last_update 11\n",
      "train: iter 193  trainloss 3.41121  validloss 4.23356±0.00000  bestvalidloss 4.13325  last_update 12\n",
      "train: iter 194  trainloss 3.37054  validloss 4.13599±0.00000  bestvalidloss 4.13325  last_update 13\n",
      "train: iter 195  trainloss 3.39841  validloss 4.23702±0.00000  bestvalidloss 4.13325  last_update 14\n",
      "train: iter 196  trainloss 3.46647  validloss 4.29282±0.00000  bestvalidloss 4.13325  last_update 15\n",
      "train: iter 197  trainloss 3.42072  validloss 4.25331±0.00000  bestvalidloss 4.13325  last_update 16\n",
      "train: iter 198  trainloss 3.41325  validloss 4.29589±0.00000  bestvalidloss 4.13325  last_update 17\n",
      "train: iter 199  trainloss 3.38111  validloss 4.26110±0.00000  bestvalidloss 4.13325  last_update 18\n",
      "train: iter 200  trainloss 3.45567  validloss 4.44769±0.00000  bestvalidloss 4.13325  last_update 19\n",
      "train: iter 201  trainloss 3.37964  validloss 4.19006±0.00000  bestvalidloss 4.13325  last_update 20\n",
      "train: iter 202  trainloss 3.36205  validloss 4.17455±0.00000  bestvalidloss 4.13325  last_update 21\n",
      "train: iter 203  trainloss 3.39695  validloss 4.32808±0.00000  bestvalidloss 4.13325  last_update 22\n",
      "train: iter 204  trainloss 3.41724  validloss 4.36774±0.00000  bestvalidloss 4.13325  last_update 23\n",
      "train: iter 205  trainloss 3.40196  validloss 4.32923±0.00000  bestvalidloss 4.13325  last_update 24\n",
      "train: iter 206  trainloss 3.41607  validloss 4.14856±0.00000  bestvalidloss 4.13325  last_update 25\n",
      "train: iter 207  trainloss 3.36995  validloss 4.36317±0.00000  bestvalidloss 4.13325  last_update 26\n",
      "train: iter 208  trainloss 3.38883  validloss 4.20003±0.00000  bestvalidloss 4.13325  last_update 27\n",
      "train: iter 209  trainloss 3.42296  validloss 4.35104±0.00000  bestvalidloss 4.13325  last_update 28\n",
      "train: iter 210  trainloss 3.38151  validloss 4.18467±0.00000  bestvalidloss 4.13325  last_update 29\n",
      "train: iter 211  trainloss 3.38711  validloss 4.26725±0.00000  bestvalidloss 4.13325  last_update 30\n",
      "train: iter 212  trainloss 3.39353  validloss 4.32434±0.00000  bestvalidloss 4.13325  last_update 31\n",
      "train: iter 213  trainloss 3.40852  validloss 4.23715±0.00000  bestvalidloss 4.13325  last_update 32\n",
      "train: iter 214  trainloss 3.37526  validloss 4.25994±0.00000  bestvalidloss 4.13325  last_update 33\n",
      "train: iter 215  trainloss 3.39639  validloss 4.26431±0.00000  bestvalidloss 4.13325  last_update 34\n",
      "train: iter 216  trainloss 3.42412  validloss 4.19335±0.00000  bestvalidloss 4.13325  last_update 35\n",
      "train: iter 217  trainloss 3.36336  validloss 4.25038±0.00000  bestvalidloss 4.13325  last_update 36\n",
      "train: iter 218  trainloss 3.39717  validloss 4.24065±0.00000  bestvalidloss 4.13325  last_update 37\n",
      "train: iter 219  trainloss 3.40470  validloss 4.25668±0.00000  bestvalidloss 4.13325  last_update 38\n",
      "train: iter 220  trainloss 3.42501  validloss 4.21107±0.00000  bestvalidloss 4.13325  last_update 39\n",
      "train: iter 221  trainloss 3.39088  validloss 4.21324±0.00000  bestvalidloss 4.13325  last_update 40\n",
      "train: iter 222  trainloss 3.35874  validloss 4.31537±0.00000  bestvalidloss 4.13325  last_update 41\n",
      "train: iter 223  trainloss 3.38266  validloss 4.24652±0.00000  bestvalidloss 4.13325  last_update 42\n",
      "train: iter 224  trainloss 3.38320  validloss 4.37521±0.00000  bestvalidloss 4.13325  last_update 43\n",
      "train: iter 225  trainloss 3.42459  validloss 4.22645±0.00000  bestvalidloss 4.13325  last_update 44\n",
      "train: iter 226  trainloss 3.41236  validloss 4.26442±0.00000  bestvalidloss 4.13325  last_update 45\n",
      "train: iter 227  trainloss 3.36306  validloss 4.35792±0.00000  bestvalidloss 4.13325  last_update 46\n",
      "train: iter 228  trainloss 3.33569  validloss 4.35197±0.00000  bestvalidloss 4.13325  last_update 47\n",
      "train: iter 229  trainloss 3.40548  validloss 4.37102±0.00000  bestvalidloss 4.13325  last_update 48\n",
      "train: iter 230  trainloss 3.36308  validloss 4.34877±0.00000  bestvalidloss 4.13325  last_update 49\n",
      "train: iter 231  trainloss 3.38090  validloss 4.28998±0.00000  bestvalidloss 4.13325  last_update 50\n",
      "train: iter 232  trainloss 3.40106  validloss 4.27329±0.00000  bestvalidloss 4.13325  last_update 51\n",
      "train: iter 233  trainloss 3.40799  validloss 4.31413±0.00000  bestvalidloss 4.13325  last_update 52\n",
      "train: iter 234  trainloss 3.41967  validloss 4.30397±0.00000  bestvalidloss 4.13325  last_update 53\n",
      "train: iter 235  trainloss 3.39663  validloss 4.20229±0.00000  bestvalidloss 4.13325  last_update 54\n",
      "train: iter 236  trainloss 3.42086  validloss 4.19326±0.00000  bestvalidloss 4.13325  last_update 55\n",
      "train: iter 237  trainloss 3.42711  validloss 4.20139±0.00000  bestvalidloss 4.13325  last_update 56\n",
      "train: iter 238  trainloss 3.42155  validloss 4.16617±0.00000  bestvalidloss 4.13325  last_update 57\n",
      "train: iter 239  trainloss 3.40988  validloss 4.45068±0.00000  bestvalidloss 4.13325  last_update 58\n",
      "train: iter 240  trainloss 3.36399  validloss 4.26591±0.00000  bestvalidloss 4.13325  last_update 59\n",
      "train: iter 241  trainloss 3.39928  validloss 4.12713±0.00000  bestvalidloss 4.12713  last_update 0\n",
      "train: iter 242  trainloss 3.43409  validloss 4.27615±0.00000  bestvalidloss 4.12713  last_update 1\n",
      "train: iter 243  trainloss 3.40408  validloss 4.31312±0.00000  bestvalidloss 4.12713  last_update 2\n",
      "train: iter 244  trainloss 3.42150  validloss 4.31696±0.00000  bestvalidloss 4.12713  last_update 3\n",
      "train: iter 245  trainloss 3.41581  validloss 4.21120±0.00000  bestvalidloss 4.12713  last_update 4\n",
      "train: iter 246  trainloss 3.38599  validloss 4.40331±0.00000  bestvalidloss 4.12713  last_update 5\n",
      "train: iter 247  trainloss 3.37852  validloss 4.44129±0.00000  bestvalidloss 4.12713  last_update 6\n",
      "train: iter 248  trainloss 3.41583  validloss 4.33052±0.00000  bestvalidloss 4.12713  last_update 7\n",
      "train: iter 249  trainloss 3.45018  validloss 4.28960±0.00000  bestvalidloss 4.12713  last_update 8\n",
      "train: iter 250  trainloss 3.41734  validloss 4.08243±0.00000  bestvalidloss 4.08243  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 251  trainloss 3.39575  validloss 4.31198±0.00000  bestvalidloss 4.08243  last_update 1\n",
      "train: iter 252  trainloss 3.40393  validloss 4.29992±0.00000  bestvalidloss 4.08243  last_update 2\n",
      "train: iter 253  trainloss 3.42055  validloss 4.25916±0.00000  bestvalidloss 4.08243  last_update 3\n",
      "train: iter 254  trainloss 3.41454  validloss 4.30768±0.00000  bestvalidloss 4.08243  last_update 4\n",
      "train: iter 255  trainloss 3.39794  validloss 4.34299±0.00000  bestvalidloss 4.08243  last_update 5\n",
      "train: iter 256  trainloss 3.41576  validloss 4.19867±0.00000  bestvalidloss 4.08243  last_update 6\n",
      "train: iter 257  trainloss 3.43876  validloss 4.27047±0.00000  bestvalidloss 4.08243  last_update 7\n",
      "train: iter 258  trainloss 3.40674  validloss 4.32469±0.00000  bestvalidloss 4.08243  last_update 8\n",
      "train: iter 259  trainloss 3.36139  validloss 4.30792±0.00000  bestvalidloss 4.08243  last_update 9\n",
      "train: iter 260  trainloss 3.39200  validloss 4.24926±0.00000  bestvalidloss 4.08243  last_update 10\n",
      "train: iter 261  trainloss 3.37271  validloss 4.24080±0.00000  bestvalidloss 4.08243  last_update 11\n",
      "train: iter 262  trainloss 3.41701  validloss 4.28718±0.00000  bestvalidloss 4.08243  last_update 12\n",
      "train: iter 263  trainloss 3.40585  validloss 4.17759±0.00000  bestvalidloss 4.08243  last_update 13\n",
      "train: iter 264  trainloss 3.34872  validloss 4.38684±0.00000  bestvalidloss 4.08243  last_update 14\n",
      "train: iter 265  trainloss 3.36025  validloss 4.39846±0.00000  bestvalidloss 4.08243  last_update 15\n",
      "train: iter 266  trainloss 3.34501  validloss 4.30783±0.00000  bestvalidloss 4.08243  last_update 16\n",
      "train: iter 267  trainloss 3.40167  validloss 4.25574±0.00000  bestvalidloss 4.08243  last_update 17\n",
      "train: iter 268  trainloss 3.38023  validloss 4.30447±0.00000  bestvalidloss 4.08243  last_update 18\n",
      "train: iter 269  trainloss 3.37354  validloss 4.42962±0.00000  bestvalidloss 4.08243  last_update 19\n",
      "train: iter 270  trainloss 3.38424  validloss 4.26263±0.00000  bestvalidloss 4.08243  last_update 20\n",
      "train: iter 271  trainloss 3.39047  validloss 4.43397±0.00000  bestvalidloss 4.08243  last_update 21\n",
      "train: iter 272  trainloss 3.38675  validloss 4.23125±0.00000  bestvalidloss 4.08243  last_update 22\n",
      "train: iter 273  trainloss 3.35586  validloss 4.29074±0.00000  bestvalidloss 4.08243  last_update 23\n",
      "train: iter 274  trainloss 3.38910  validloss 4.19147±0.00000  bestvalidloss 4.08243  last_update 24\n",
      "train: iter 275  trainloss 3.40218  validloss 4.27970±0.00000  bestvalidloss 4.08243  last_update 25\n",
      "train: iter 276  trainloss 3.38673  validloss 4.34398±0.00000  bestvalidloss 4.08243  last_update 26\n",
      "train: iter 277  trainloss 3.35728  validloss 4.22817±0.00000  bestvalidloss 4.08243  last_update 27\n",
      "train: iter 278  trainloss 3.37661  validloss 4.19421±0.00000  bestvalidloss 4.08243  last_update 28\n",
      "train: iter 279  trainloss 3.42812  validloss 4.28405±0.00000  bestvalidloss 4.08243  last_update 29\n",
      "train: iter 280  trainloss 3.37202  validloss 4.37580±0.00000  bestvalidloss 4.08243  last_update 30\n",
      "train: iter 281  trainloss 3.37104  validloss 4.31370±0.00000  bestvalidloss 4.08243  last_update 31\n",
      "train: iter 282  trainloss 3.35801  validloss 4.29764±0.00000  bestvalidloss 4.08243  last_update 32\n",
      "train: iter 283  trainloss 3.39144  validloss 4.34345±0.00000  bestvalidloss 4.08243  last_update 33\n",
      "train: iter 284  trainloss 3.32977  validloss 4.16682±0.00000  bestvalidloss 4.08243  last_update 34\n",
      "train: iter 285  trainloss 3.43741  validloss 4.23206±0.00000  bestvalidloss 4.08243  last_update 35\n",
      "train: iter 286  trainloss 3.43285  validloss 4.34926±0.00000  bestvalidloss 4.08243  last_update 36\n",
      "train: iter 287  trainloss 3.39352  validloss 4.45283±0.00000  bestvalidloss 4.08243  last_update 37\n",
      "train: iter 288  trainloss 3.36953  validloss 4.31409±0.00000  bestvalidloss 4.08243  last_update 38\n",
      "train: iter 289  trainloss 3.40155  validloss 4.18471±0.00000  bestvalidloss 4.08243  last_update 39\n",
      "train: iter 290  trainloss 3.38641  validloss 4.31532±0.00000  bestvalidloss 4.08243  last_update 40\n",
      "train: iter 291  trainloss 3.35110  validloss 4.21860±0.00000  bestvalidloss 4.08243  last_update 41\n",
      "train: iter 292  trainloss 3.36267  validloss 4.21838±0.00000  bestvalidloss 4.08243  last_update 42\n",
      "train: iter 293  trainloss 3.37114  validloss 4.40321±0.00000  bestvalidloss 4.08243  last_update 43\n",
      "train: iter 294  trainloss 3.37673  validloss 4.29095±0.00000  bestvalidloss 4.08243  last_update 44\n",
      "train: iter 295  trainloss 3.41385  validloss 4.24652±0.00000  bestvalidloss 4.08243  last_update 45\n",
      "train: iter 296  trainloss 3.36368  validloss 4.38825±0.00000  bestvalidloss 4.08243  last_update 46\n",
      "train: iter 297  trainloss 3.38168  validloss 4.40905±0.00000  bestvalidloss 4.08243  last_update 47\n",
      "train: iter 298  trainloss 3.38732  validloss 4.24128±0.00000  bestvalidloss 4.08243  last_update 48\n",
      "train: iter 299  trainloss 3.37930  validloss 4.31215±0.00000  bestvalidloss 4.08243  last_update 49\n",
      "train: iter 300  trainloss 3.36649  validloss 4.26268±0.00000  bestvalidloss 4.08243  last_update 50\n",
      "train: iter 301  trainloss 3.39788  validloss 4.28433±0.00000  bestvalidloss 4.08243  last_update 51\n",
      "train: iter 302  trainloss 3.31580  validloss 4.21282±0.00000  bestvalidloss 4.08243  last_update 52\n",
      "train: iter 303  trainloss 3.35717  validloss 4.29994±0.00000  bestvalidloss 4.08243  last_update 53\n",
      "train: iter 304  trainloss 3.40236  validloss 4.29799±0.00000  bestvalidloss 4.08243  last_update 54\n",
      "train: iter 305  trainloss 3.32062  validloss 4.45444±0.00000  bestvalidloss 4.08243  last_update 55\n",
      "train: iter 306  trainloss 3.37418  validloss 4.34862±0.00000  bestvalidloss 4.08243  last_update 56\n",
      "train: iter 307  trainloss 3.31669  validloss 4.26975±0.00000  bestvalidloss 4.08243  last_update 57\n",
      "train: iter 308  trainloss 3.37594  validloss 4.26377±0.00000  bestvalidloss 4.08243  last_update 58\n",
      "train: iter 309  trainloss 3.38427  validloss 4.21118±0.00000  bestvalidloss 4.08243  last_update 59\n",
      "train: iter 310  trainloss 3.41201  validloss 4.31364±0.00000  bestvalidloss 4.08243  last_update 60\n",
      "train: iter 311  trainloss 3.35826  validloss 4.23965±0.00000  bestvalidloss 4.08243  last_update 61\n",
      "train: iter 312  trainloss 3.35370  validloss 4.22263±0.00000  bestvalidloss 4.08243  last_update 62\n",
      "train: iter 313  trainloss 3.36412  validloss 4.11063±0.00000  bestvalidloss 4.08243  last_update 63\n",
      "train: iter 314  trainloss 3.40399  validloss 4.32085±0.00000  bestvalidloss 4.08243  last_update 64\n",
      "train: iter 315  trainloss 3.38273  validloss 4.37939±0.00000  bestvalidloss 4.08243  last_update 65\n",
      "train: iter 316  trainloss 3.43427  validloss 4.44954±0.00000  bestvalidloss 4.08243  last_update 66\n",
      "train: iter 317  trainloss 3.34868  validloss 4.32933±0.00000  bestvalidloss 4.08243  last_update 67\n",
      "train: iter 318  trainloss 3.35557  validloss 4.25353±0.00000  bestvalidloss 4.08243  last_update 68\n",
      "train: iter 319  trainloss 3.39925  validloss 4.40489±0.00000  bestvalidloss 4.08243  last_update 69\n",
      "train: iter 320  trainloss 3.37235  validloss 4.29307±0.00000  bestvalidloss 4.08243  last_update 70\n",
      "train: iter 321  trainloss 3.32141  validloss 4.24688±0.00000  bestvalidloss 4.08243  last_update 71\n",
      "train: iter 322  trainloss 3.38113  validloss 4.27356±0.00000  bestvalidloss 4.08243  last_update 72\n",
      "train: iter 323  trainloss 3.36731  validloss 4.15899±0.00000  bestvalidloss 4.08243  last_update 73\n",
      "train: iter 324  trainloss 3.37177  validloss 4.35103±0.00000  bestvalidloss 4.08243  last_update 74\n",
      "train: iter 325  trainloss 3.37477  validloss 4.43801±0.00000  bestvalidloss 4.08243  last_update 75\n",
      "train: iter 326  trainloss 3.33508  validloss 4.30330±0.00000  bestvalidloss 4.08243  last_update 76\n",
      "train: iter 327  trainloss 3.39889  validloss 4.33800±0.00000  bestvalidloss 4.08243  last_update 77\n",
      "train: iter 328  trainloss 3.30588  validloss 4.27825±0.00000  bestvalidloss 4.08243  last_update 78\n",
      "train: iter 329  trainloss 3.41195  validloss 4.22951±0.00000  bestvalidloss 4.08243  last_update 79\n",
      "train: iter 330  trainloss 3.38103  validloss 4.21893±0.00000  bestvalidloss 4.08243  last_update 80\n",
      "train: iter 331  trainloss 3.36436  validloss 4.38529±0.00000  bestvalidloss 4.08243  last_update 81\n",
      "train: iter 332  trainloss 3.36224  validloss 4.36082±0.00000  bestvalidloss 4.08243  last_update 82\n",
      "train: iter 333  trainloss 3.34425  validloss 4.17253±0.00000  bestvalidloss 4.08243  last_update 83\n",
      "train: iter 334  trainloss 3.41808  validloss 4.27289±0.00000  bestvalidloss 4.08243  last_update 84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 335  trainloss 3.39324  validloss 4.36254±0.00000  bestvalidloss 4.08243  last_update 85\n",
      "train: iter 336  trainloss 3.35004  validloss 4.23984±0.00000  bestvalidloss 4.08243  last_update 86\n",
      "train: iter 337  trainloss 3.36314  validloss 4.36226±0.00000  bestvalidloss 4.08243  last_update 87\n",
      "train: iter 338  trainloss 3.35949  validloss 4.39556±0.00000  bestvalidloss 4.08243  last_update 88\n",
      "train: iter 339  trainloss 3.34866  validloss 4.36223±0.00000  bestvalidloss 4.08243  last_update 89\n",
      "train: iter 340  trainloss 3.35053  validloss 4.34997±0.00000  bestvalidloss 4.08243  last_update 90\n",
      "train: iter 341  trainloss 3.41916  validloss 4.31297±0.00000  bestvalidloss 4.08243  last_update 91\n",
      "train: iter 342  trainloss 3.36834  validloss 4.20833±0.00000  bestvalidloss 4.08243  last_update 92\n",
      "train: iter 343  trainloss 3.38281  validloss 4.24255±0.00000  bestvalidloss 4.08243  last_update 93\n",
      "train: iter 344  trainloss 3.35028  validloss 4.16758±0.00000  bestvalidloss 4.08243  last_update 94\n",
      "train: iter 345  trainloss 3.38393  validloss 4.34513±0.00000  bestvalidloss 4.08243  last_update 95\n",
      "train: iter 346  trainloss 3.39648  validloss 4.30074±0.00000  bestvalidloss 4.08243  last_update 96\n",
      "train: iter 347  trainloss 3.33854  validloss 4.27711±0.00000  bestvalidloss 4.08243  last_update 97\n",
      "train: iter 348  trainloss 3.38028  validloss 4.43072±0.00000  bestvalidloss 4.08243  last_update 98\n",
      "train: iter 349  trainloss 3.35724  validloss 4.19563±0.00000  bestvalidloss 4.08243  last_update 99\n",
      "train: iter 350  trainloss 3.42750  validloss 4.27835±0.00000  bestvalidloss 4.08243  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-5.7386)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-2.9783)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5689940793544164\n",
      "tensor([-0.2419])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfff682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c9ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e0943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198825bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f45ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33660c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f08a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d77961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129676a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7f114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c970e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
